{"ast":null,"code":"import { IcebergRestCatalog } from \"iceberg-js\";\n\n//#region src/lib/errors.ts\nvar StorageError = class extends Error {\n  constructor(message) {\n    super(message);\n    this.__isStorageError = true;\n    this.name = \"StorageError\";\n  }\n};\nfunction isStorageError(error) {\n  return typeof error === \"object\" && error !== null && \"__isStorageError\" in error;\n}\nvar StorageApiError = class extends StorageError {\n  constructor(message, status, statusCode) {\n    super(message);\n    this.name = \"StorageApiError\";\n    this.status = status;\n    this.statusCode = statusCode;\n  }\n  toJSON() {\n    return {\n      name: this.name,\n      message: this.message,\n      status: this.status,\n      statusCode: this.statusCode\n    };\n  }\n};\nvar StorageUnknownError = class extends StorageError {\n  constructor(message, originalError) {\n    super(message);\n    this.name = \"StorageUnknownError\";\n    this.originalError = originalError;\n  }\n};\n\n//#endregion\n//#region src/lib/helpers.ts\nconst resolveFetch$1 = customFetch => {\n  if (customFetch) return function () {\n    return customFetch(...arguments);\n  };\n  return function () {\n    return fetch(...arguments);\n  };\n};\nconst resolveResponse$1 = () => {\n  return Response;\n};\nconst recursiveToCamel = item => {\n  if (Array.isArray(item)) return item.map(el => recursiveToCamel(el));else if (typeof item === \"function\" || item !== Object(item)) return item;\n  const result = {};\n  Object.entries(item).forEach(_ref => {\n    let [key, value] = _ref;\n    const newKey = key.replace(/([-_][a-z])/gi, c => c.toUpperCase().replace(/[-_]/g, \"\"));\n    result[newKey] = recursiveToCamel(value);\n  });\n  return result;\n};\n/**\n* Determine if input is a plain object\n* An object is plain if it's created by either {}, new Object(), or Object.create(null)\n* source: https://github.com/sindresorhus/is-plain-obj\n*/\nconst isPlainObject$1 = value => {\n  if (typeof value !== \"object\" || value === null) return false;\n  const prototype = Object.getPrototypeOf(value);\n  return (prototype === null || prototype === Object.prototype || Object.getPrototypeOf(prototype) === null) && !(Symbol.toStringTag in value) && !(Symbol.iterator in value);\n};\n/**\n* Validates if a given bucket name is valid according to Supabase Storage API rules\n* Mirrors backend validation from: storage/src/storage/limits.ts:isValidBucketName()\n*\n* Rules:\n* - Length: 1-100 characters\n* - Allowed characters: alphanumeric (a-z, A-Z, 0-9), underscore (_), and safe special characters\n* - Safe special characters: ! - . * ' ( ) space & $ @ = ; : + , ?\n* - Forbidden: path separators (/, \\), path traversal (..), leading/trailing whitespace\n*\n* AWS S3 Reference: https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-keys.html\n*\n* @param bucketName - The bucket name to validate\n* @returns true if valid, false otherwise\n*/\nconst isValidBucketName = bucketName => {\n  if (!bucketName || typeof bucketName !== \"string\") return false;\n  if (bucketName.length === 0 || bucketName.length > 100) return false;\n  if (bucketName.trim() !== bucketName) return false;\n  if (bucketName.includes(\"/\") || bucketName.includes(\"\\\\\")) return false;\n  return /^[\\w!.\\*'() &$@=;:+,?-]+$/.test(bucketName);\n};\n\n//#endregion\n//#region \\0@oxc-project+runtime@0.101.0/helpers/typeof.js\nfunction _typeof(o) {\n  \"@babel/helpers - typeof\";\n\n  return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (o$1) {\n    return typeof o$1;\n  } : function (o$1) {\n    return o$1 && \"function\" == typeof Symbol && o$1.constructor === Symbol && o$1 !== Symbol.prototype ? \"symbol\" : typeof o$1;\n  }, _typeof(o);\n}\n\n//#endregion\n//#region \\0@oxc-project+runtime@0.101.0/helpers/toPrimitive.js\nfunction toPrimitive(t, r) {\n  if (\"object\" != _typeof(t) || !t) return t;\n  var e = t[Symbol.toPrimitive];\n  if (void 0 !== e) {\n    var i = e.call(t, r || \"default\");\n    if (\"object\" != _typeof(i)) return i;\n    throw new TypeError(\"@@toPrimitive must return a primitive value.\");\n  }\n  return (\"string\" === r ? String : Number)(t);\n}\n\n//#endregion\n//#region \\0@oxc-project+runtime@0.101.0/helpers/toPropertyKey.js\nfunction toPropertyKey(t) {\n  var i = toPrimitive(t, \"string\");\n  return \"symbol\" == _typeof(i) ? i : i + \"\";\n}\n\n//#endregion\n//#region \\0@oxc-project+runtime@0.101.0/helpers/defineProperty.js\nfunction _defineProperty(e, r, t) {\n  return (r = toPropertyKey(r)) in e ? Object.defineProperty(e, r, {\n    value: t,\n    enumerable: !0,\n    configurable: !0,\n    writable: !0\n  }) : e[r] = t, e;\n}\n\n//#endregion\n//#region \\0@oxc-project+runtime@0.101.0/helpers/objectSpread2.js\nfunction ownKeys(e, r) {\n  var t = Object.keys(e);\n  if (Object.getOwnPropertySymbols) {\n    var o = Object.getOwnPropertySymbols(e);\n    r && (o = o.filter(function (r$1) {\n      return Object.getOwnPropertyDescriptor(e, r$1).enumerable;\n    })), t.push.apply(t, o);\n  }\n  return t;\n}\nfunction _objectSpread2(e) {\n  for (var r = 1; r < arguments.length; r++) {\n    var t = null != arguments[r] ? arguments[r] : {};\n    r % 2 ? ownKeys(Object(t), !0).forEach(function (r$1) {\n      _defineProperty(e, r$1, t[r$1]);\n    }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(e, Object.getOwnPropertyDescriptors(t)) : ownKeys(Object(t)).forEach(function (r$1) {\n      Object.defineProperty(e, r$1, Object.getOwnPropertyDescriptor(t, r$1));\n    });\n  }\n  return e;\n}\n\n//#endregion\n//#region src/lib/fetch.ts\nconst _getErrorMessage$1 = err => {\n  var _err$error;\n  return err.msg || err.message || err.error_description || (typeof err.error === \"string\" ? err.error : (_err$error = err.error) === null || _err$error === void 0 ? void 0 : _err$error.message) || JSON.stringify(err);\n};\nconst handleError$1 = async (error, reject, options) => {\n  if (error instanceof (await resolveResponse$1()) && !(options === null || options === void 0 ? void 0 : options.noResolveJson)) error.json().then(err => {\n    const status = error.status || 500;\n    const statusCode = (err === null || err === void 0 ? void 0 : err.statusCode) || status + \"\";\n    reject(new StorageApiError(_getErrorMessage$1(err), status, statusCode));\n  }).catch(err => {\n    reject(new StorageUnknownError(_getErrorMessage$1(err), err));\n  });else reject(new StorageUnknownError(_getErrorMessage$1(error), error));\n};\nconst _getRequestParams$1 = (method, options, parameters, body) => {\n  const params = {\n    method,\n    headers: (options === null || options === void 0 ? void 0 : options.headers) || {}\n  };\n  if (method === \"GET\" || !body) return params;\n  if (isPlainObject$1(body)) {\n    params.headers = _objectSpread2({\n      \"Content-Type\": \"application/json\"\n    }, options === null || options === void 0 ? void 0 : options.headers);\n    params.body = JSON.stringify(body);\n  } else params.body = body;\n  if (options === null || options === void 0 ? void 0 : options.duplex) params.duplex = options.duplex;\n  return _objectSpread2(_objectSpread2({}, params), parameters);\n};\nasync function _handleRequest$1(fetcher, method, url, options, parameters, body) {\n  return new Promise((resolve, reject) => {\n    fetcher(url, _getRequestParams$1(method, options, parameters, body)).then(result => {\n      if (!result.ok) throw result;\n      if (options === null || options === void 0 ? void 0 : options.noResolveJson) return result;\n      return result.json();\n    }).then(data => resolve(data)).catch(error => handleError$1(error, reject, options));\n  });\n}\nasync function get(fetcher, url, options, parameters) {\n  return _handleRequest$1(fetcher, \"GET\", url, options, parameters);\n}\nasync function post$1(fetcher, url, body, options, parameters) {\n  return _handleRequest$1(fetcher, \"POST\", url, options, parameters, body);\n}\nasync function put(fetcher, url, body, options, parameters) {\n  return _handleRequest$1(fetcher, \"PUT\", url, options, parameters, body);\n}\nasync function head(fetcher, url, options, parameters) {\n  return _handleRequest$1(fetcher, \"HEAD\", url, _objectSpread2(_objectSpread2({}, options), {}, {\n    noResolveJson: true\n  }), parameters);\n}\nasync function remove(fetcher, url, body, options, parameters) {\n  return _handleRequest$1(fetcher, \"DELETE\", url, options, parameters, body);\n}\n\n//#endregion\n//#region src/packages/StreamDownloadBuilder.ts\nvar StreamDownloadBuilder = class {\n  constructor(downloadFn, shouldThrowOnError) {\n    this.downloadFn = downloadFn;\n    this.shouldThrowOnError = shouldThrowOnError;\n  }\n  then(onfulfilled, onrejected) {\n    return this.execute().then(onfulfilled, onrejected);\n  }\n  async execute() {\n    var _this = this;\n    try {\n      return {\n        data: (await _this.downloadFn()).body,\n        error: null\n      };\n    } catch (error) {\n      if (_this.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n};\n\n//#endregion\n//#region src/packages/BlobDownloadBuilder.ts\nlet _Symbol$toStringTag;\n_Symbol$toStringTag = Symbol.toStringTag;\nvar BlobDownloadBuilder = class {\n  constructor(downloadFn, shouldThrowOnError) {\n    this.downloadFn = downloadFn;\n    this.shouldThrowOnError = shouldThrowOnError;\n    this[_Symbol$toStringTag] = \"BlobDownloadBuilder\";\n    this.promise = null;\n  }\n  asStream() {\n    return new StreamDownloadBuilder(this.downloadFn, this.shouldThrowOnError);\n  }\n  then(onfulfilled, onrejected) {\n    return this.getPromise().then(onfulfilled, onrejected);\n  }\n  catch(onrejected) {\n    return this.getPromise().catch(onrejected);\n  }\n  finally(onfinally) {\n    return this.getPromise().finally(onfinally);\n  }\n  getPromise() {\n    if (!this.promise) this.promise = this.execute();\n    return this.promise;\n  }\n  async execute() {\n    var _this = this;\n    try {\n      return {\n        data: await (await _this.downloadFn()).blob(),\n        error: null\n      };\n    } catch (error) {\n      if (_this.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n};\n\n//#endregion\n//#region src/packages/StorageFileApi.ts\nconst DEFAULT_SEARCH_OPTIONS = {\n  limit: 100,\n  offset: 0,\n  sortBy: {\n    column: \"name\",\n    order: \"asc\"\n  }\n};\nconst DEFAULT_FILE_OPTIONS = {\n  cacheControl: \"3600\",\n  contentType: \"text/plain;charset=UTF-8\",\n  upsert: false\n};\nvar StorageFileApi = class {\n  constructor(url) {\n    let headers = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let bucketId = arguments.length > 2 ? arguments[2] : undefined;\n    let fetch$1 = arguments.length > 3 ? arguments[3] : undefined;\n    this.shouldThrowOnError = false;\n    this.url = url;\n    this.headers = headers;\n    this.bucketId = bucketId;\n    this.fetch = resolveFetch$1(fetch$1);\n  }\n  /**\n  * Enable throwing errors instead of returning them.\n  *\n  * @category File Buckets\n  */\n  throwOnError() {\n    this.shouldThrowOnError = true;\n    return this;\n  }\n  /**\n  * Uploads a file to an existing bucket or replaces an existing file at the specified path with a new one.\n  *\n  * @param method HTTP method.\n  * @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n  * @param fileBody The body of the file to be stored in the bucket.\n  */\n  async uploadOrUpdate(method, path, fileBody, fileOptions) {\n    var _this = this;\n    try {\n      let body;\n      const options = _objectSpread2(_objectSpread2({}, DEFAULT_FILE_OPTIONS), fileOptions);\n      let headers = _objectSpread2(_objectSpread2({}, _this.headers), method === \"POST\" && {\n        \"x-upsert\": String(options.upsert)\n      });\n      const metadata = options.metadata;\n      if (typeof Blob !== \"undefined\" && fileBody instanceof Blob) {\n        body = new FormData();\n        body.append(\"cacheControl\", options.cacheControl);\n        if (metadata) body.append(\"metadata\", _this.encodeMetadata(metadata));\n        body.append(\"\", fileBody);\n      } else if (typeof FormData !== \"undefined\" && fileBody instanceof FormData) {\n        body = fileBody;\n        if (!body.has(\"cacheControl\")) body.append(\"cacheControl\", options.cacheControl);\n        if (metadata && !body.has(\"metadata\")) body.append(\"metadata\", _this.encodeMetadata(metadata));\n      } else {\n        body = fileBody;\n        headers[\"cache-control\"] = \"max-age=\".concat(options.cacheControl);\n        headers[\"content-type\"] = options.contentType;\n        if (metadata) headers[\"x-metadata\"] = _this.toBase64(_this.encodeMetadata(metadata));\n        if ((typeof ReadableStream !== \"undefined\" && body instanceof ReadableStream || body && typeof body === \"object\" && \"pipe\" in body && typeof body.pipe === \"function\") && !options.duplex) options.duplex = \"half\";\n      }\n      if (fileOptions === null || fileOptions === void 0 ? void 0 : fileOptions.headers) headers = _objectSpread2(_objectSpread2({}, headers), fileOptions.headers);\n      const cleanPath = _this._removeEmptyFolders(path);\n      const _path = _this._getFinalPath(cleanPath);\n      const data = await (method == \"PUT\" ? put : post$1)(_this.fetch, \"\".concat(_this.url, \"/object/\").concat(_path), body, _objectSpread2({\n        headers\n      }, (options === null || options === void 0 ? void 0 : options.duplex) ? {\n        duplex: options.duplex\n      } : {}));\n      return {\n        data: {\n          path: cleanPath,\n          id: data.Id,\n          fullPath: data.Key\n        },\n        error: null\n      };\n    } catch (error) {\n      if (_this.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /**\n  * Uploads a file to an existing bucket.\n  *\n  * @category File Buckets\n  * @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n  * @param fileBody The body of the file to be stored in the bucket.\n  * @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\n  * @returns Promise with response containing file path, id, and fullPath or error\n  *\n  * @example Upload file\n  * ```js\n  * const avatarFile = event.target.files[0]\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .upload('public/avatar1.png', avatarFile, {\n  *     cacheControl: '3600',\n  *     upsert: false\n  *   })\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"path\": \"public/avatar1.png\",\n  *     \"fullPath\": \"avatars/public/avatar1.png\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  *\n  * @example Upload file using `ArrayBuffer` from base64 file data\n  * ```js\n  * import { decode } from 'base64-arraybuffer'\n  *\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .upload('public/avatar1.png', decode('base64FileData'), {\n  *     contentType: 'image/png'\n  *   })\n  * ```\n  */\n  async upload(path, fileBody, fileOptions) {\n    return this.uploadOrUpdate(\"POST\", path, fileBody, fileOptions);\n  }\n  /**\n  * Upload a file with a token generated from `createSignedUploadUrl`.\n  *\n  * @category File Buckets\n  * @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n  * @param token The token generated from `createSignedUploadUrl`\n  * @param fileBody The body of the file to be stored in the bucket.\n  * @param fileOptions HTTP headers (cacheControl, contentType, etc.).\n  * **Note:** The `upsert` option has no effect here. To enable upsert behavior,\n  * pass `{ upsert: true }` when calling `createSignedUploadUrl()` instead.\n  * @returns Promise with response containing file path and fullPath or error\n  *\n  * @example Upload to a signed URL\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .uploadToSignedUrl('folder/cat.jpg', 'token-from-createSignedUploadUrl', file)\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"path\": \"folder/cat.jpg\",\n  *     \"fullPath\": \"avatars/folder/cat.jpg\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async uploadToSignedUrl(path, token, fileBody, fileOptions) {\n    var _this3 = this;\n    const cleanPath = _this3._removeEmptyFolders(path);\n    const _path = _this3._getFinalPath(cleanPath);\n    const url = new URL(_this3.url + \"/object/upload/sign/\".concat(_path));\n    url.searchParams.set(\"token\", token);\n    try {\n      let body;\n      const options = _objectSpread2({\n        upsert: DEFAULT_FILE_OPTIONS.upsert\n      }, fileOptions);\n      const headers = _objectSpread2(_objectSpread2({}, _this3.headers), {\n        \"x-upsert\": String(options.upsert)\n      });\n      if (typeof Blob !== \"undefined\" && fileBody instanceof Blob) {\n        body = new FormData();\n        body.append(\"cacheControl\", options.cacheControl);\n        body.append(\"\", fileBody);\n      } else if (typeof FormData !== \"undefined\" && fileBody instanceof FormData) {\n        body = fileBody;\n        body.append(\"cacheControl\", options.cacheControl);\n      } else {\n        body = fileBody;\n        headers[\"cache-control\"] = \"max-age=\".concat(options.cacheControl);\n        headers[\"content-type\"] = options.contentType;\n      }\n      return {\n        data: {\n          path: cleanPath,\n          fullPath: (await put(_this3.fetch, url.toString(), body, {\n            headers\n          })).Key\n        },\n        error: null\n      };\n    } catch (error) {\n      if (_this3.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /**\n  * Creates a signed upload URL.\n  * Signed upload URLs can be used to upload files to the bucket without further authentication.\n  * They are valid for 2 hours.\n  *\n  * @category File Buckets\n  * @param path The file path, including the current file name. For example `folder/image.png`.\n  * @param options.upsert If set to true, allows the file to be overwritten if it already exists.\n  * @returns Promise with response containing signed upload URL, token, and path or error\n  *\n  * @example Create Signed Upload URL\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .createSignedUploadUrl('folder/cat.jpg')\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"signedUrl\": \"https://example.supabase.co/storage/v1/object/upload/sign/avatars/folder/cat.jpg?token=<TOKEN>\",\n  *     \"path\": \"folder/cat.jpg\",\n  *     \"token\": \"<TOKEN>\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async createSignedUploadUrl(path, options) {\n    var _this4 = this;\n    try {\n      let _path = _this4._getFinalPath(path);\n      const headers = _objectSpread2({}, _this4.headers);\n      if (options === null || options === void 0 ? void 0 : options.upsert) headers[\"x-upsert\"] = \"true\";\n      const data = await post$1(_this4.fetch, \"\".concat(_this4.url, \"/object/upload/sign/\").concat(_path), {}, {\n        headers\n      });\n      const url = new URL(_this4.url + data.url);\n      const token = url.searchParams.get(\"token\");\n      if (!token) throw new StorageError(\"No token returned by API\");\n      return {\n        data: {\n          signedUrl: url.toString(),\n          path,\n          token\n        },\n        error: null\n      };\n    } catch (error) {\n      if (_this4.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /**\n  * Replaces an existing file at the specified path with a new one.\n  *\n  * @category File Buckets\n  * @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to update.\n  * @param fileBody The body of the file to be stored in the bucket.\n  * @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\n  * @returns Promise with response containing file path, id, and fullPath or error\n  *\n  * @example Update file\n  * ```js\n  * const avatarFile = event.target.files[0]\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .update('public/avatar1.png', avatarFile, {\n  *     cacheControl: '3600',\n  *     upsert: true\n  *   })\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"path\": \"public/avatar1.png\",\n  *     \"fullPath\": \"avatars/public/avatar1.png\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  *\n  * @example Update file using `ArrayBuffer` from base64 file data\n  * ```js\n  * import {decode} from 'base64-arraybuffer'\n  *\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .update('public/avatar1.png', decode('base64FileData'), {\n  *     contentType: 'image/png'\n  *   })\n  * ```\n  */\n  async update(path, fileBody, fileOptions) {\n    return this.uploadOrUpdate(\"PUT\", path, fileBody, fileOptions);\n  }\n  /**\n  * Moves an existing file to a new path in the same bucket.\n  *\n  * @category File Buckets\n  * @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n  * @param toPath The new file path, including the new file name. For example `folder/image-new.png`.\n  * @param options The destination options.\n  * @returns Promise with response containing success message or error\n  *\n  * @example Move file\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .move('public/avatar1.png', 'private/avatar2.png')\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"message\": \"Successfully moved\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async move(fromPath, toPath, options) {\n    var _this6 = this;\n    try {\n      return {\n        data: await post$1(_this6.fetch, \"\".concat(_this6.url, \"/object/move\"), {\n          bucketId: _this6.bucketId,\n          sourceKey: fromPath,\n          destinationKey: toPath,\n          destinationBucket: options === null || options === void 0 ? void 0 : options.destinationBucket\n        }, {\n          headers: _this6.headers\n        }),\n        error: null\n      };\n    } catch (error) {\n      if (_this6.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /**\n  * Copies an existing file to a new path in the same bucket.\n  *\n  * @category File Buckets\n  * @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n  * @param toPath The new file path, including the new file name. For example `folder/image-copy.png`.\n  * @param options The destination options.\n  * @returns Promise with response containing copied file path or error\n  *\n  * @example Copy file\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .copy('public/avatar1.png', 'private/avatar2.png')\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"path\": \"avatars/private/avatar2.png\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async copy(fromPath, toPath, options) {\n    var _this7 = this;\n    try {\n      return {\n        data: {\n          path: (await post$1(_this7.fetch, \"\".concat(_this7.url, \"/object/copy\"), {\n            bucketId: _this7.bucketId,\n            sourceKey: fromPath,\n            destinationKey: toPath,\n            destinationBucket: options === null || options === void 0 ? void 0 : options.destinationBucket\n          }, {\n            headers: _this7.headers\n          })).Key\n        },\n        error: null\n      };\n    } catch (error) {\n      if (_this7.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /**\n  * Creates a signed URL. Use a signed URL to share a file for a fixed amount of time.\n  *\n  * @category File Buckets\n  * @param path The file path, including the current file name. For example `folder/image.png`.\n  * @param expiresIn The number of seconds until the signed URL expires. For example, `60` for a URL which is valid for one minute.\n  * @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n  * @param options.transform Transform the asset before serving it to the client.\n  * @returns Promise with response containing signed URL or error\n  *\n  * @example Create Signed URL\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .createSignedUrl('folder/avatar1.png', 60)\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  *\n  * @example Create a signed URL for an asset with transformations\n  * ```js\n  * const { data } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .createSignedUrl('folder/avatar1.png', 60, {\n  *     transform: {\n  *       width: 100,\n  *       height: 100,\n  *     }\n  *   })\n  * ```\n  *\n  * @example Create a signed URL which triggers the download of the asset\n  * ```js\n  * const { data } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .createSignedUrl('folder/avatar1.png', 60, {\n  *     download: true,\n  *   })\n  * ```\n  */\n  async createSignedUrl(path, expiresIn, options) {\n    var _this8 = this;\n    try {\n      let _path = _this8._getFinalPath(path);\n      let data = await post$1(_this8.fetch, \"\".concat(_this8.url, \"/object/sign/\").concat(_path), _objectSpread2({\n        expiresIn\n      }, (options === null || options === void 0 ? void 0 : options.transform) ? {\n        transform: options.transform\n      } : {}), {\n        headers: _this8.headers\n      });\n      const downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download) ? \"&download=\".concat(options.download === true ? \"\" : options.download) : \"\";\n      data = {\n        signedUrl: encodeURI(\"\".concat(_this8.url).concat(data.signedURL).concat(downloadQueryParam))\n      };\n      return {\n        data,\n        error: null\n      };\n    } catch (error) {\n      if (_this8.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /**\n  * Creates multiple signed URLs. Use a signed URL to share a file for a fixed amount of time.\n  *\n  * @category File Buckets\n  * @param paths The file paths to be downloaded, including the current file names. For example `['folder/image.png', 'folder2/image2.png']`.\n  * @param expiresIn The number of seconds until the signed URLs expire. For example, `60` for URLs which are valid for one minute.\n  * @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n  * @returns Promise with response containing array of objects with signedUrl, path, and error or error\n  *\n  * @example Create Signed URLs\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .createSignedUrls(['folder/avatar1.png', 'folder/avatar2.png'], 60)\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": [\n  *     {\n  *       \"error\": null,\n  *       \"path\": \"folder/avatar1.png\",\n  *       \"signedURL\": \"/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\",\n  *       \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\"\n  *     },\n  *     {\n  *       \"error\": null,\n  *       \"path\": \"folder/avatar2.png\",\n  *       \"signedURL\": \"/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\",\n  *       \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\"\n  *     }\n  *   ],\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async createSignedUrls(paths, expiresIn, options) {\n    var _this9 = this;\n    try {\n      const data = await post$1(_this9.fetch, \"\".concat(_this9.url, \"/object/sign/\").concat(_this9.bucketId), {\n        expiresIn,\n        paths\n      }, {\n        headers: _this9.headers\n      });\n      const downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download) ? \"&download=\".concat(options.download === true ? \"\" : options.download) : \"\";\n      return {\n        data: data.map(datum => _objectSpread2(_objectSpread2({}, datum), {}, {\n          signedUrl: datum.signedURL ? encodeURI(\"\".concat(_this9.url).concat(datum.signedURL).concat(downloadQueryParam)) : null\n        })),\n        error: null\n      };\n    } catch (error) {\n      if (_this9.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /**\n  * Downloads a file from a private bucket. For public buckets, make a request to the URL returned from `getPublicUrl` instead.\n  *\n  * @category File Buckets\n  * @param path The full path and file name of the file to be downloaded. For example `folder/image.png`.\n  * @param options.transform Transform the asset before serving it to the client.\n  * @returns BlobDownloadBuilder instance for downloading the file\n  *\n  * @example Download file\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .download('folder/avatar1.png')\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": <BLOB>,\n  *   \"error\": null\n  * }\n  * ```\n  *\n  * @example Download file with transformations\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .download('folder/avatar1.png', {\n  *     transform: {\n  *       width: 100,\n  *       height: 100,\n  *       quality: 80\n  *     }\n  *   })\n  * ```\n  */\n  download(path, options) {\n    const renderPath = typeof (options === null || options === void 0 ? void 0 : options.transform) !== \"undefined\" ? \"render/image/authenticated\" : \"object\";\n    const transformationQuery = this.transformOptsToQueryString((options === null || options === void 0 ? void 0 : options.transform) || {});\n    const queryString = transformationQuery ? \"?\".concat(transformationQuery) : \"\";\n    const _path = this._getFinalPath(path);\n    const downloadFn = () => get(this.fetch, \"\".concat(this.url, \"/\").concat(renderPath, \"/\").concat(_path).concat(queryString), {\n      headers: this.headers,\n      noResolveJson: true\n    });\n    return new BlobDownloadBuilder(downloadFn, this.shouldThrowOnError);\n  }\n  /**\n  * Retrieves the details of an existing file.\n  *\n  * @category File Buckets\n  * @param path The file path, including the file name. For example `folder/image.png`.\n  * @returns Promise with response containing file metadata or error\n  *\n  * @example Get file info\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .info('folder/avatar1.png')\n  * ```\n  */\n  async info(path) {\n    var _this10 = this;\n    const _path = _this10._getFinalPath(path);\n    try {\n      return {\n        data: recursiveToCamel(await get(_this10.fetch, \"\".concat(_this10.url, \"/object/info/\").concat(_path), {\n          headers: _this10.headers\n        })),\n        error: null\n      };\n    } catch (error) {\n      if (_this10.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /**\n  * Checks the existence of a file.\n  *\n  * @category File Buckets\n  * @param path The file path, including the file name. For example `folder/image.png`.\n  * @returns Promise with response containing boolean indicating file existence or error\n  *\n  * @example Check file existence\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .exists('folder/avatar1.png')\n  * ```\n  */\n  async exists(path) {\n    var _this11 = this;\n    const _path = _this11._getFinalPath(path);\n    try {\n      await head(_this11.fetch, \"\".concat(_this11.url, \"/object/\").concat(_path), {\n        headers: _this11.headers\n      });\n      return {\n        data: true,\n        error: null\n      };\n    } catch (error) {\n      if (_this11.shouldThrowOnError) throw error;\n      if (isStorageError(error) && error instanceof StorageUnknownError) {\n        const originalError = error.originalError;\n        if ([400, 404].includes(originalError === null || originalError === void 0 ? void 0 : originalError.status)) return {\n          data: false,\n          error\n        };\n      }\n      throw error;\n    }\n  }\n  /**\n  * A simple convenience function to get the URL for an asset in a public bucket. If you do not want to use this function, you can construct the public URL by concatenating the bucket URL with the path to the asset.\n  * This function does not verify if the bucket is public. If a public URL is created for a bucket which is not public, you will not be able to download the asset.\n  *\n  * @category File Buckets\n  * @param path The path and name of the file to generate the public URL for. For example `folder/image.png`.\n  * @param options.download Triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n  * @param options.transform Transform the asset before serving it to the client.\n  * @returns Object with public URL\n  *\n  * @example Returns the URL for an asset in a public bucket\n  * ```js\n  * const { data } = supabase\n  *   .storage\n  *   .from('public-bucket')\n  *   .getPublicUrl('folder/avatar1.png')\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"publicUrl\": \"https://example.supabase.co/storage/v1/object/public/public-bucket/folder/avatar1.png\"\n  *   }\n  * }\n  * ```\n  *\n  * @example Returns the URL for an asset in a public bucket with transformations\n  * ```js\n  * const { data } = supabase\n  *   .storage\n  *   .from('public-bucket')\n  *   .getPublicUrl('folder/avatar1.png', {\n  *     transform: {\n  *       width: 100,\n  *       height: 100,\n  *     }\n  *   })\n  * ```\n  *\n  * @example Returns the URL which triggers the download of an asset in a public bucket\n  * ```js\n  * const { data } = supabase\n  *   .storage\n  *   .from('public-bucket')\n  *   .getPublicUrl('folder/avatar1.png', {\n  *     download: true,\n  *   })\n  * ```\n  */\n  getPublicUrl(path, options) {\n    const _path = this._getFinalPath(path);\n    const _queryString = [];\n    const downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download) ? \"download=\".concat(options.download === true ? \"\" : options.download) : \"\";\n    if (downloadQueryParam !== \"\") _queryString.push(downloadQueryParam);\n    const renderPath = typeof (options === null || options === void 0 ? void 0 : options.transform) !== \"undefined\" ? \"render/image\" : \"object\";\n    const transformationQuery = this.transformOptsToQueryString((options === null || options === void 0 ? void 0 : options.transform) || {});\n    if (transformationQuery !== \"\") _queryString.push(transformationQuery);\n    let queryString = _queryString.join(\"&\");\n    if (queryString !== \"\") queryString = \"?\".concat(queryString);\n    return {\n      data: {\n        publicUrl: encodeURI(\"\".concat(this.url, \"/\").concat(renderPath, \"/public/\").concat(_path).concat(queryString))\n      }\n    };\n  }\n  /**\n  * Deletes files within the same bucket\n  *\n  * @category File Buckets\n  * @param paths An array of files to delete, including the path and file name. For example [`'folder/image.png'`].\n  * @returns Promise with response containing array of deleted file objects or error\n  *\n  * @example Delete file\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .remove(['folder/avatar1.png'])\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": [],\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async remove(paths) {\n    var _this12 = this;\n    try {\n      return {\n        data: await remove(_this12.fetch, \"\".concat(_this12.url, \"/object/\").concat(_this12.bucketId), {\n          prefixes: paths\n        }, {\n          headers: _this12.headers\n        }),\n        error: null\n      };\n    } catch (error) {\n      if (_this12.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /**\n  * Get file metadata\n  * @param id the file id to retrieve metadata\n  */\n  /**\n  * Update file metadata\n  * @param id the file id to update metadata\n  * @param meta the new file metadata\n  */\n  /**\n  * Lists all the files and folders within a path of the bucket.\n  *\n  * @category File Buckets\n  * @param path The folder path.\n  * @param options Search options including limit (defaults to 100), offset, sortBy, and search\n  * @param parameters Optional fetch parameters including signal for cancellation\n  * @returns Promise with response containing array of files or error\n  *\n  * @example List files in a bucket\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .list('folder', {\n  *     limit: 100,\n  *     offset: 0,\n  *     sortBy: { column: 'name', order: 'asc' },\n  *   })\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": [\n  *     {\n  *       \"name\": \"avatar1.png\",\n  *       \"id\": \"e668cf7f-821b-4a2f-9dce-7dfa5dd1cfd2\",\n  *       \"updated_at\": \"2024-05-22T23:06:05.580Z\",\n  *       \"created_at\": \"2024-05-22T23:04:34.443Z\",\n  *       \"last_accessed_at\": \"2024-05-22T23:04:34.443Z\",\n  *       \"metadata\": {\n  *         \"eTag\": \"\\\"c5e8c553235d9af30ef4f6e280790b92\\\"\",\n  *         \"size\": 32175,\n  *         \"mimetype\": \"image/png\",\n  *         \"cacheControl\": \"max-age=3600\",\n  *         \"lastModified\": \"2024-05-22T23:06:05.574Z\",\n  *         \"contentLength\": 32175,\n  *         \"httpStatusCode\": 200\n  *       }\n  *     }\n  *   ],\n  *   \"error\": null\n  * }\n  * ```\n  *\n  * @example Search files in a bucket\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .list('folder', {\n  *     limit: 100,\n  *     offset: 0,\n  *     sortBy: { column: 'name', order: 'asc' },\n  *     search: 'jon'\n  *   })\n  * ```\n  */\n  async list(path, options, parameters) {\n    var _this13 = this;\n    try {\n      const body = _objectSpread2(_objectSpread2(_objectSpread2({}, DEFAULT_SEARCH_OPTIONS), options), {}, {\n        prefix: path || \"\"\n      });\n      return {\n        data: await post$1(_this13.fetch, \"\".concat(_this13.url, \"/object/list/\").concat(_this13.bucketId), body, {\n          headers: _this13.headers\n        }, parameters),\n        error: null\n      };\n    } catch (error) {\n      if (_this13.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /**\n  * @experimental this method signature might change in the future\n  *\n  * @category File Buckets\n  * @param options search options\n  * @param parameters\n  */\n  async listV2(options, parameters) {\n    var _this14 = this;\n    try {\n      const body = _objectSpread2({}, options);\n      return {\n        data: await post$1(_this14.fetch, \"\".concat(_this14.url, \"/object/list-v2/\").concat(_this14.bucketId), body, {\n          headers: _this14.headers\n        }, parameters),\n        error: null\n      };\n    } catch (error) {\n      if (_this14.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  encodeMetadata(metadata) {\n    return JSON.stringify(metadata);\n  }\n  toBase64(data) {\n    if (typeof Buffer !== \"undefined\") return Buffer.from(data).toString(\"base64\");\n    return btoa(data);\n  }\n  _getFinalPath(path) {\n    return \"\".concat(this.bucketId, \"/\").concat(path.replace(/^\\/+/, \"\"));\n  }\n  _removeEmptyFolders(path) {\n    return path.replace(/^\\/|\\/$/g, \"\").replace(/\\/+/g, \"/\");\n  }\n  transformOptsToQueryString(transform) {\n    const params = [];\n    if (transform.width) params.push(\"width=\".concat(transform.width));\n    if (transform.height) params.push(\"height=\".concat(transform.height));\n    if (transform.resize) params.push(\"resize=\".concat(transform.resize));\n    if (transform.format) params.push(\"format=\".concat(transform.format));\n    if (transform.quality) params.push(\"quality=\".concat(transform.quality));\n    return params.join(\"&\");\n  }\n};\n\n//#endregion\n//#region src/lib/version.ts\nconst version = \"2.90.1\";\n\n//#endregion\n//#region src/lib/constants.ts\nconst DEFAULT_HEADERS$1 = {\n  \"X-Client-Info\": \"storage-js/\".concat(version)\n};\n\n//#endregion\n//#region src/packages/StorageBucketApi.ts\nvar StorageBucketApi = class {\n  constructor(url) {\n    let headers = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let fetch$1 = arguments.length > 2 ? arguments[2] : undefined;\n    let opts = arguments.length > 3 ? arguments[3] : undefined;\n    this.shouldThrowOnError = false;\n    const baseUrl = new URL(url);\n    if (opts === null || opts === void 0 ? void 0 : opts.useNewHostname) {\n      if (/supabase\\.(co|in|red)$/.test(baseUrl.hostname) && !baseUrl.hostname.includes(\"storage.supabase.\")) baseUrl.hostname = baseUrl.hostname.replace(\"supabase.\", \"storage.supabase.\");\n    }\n    this.url = baseUrl.href.replace(/\\/$/, \"\");\n    this.headers = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS$1), headers);\n    this.fetch = resolveFetch$1(fetch$1);\n  }\n  /**\n  * Enable throwing errors instead of returning them.\n  *\n  * @category File Buckets\n  */\n  throwOnError() {\n    this.shouldThrowOnError = true;\n    return this;\n  }\n  /**\n  * Retrieves the details of all Storage buckets within an existing project.\n  *\n  * @category File Buckets\n  * @param options Query parameters for listing buckets\n  * @param options.limit Maximum number of buckets to return\n  * @param options.offset Number of buckets to skip\n  * @param options.sortColumn Column to sort by ('id', 'name', 'created_at', 'updated_at')\n  * @param options.sortOrder Sort order ('asc' or 'desc')\n  * @param options.search Search term to filter bucket names\n  * @returns Promise with response containing array of buckets or error\n  *\n  * @example List buckets\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .listBuckets()\n  * ```\n  *\n  * @example List buckets with options\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .listBuckets({\n  *     limit: 10,\n  *     offset: 0,\n  *     sortColumn: 'created_at',\n  *     sortOrder: 'desc',\n  *     search: 'prod'\n  *   })\n  * ```\n  */\n  async listBuckets(options) {\n    var _this = this;\n    try {\n      const queryString = _this.listBucketOptionsToQueryString(options);\n      return {\n        data: await get(_this.fetch, \"\".concat(_this.url, \"/bucket\").concat(queryString), {\n          headers: _this.headers\n        }),\n        error: null\n      };\n    } catch (error) {\n      if (_this.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /**\n  * Retrieves the details of an existing Storage bucket.\n  *\n  * @category File Buckets\n  * @param id The unique identifier of the bucket you would like to retrieve.\n  * @returns Promise with response containing bucket details or error\n  *\n  * @example Get bucket\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .getBucket('avatars')\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"id\": \"avatars\",\n  *     \"name\": \"avatars\",\n  *     \"owner\": \"\",\n  *     \"public\": false,\n  *     \"file_size_limit\": 1024,\n  *     \"allowed_mime_types\": [\n  *       \"image/png\"\n  *     ],\n  *     \"created_at\": \"2024-05-22T22:26:05.100Z\",\n  *     \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async getBucket(id) {\n    var _this2 = this;\n    try {\n      return {\n        data: await get(_this2.fetch, \"\".concat(_this2.url, \"/bucket/\").concat(id), {\n          headers: _this2.headers\n        }),\n        error: null\n      };\n    } catch (error) {\n      if (_this2.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /**\n  * Creates a new Storage bucket\n  *\n  * @category File Buckets\n  * @param id A unique identifier for the bucket you are creating.\n  * @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations. By default, buckets are private.\n  * @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n  * The global file size limit takes precedence over this value.\n  * The default value is null, which doesn't set a per bucket file size limit.\n  * @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n  * The default value is null, which allows files with all mime types to be uploaded.\n  * Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n  * @param options.type (private-beta) specifies the bucket type. see `BucketType` for more details.\n  *   - default bucket type is `STANDARD`\n  * @returns Promise with response containing newly created bucket name or error\n  *\n  * @example Create bucket\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .createBucket('avatars', {\n  *     public: false,\n  *     allowedMimeTypes: ['image/png'],\n  *     fileSizeLimit: 1024\n  *   })\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"name\": \"avatars\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async createBucket(id) {\n    let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {\n      public: false\n    };\n    var _this3 = this;\n    try {\n      return {\n        data: await post$1(_this3.fetch, \"\".concat(_this3.url, \"/bucket\"), {\n          id,\n          name: id,\n          type: options.type,\n          public: options.public,\n          file_size_limit: options.fileSizeLimit,\n          allowed_mime_types: options.allowedMimeTypes\n        }, {\n          headers: _this3.headers\n        }),\n        error: null\n      };\n    } catch (error) {\n      if (_this3.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /**\n  * Updates a Storage bucket\n  *\n  * @category File Buckets\n  * @param id A unique identifier for the bucket you are updating.\n  * @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations.\n  * @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n  * The global file size limit takes precedence over this value.\n  * The default value is null, which doesn't set a per bucket file size limit.\n  * @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n  * The default value is null, which allows files with all mime types to be uploaded.\n  * Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n  * @returns Promise with response containing success message or error\n  *\n  * @example Update bucket\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .updateBucket('avatars', {\n  *     public: false,\n  *     allowedMimeTypes: ['image/png'],\n  *     fileSizeLimit: 1024\n  *   })\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"message\": \"Successfully updated\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async updateBucket(id, options) {\n    var _this4 = this;\n    try {\n      return {\n        data: await put(_this4.fetch, \"\".concat(_this4.url, \"/bucket/\").concat(id), {\n          id,\n          name: id,\n          public: options.public,\n          file_size_limit: options.fileSizeLimit,\n          allowed_mime_types: options.allowedMimeTypes\n        }, {\n          headers: _this4.headers\n        }),\n        error: null\n      };\n    } catch (error) {\n      if (_this4.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /**\n  * Removes all objects inside a single bucket.\n  *\n  * @category File Buckets\n  * @param id The unique identifier of the bucket you would like to empty.\n  * @returns Promise with success message or error\n  *\n  * @example Empty bucket\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .emptyBucket('avatars')\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"message\": \"Successfully emptied\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async emptyBucket(id) {\n    var _this5 = this;\n    try {\n      return {\n        data: await post$1(_this5.fetch, \"\".concat(_this5.url, \"/bucket/\").concat(id, \"/empty\"), {}, {\n          headers: _this5.headers\n        }),\n        error: null\n      };\n    } catch (error) {\n      if (_this5.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /**\n  * Deletes an existing bucket. A bucket can't be deleted with existing objects inside it.\n  * You must first `empty()` the bucket.\n  *\n  * @category File Buckets\n  * @param id The unique identifier of the bucket you would like to delete.\n  * @returns Promise with success message or error\n  *\n  * @example Delete bucket\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .deleteBucket('avatars')\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"message\": \"Successfully deleted\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async deleteBucket(id) {\n    var _this6 = this;\n    try {\n      return {\n        data: await remove(_this6.fetch, \"\".concat(_this6.url, \"/bucket/\").concat(id), {}, {\n          headers: _this6.headers\n        }),\n        error: null\n      };\n    } catch (error) {\n      if (_this6.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  listBucketOptionsToQueryString(options) {\n    const params = {};\n    if (options) {\n      if (\"limit\" in options) params.limit = String(options.limit);\n      if (\"offset\" in options) params.offset = String(options.offset);\n      if (options.search) params.search = options.search;\n      if (options.sortColumn) params.sortColumn = options.sortColumn;\n      if (options.sortOrder) params.sortOrder = options.sortOrder;\n    }\n    return Object.keys(params).length > 0 ? \"?\" + new URLSearchParams(params).toString() : \"\";\n  }\n};\n\n//#endregion\n//#region src/packages/StorageAnalyticsClient.ts\n/**\n* Client class for managing Analytics Buckets using Iceberg tables\n* Provides methods for creating, listing, and deleting analytics buckets\n*/\nvar StorageAnalyticsClient = class {\n  /**\n  * @alpha\n  *\n  * Creates a new StorageAnalyticsClient instance\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Analytics Buckets\n  * @param url - The base URL for the storage API\n  * @param headers - HTTP headers to include in requests\n  * @param fetch - Optional custom fetch implementation\n  *\n  * @example\n  * ```typescript\n  * const client = new StorageAnalyticsClient(url, headers)\n  * ```\n  */\n  constructor(url) {\n    let headers = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let fetch$1 = arguments.length > 2 ? arguments[2] : undefined;\n    this.shouldThrowOnError = false;\n    this.url = url.replace(/\\/$/, \"\");\n    this.headers = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS$1), headers);\n    this.fetch = resolveFetch$1(fetch$1);\n  }\n  /**\n  * @alpha\n  *\n  * Enable throwing errors instead of returning them in the response\n  * When enabled, failed operations will throw instead of returning { data: null, error }\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Analytics Buckets\n  * @returns This instance for method chaining\n  */\n  throwOnError() {\n    this.shouldThrowOnError = true;\n    return this;\n  }\n  /**\n  * @alpha\n  *\n  * Creates a new analytics bucket using Iceberg tables\n  * Analytics buckets are optimized for analytical queries and data processing\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Analytics Buckets\n  * @param name A unique name for the bucket you are creating\n  * @returns Promise with response containing newly created analytics bucket or error\n  *\n  * @example Create analytics bucket\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .analytics\n  *   .createBucket('analytics-data')\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"name\": \"analytics-data\",\n  *     \"type\": \"ANALYTICS\",\n  *     \"format\": \"iceberg\",\n  *     \"created_at\": \"2024-05-22T22:26:05.100Z\",\n  *     \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async createBucket(name) {\n    var _this = this;\n    try {\n      return {\n        data: await post$1(_this.fetch, \"\".concat(_this.url, \"/bucket\"), {\n          name\n        }, {\n          headers: _this.headers\n        }),\n        error: null\n      };\n    } catch (error) {\n      if (_this.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /**\n  * @alpha\n  *\n  * Retrieves the details of all Analytics Storage buckets within an existing project\n  * Only returns buckets of type 'ANALYTICS'\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Analytics Buckets\n  * @param options Query parameters for listing buckets\n  * @param options.limit Maximum number of buckets to return\n  * @param options.offset Number of buckets to skip\n  * @param options.sortColumn Column to sort by ('name', 'created_at', 'updated_at')\n  * @param options.sortOrder Sort order ('asc' or 'desc')\n  * @param options.search Search term to filter bucket names\n  * @returns Promise with response containing array of analytics buckets or error\n  *\n  * @example List analytics buckets\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .analytics\n  *   .listBuckets({\n  *     limit: 10,\n  *     offset: 0,\n  *     sortColumn: 'created_at',\n  *     sortOrder: 'desc'\n  *   })\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": [\n  *     {\n  *       \"name\": \"analytics-data\",\n  *       \"type\": \"ANALYTICS\",\n  *       \"format\": \"iceberg\",\n  *       \"created_at\": \"2024-05-22T22:26:05.100Z\",\n  *       \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n  *     }\n  *   ],\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async listBuckets(options) {\n    var _this2 = this;\n    try {\n      const queryParams = new URLSearchParams();\n      if ((options === null || options === void 0 ? void 0 : options.limit) !== void 0) queryParams.set(\"limit\", options.limit.toString());\n      if ((options === null || options === void 0 ? void 0 : options.offset) !== void 0) queryParams.set(\"offset\", options.offset.toString());\n      if (options === null || options === void 0 ? void 0 : options.sortColumn) queryParams.set(\"sortColumn\", options.sortColumn);\n      if (options === null || options === void 0 ? void 0 : options.sortOrder) queryParams.set(\"sortOrder\", options.sortOrder);\n      if (options === null || options === void 0 ? void 0 : options.search) queryParams.set(\"search\", options.search);\n      const queryString = queryParams.toString();\n      const url = queryString ? \"\".concat(_this2.url, \"/bucket?\").concat(queryString) : \"\".concat(_this2.url, \"/bucket\");\n      return {\n        data: await get(_this2.fetch, url, {\n          headers: _this2.headers\n        }),\n        error: null\n      };\n    } catch (error) {\n      if (_this2.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /**\n  * @alpha\n  *\n  * Deletes an existing analytics bucket\n  * A bucket can't be deleted with existing objects inside it\n  * You must first empty the bucket before deletion\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Analytics Buckets\n  * @param bucketName The unique identifier of the bucket you would like to delete\n  * @returns Promise with response containing success message or error\n  *\n  * @example Delete analytics bucket\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .analytics\n  *   .deleteBucket('analytics-data')\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"message\": \"Successfully deleted\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async deleteBucket(bucketName) {\n    var _this3 = this;\n    try {\n      return {\n        data: await remove(_this3.fetch, \"\".concat(_this3.url, \"/bucket/\").concat(bucketName), {}, {\n          headers: _this3.headers\n        }),\n        error: null\n      };\n    } catch (error) {\n      if (_this3.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /**\n  * @alpha\n  *\n  * Get an Iceberg REST Catalog client configured for a specific analytics bucket\n  * Use this to perform advanced table and namespace operations within the bucket\n  * The returned client provides full access to the Apache Iceberg REST Catalog API\n  * with the Supabase `{ data, error }` pattern for consistent error handling on all operations.\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Analytics Buckets\n  * @param bucketName - The name of the analytics bucket (warehouse) to connect to\n  * @returns The wrapped Iceberg catalog client\n  * @throws {StorageError} If the bucket name is invalid\n  *\n  * @example Get catalog and create table\n  * ```js\n  * // First, create an analytics bucket\n  * const { data: bucket, error: bucketError } = await supabase\n  *   .storage\n  *   .analytics\n  *   .createBucket('analytics-data')\n  *\n  * // Get the Iceberg catalog for that bucket\n  * const catalog = supabase.storage.analytics.from('analytics-data')\n  *\n  * // Create a namespace\n  * const { error: nsError } = await catalog.createNamespace({ namespace: ['default'] })\n  *\n  * // Create a table with schema\n  * const { data: tableMetadata, error: tableError } = await catalog.createTable(\n  *   { namespace: ['default'] },\n  *   {\n  *     name: 'events',\n  *     schema: {\n  *       type: 'struct',\n  *       fields: [\n  *         { id: 1, name: 'id', type: 'long', required: true },\n  *         { id: 2, name: 'timestamp', type: 'timestamp', required: true },\n  *         { id: 3, name: 'user_id', type: 'string', required: false }\n  *       ],\n  *       'schema-id': 0,\n  *       'identifier-field-ids': [1]\n  *     },\n  *     'partition-spec': {\n  *       'spec-id': 0,\n  *       fields: []\n  *     },\n  *     'write-order': {\n  *       'order-id': 0,\n  *       fields: []\n  *     },\n  *     properties: {\n  *       'write.format.default': 'parquet'\n  *     }\n  *   }\n  * )\n  * ```\n  *\n  * @example List tables in namespace\n  * ```js\n  * const catalog = supabase.storage.analytics.from('analytics-data')\n  *\n  * // List all tables in the default namespace\n  * const { data: tables, error: listError } = await catalog.listTables({ namespace: ['default'] })\n  * if (listError) {\n  *   if (listError.isNotFound()) {\n  *     console.log('Namespace not found')\n  *   }\n  *   return\n  * }\n  * console.log(tables) // [{ namespace: ['default'], name: 'events' }]\n  * ```\n  *\n  * @example Working with namespaces\n  * ```js\n  * const catalog = supabase.storage.analytics.from('analytics-data')\n  *\n  * // List all namespaces\n  * const { data: namespaces } = await catalog.listNamespaces()\n  *\n  * // Create namespace with properties\n  * await catalog.createNamespace(\n  *   { namespace: ['production'] },\n  *   { properties: { owner: 'data-team', env: 'prod' } }\n  * )\n  * ```\n  *\n  * @example Cleanup operations\n  * ```js\n  * const catalog = supabase.storage.analytics.from('analytics-data')\n  *\n  * // Drop table with purge option (removes all data)\n  * const { error: dropError } = await catalog.dropTable(\n  *   { namespace: ['default'], name: 'events' },\n  *   { purge: true }\n  * )\n  *\n  * if (dropError?.isNotFound()) {\n  *   console.log('Table does not exist')\n  * }\n  *\n  * // Drop namespace (must be empty)\n  * await catalog.dropNamespace({ namespace: ['default'] })\n  * ```\n  *\n  * @remarks\n  * This method provides a bridge between Supabase's bucket management and the standard\n  * Apache Iceberg REST Catalog API. The bucket name maps to the Iceberg warehouse parameter.\n  * All authentication and configuration is handled automatically using your Supabase credentials.\n  *\n  * **Error Handling**: Invalid bucket names throw immediately. All catalog\n  * operations return `{ data, error }` where errors are `IcebergError` instances from iceberg-js.\n  * Use helper methods like `error.isNotFound()` or check `error.status` for specific error handling.\n  * Use `.throwOnError()` on the analytics client if you prefer exceptions for catalog operations.\n  *\n  * **Cleanup Operations**: When using `dropTable`, the `purge: true` option permanently\n  * deletes all table data. Without it, the table is marked as deleted but data remains.\n  *\n  * **Library Dependency**: The returned catalog wraps `IcebergRestCatalog` from iceberg-js.\n  * For complete API documentation and advanced usage, refer to the\n  * [iceberg-js documentation](https://supabase.github.io/iceberg-js/).\n  */\n  from(bucketName) {\n    var _this4 = this;\n    if (!isValidBucketName(bucketName)) throw new StorageError(\"Invalid bucket name: File, folder, and bucket names must follow AWS object key naming guidelines and should avoid the use of any other characters.\");\n    const catalog = new IcebergRestCatalog({\n      baseUrl: this.url,\n      catalogName: bucketName,\n      auth: {\n        type: \"custom\",\n        getHeaders: async () => _this4.headers\n      },\n      fetch: this.fetch\n    });\n    const shouldThrowOnError = this.shouldThrowOnError;\n    return new Proxy(catalog, {\n      get(target, prop) {\n        const value = target[prop];\n        if (typeof value !== \"function\") return value;\n        return async function () {\n          try {\n            for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n              args[_key] = arguments[_key];\n            }\n            return {\n              data: await value.apply(target, args),\n              error: null\n            };\n          } catch (error) {\n            if (shouldThrowOnError) throw error;\n            return {\n              data: null,\n              error\n            };\n          }\n        };\n      }\n    });\n  }\n};\n\n//#endregion\n//#region src/lib/vectors/constants.ts\nconst DEFAULT_HEADERS = {\n  \"X-Client-Info\": \"storage-js/\".concat(version),\n  \"Content-Type\": \"application/json\"\n};\n\n//#endregion\n//#region src/lib/vectors/errors.ts\n/**\n* Base error class for all Storage Vectors errors\n*/\nvar StorageVectorsError = class extends Error {\n  constructor(message) {\n    super(message);\n    this.__isStorageVectorsError = true;\n    this.name = \"StorageVectorsError\";\n  }\n};\n/**\n* Type guard to check if an error is a StorageVectorsError\n* @param error - The error to check\n* @returns True if the error is a StorageVectorsError\n*/\nfunction isStorageVectorsError(error) {\n  return typeof error === \"object\" && error !== null && \"__isStorageVectorsError\" in error;\n}\n/**\n* API error returned from S3 Vectors service\n* Includes HTTP status code and service-specific error code\n*/\nvar StorageVectorsApiError = class extends StorageVectorsError {\n  constructor(message, status, statusCode) {\n    super(message);\n    this.name = \"StorageVectorsApiError\";\n    this.status = status;\n    this.statusCode = statusCode;\n  }\n  toJSON() {\n    return {\n      name: this.name,\n      message: this.message,\n      status: this.status,\n      statusCode: this.statusCode\n    };\n  }\n};\n/**\n* Unknown error that doesn't match expected error patterns\n* Wraps the original error for debugging\n*/\nvar StorageVectorsUnknownError = class extends StorageVectorsError {\n  constructor(message, originalError) {\n    super(message);\n    this.name = \"StorageVectorsUnknownError\";\n    this.originalError = originalError;\n  }\n};\n/**\n* Error codes specific to S3 Vectors API\n* Maps AWS service errors to application-friendly error codes\n*/\nlet StorageVectorsErrorCode = /* @__PURE__ */function (StorageVectorsErrorCode$1) {\n  /** Internal server fault (HTTP 500) */\n  StorageVectorsErrorCode$1[\"InternalError\"] = \"InternalError\";\n  /** Resource already exists / conflict (HTTP 409) */\n  StorageVectorsErrorCode$1[\"S3VectorConflictException\"] = \"S3VectorConflictException\";\n  /** Resource not found (HTTP 404) */\n  StorageVectorsErrorCode$1[\"S3VectorNotFoundException\"] = \"S3VectorNotFoundException\";\n  /** Delete bucket while not empty (HTTP 400) */\n  StorageVectorsErrorCode$1[\"S3VectorBucketNotEmpty\"] = \"S3VectorBucketNotEmpty\";\n  /** Exceeds bucket quota/limit (HTTP 400) */\n  StorageVectorsErrorCode$1[\"S3VectorMaxBucketsExceeded\"] = \"S3VectorMaxBucketsExceeded\";\n  /** Exceeds index quota/limit (HTTP 400) */\n  StorageVectorsErrorCode$1[\"S3VectorMaxIndexesExceeded\"] = \"S3VectorMaxIndexesExceeded\";\n  return StorageVectorsErrorCode$1;\n}({});\n\n//#endregion\n//#region src/lib/vectors/helpers.ts\n/**\n* Resolves the fetch implementation to use\n* Uses custom fetch if provided, otherwise uses native fetch\n*\n* @param customFetch - Optional custom fetch implementation\n* @returns Resolved fetch function\n*/\nconst resolveFetch = customFetch => {\n  if (customFetch) return function () {\n    return customFetch(...arguments);\n  };\n  return function () {\n    return fetch(...arguments);\n  };\n};\n/**\n* Resolves the Response constructor to use\n* Returns native Response constructor\n*\n* @returns Response constructor\n*/\nconst resolveResponse = () => {\n  return Response;\n};\n/**\n* Determine if input is a plain object\n* An object is plain if it's created by either {}, new Object(), or Object.create(null)\n*\n* @param value - Value to check\n* @returns True if value is a plain object\n* @source https://github.com/sindresorhus/is-plain-obj\n*/\nconst isPlainObject = value => {\n  if (typeof value !== \"object\" || value === null) return false;\n  const prototype = Object.getPrototypeOf(value);\n  return (prototype === null || prototype === Object.prototype || Object.getPrototypeOf(prototype) === null) && !(Symbol.toStringTag in value) && !(Symbol.iterator in value);\n};\n/**\n* Normalizes a number array to float32 format\n* Ensures all vector values are valid 32-bit floats\n*\n* @param values - Array of numbers to normalize\n* @returns Normalized float32 array\n*/\nconst normalizeToFloat32 = values => {\n  return Array.from(new Float32Array(values));\n};\n/**\n* Validates vector dimensions match expected dimension\n* Throws error if dimensions don't match\n*\n* @param vector - Vector data to validate\n* @param expectedDimension - Expected vector dimension\n* @throws Error if dimensions don't match\n*/\nconst validateVectorDimension = (vector, expectedDimension) => {\n  if (expectedDimension !== void 0 && vector.float32.length !== expectedDimension) throw new Error(\"Vector dimension mismatch: expected \".concat(expectedDimension, \", got \").concat(vector.float32.length));\n};\n\n//#endregion\n//#region src/lib/vectors/fetch.ts\n/**\n* Extracts error message from various error response formats\n* @param err - Error object from API\n* @returns Human-readable error message\n*/\nconst _getErrorMessage = err => err.msg || err.message || err.error_description || err.error || JSON.stringify(err);\n/**\n* Handles fetch errors and converts them to StorageVectors error types\n* @param error - The error caught from fetch\n* @param reject - Promise rejection function\n* @param options - Fetch options that may affect error handling\n*/\nconst handleError = async (error, reject, options) => {\n  if (error && typeof error === \"object\" && \"status\" in error && \"ok\" in error && typeof error.status === \"number\" && !(options === null || options === void 0 ? void 0 : options.noResolveJson)) {\n    const status = error.status || 500;\n    const responseError = error;\n    if (typeof responseError.json === \"function\") responseError.json().then(err => {\n      const statusCode = (err === null || err === void 0 ? void 0 : err.statusCode) || (err === null || err === void 0 ? void 0 : err.code) || status + \"\";\n      reject(new StorageVectorsApiError(_getErrorMessage(err), status, statusCode));\n    }).catch(() => {\n      const statusCode = status + \"\";\n      reject(new StorageVectorsApiError(responseError.statusText || \"HTTP \".concat(status, \" error\"), status, statusCode));\n    });else {\n      const statusCode = status + \"\";\n      reject(new StorageVectorsApiError(responseError.statusText || \"HTTP \".concat(status, \" error\"), status, statusCode));\n    }\n  } else reject(new StorageVectorsUnknownError(_getErrorMessage(error), error));\n};\n/**\n* Builds request parameters for fetch calls\n* @param method - HTTP method\n* @param options - Custom fetch options\n* @param parameters - Additional fetch parameters like AbortSignal\n* @param body - Request body (will be JSON stringified if plain object)\n* @returns Complete fetch request parameters\n*/\nconst _getRequestParams = (method, options, parameters, body) => {\n  const params = {\n    method,\n    headers: (options === null || options === void 0 ? void 0 : options.headers) || {}\n  };\n  if (method === \"GET\" || !body) return params;\n  if (isPlainObject(body)) {\n    params.headers = _objectSpread2({\n      \"Content-Type\": \"application/json\"\n    }, options === null || options === void 0 ? void 0 : options.headers);\n    params.body = JSON.stringify(body);\n  } else params.body = body;\n  return _objectSpread2(_objectSpread2({}, params), parameters);\n};\n/**\n* Internal request handler that wraps fetch with error handling\n* @param fetcher - Fetch function to use\n* @param method - HTTP method\n* @param url - Request URL\n* @param options - Custom fetch options\n* @param parameters - Additional fetch parameters\n* @param body - Request body\n* @returns Promise with parsed response or error\n*/\nasync function _handleRequest(fetcher, method, url, options, parameters, body) {\n  return new Promise((resolve, reject) => {\n    fetcher(url, _getRequestParams(method, options, parameters, body)).then(result => {\n      if (!result.ok) throw result;\n      if (options === null || options === void 0 ? void 0 : options.noResolveJson) return result;\n      const contentType = result.headers.get(\"content-type\");\n      if (!contentType || !contentType.includes(\"application/json\")) return {};\n      return result.json();\n    }).then(data => resolve(data)).catch(error => handleError(error, reject, options));\n  });\n}\n/**\n* Performs a POST request\n* @param fetcher - Fetch function to use\n* @param url - Request URL\n* @param body - Request body to be JSON stringified\n* @param options - Custom fetch options\n* @param parameters - Additional fetch parameters\n* @returns Promise with parsed response\n*/\nasync function post(fetcher, url, body, options, parameters) {\n  return _handleRequest(fetcher, \"POST\", url, options, parameters, body);\n}\n\n//#endregion\n//#region src/lib/vectors/VectorIndexApi.ts\n/**\n* @hidden\n* Base implementation for vector index operations.\n* Use {@link VectorBucketScope} via `supabase.storage.vectors.from('bucket')` instead.\n*/\nvar VectorIndexApi = class {\n  /** Creates a new VectorIndexApi instance */\n  constructor(url) {\n    let headers = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let fetch$1 = arguments.length > 2 ? arguments[2] : undefined;\n    this.shouldThrowOnError = false;\n    this.url = url.replace(/\\/$/, \"\");\n    this.headers = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), headers);\n    this.fetch = resolveFetch(fetch$1);\n  }\n  /** Enable throwing errors instead of returning them in the response */\n  throwOnError() {\n    this.shouldThrowOnError = true;\n    return this;\n  }\n  /** Creates a new vector index within a bucket */\n  async createIndex(options) {\n    var _this = this;\n    try {\n      return {\n        data: (await post(_this.fetch, \"\".concat(_this.url, \"/CreateIndex\"), options, {\n          headers: _this.headers\n        })) || {},\n        error: null\n      };\n    } catch (error) {\n      if (_this.shouldThrowOnError) throw error;\n      if (isStorageVectorsError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /** Retrieves metadata for a specific vector index */\n  async getIndex(vectorBucketName, indexName) {\n    var _this2 = this;\n    try {\n      return {\n        data: await post(_this2.fetch, \"\".concat(_this2.url, \"/GetIndex\"), {\n          vectorBucketName,\n          indexName\n        }, {\n          headers: _this2.headers\n        }),\n        error: null\n      };\n    } catch (error) {\n      if (_this2.shouldThrowOnError) throw error;\n      if (isStorageVectorsError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /** Lists vector indexes within a bucket with optional filtering and pagination */\n  async listIndexes(options) {\n    var _this3 = this;\n    try {\n      return {\n        data: await post(_this3.fetch, \"\".concat(_this3.url, \"/ListIndexes\"), options, {\n          headers: _this3.headers\n        }),\n        error: null\n      };\n    } catch (error) {\n      if (_this3.shouldThrowOnError) throw error;\n      if (isStorageVectorsError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /** Deletes a vector index and all its data */\n  async deleteIndex(vectorBucketName, indexName) {\n    var _this4 = this;\n    try {\n      return {\n        data: (await post(_this4.fetch, \"\".concat(_this4.url, \"/DeleteIndex\"), {\n          vectorBucketName,\n          indexName\n        }, {\n          headers: _this4.headers\n        })) || {},\n        error: null\n      };\n    } catch (error) {\n      if (_this4.shouldThrowOnError) throw error;\n      if (isStorageVectorsError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n};\n\n//#endregion\n//#region src/lib/vectors/VectorDataApi.ts\n/**\n* @hidden\n* Base implementation for vector data operations.\n* Use {@link VectorIndexScope} via `supabase.storage.vectors.from('bucket').index('idx')` instead.\n*/\nvar VectorDataApi = class {\n  /** Creates a new VectorDataApi instance */\n  constructor(url) {\n    let headers = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let fetch$1 = arguments.length > 2 ? arguments[2] : undefined;\n    this.shouldThrowOnError = false;\n    this.url = url.replace(/\\/$/, \"\");\n    this.headers = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), headers);\n    this.fetch = resolveFetch(fetch$1);\n  }\n  /** Enable throwing errors instead of returning them in the response */\n  throwOnError() {\n    this.shouldThrowOnError = true;\n    return this;\n  }\n  /** Inserts or updates vectors in batch (1-500 per request) */\n  async putVectors(options) {\n    var _this = this;\n    try {\n      if (options.vectors.length < 1 || options.vectors.length > 500) throw new Error(\"Vector batch size must be between 1 and 500 items\");\n      return {\n        data: (await post(_this.fetch, \"\".concat(_this.url, \"/PutVectors\"), options, {\n          headers: _this.headers\n        })) || {},\n        error: null\n      };\n    } catch (error) {\n      if (_this.shouldThrowOnError) throw error;\n      if (isStorageVectorsError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /** Retrieves vectors by their keys in batch */\n  async getVectors(options) {\n    var _this2 = this;\n    try {\n      return {\n        data: await post(_this2.fetch, \"\".concat(_this2.url, \"/GetVectors\"), options, {\n          headers: _this2.headers\n        }),\n        error: null\n      };\n    } catch (error) {\n      if (_this2.shouldThrowOnError) throw error;\n      if (isStorageVectorsError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /** Lists vectors in an index with pagination */\n  async listVectors(options) {\n    var _this3 = this;\n    try {\n      if (options.segmentCount !== void 0) {\n        if (options.segmentCount < 1 || options.segmentCount > 16) throw new Error(\"segmentCount must be between 1 and 16\");\n        if (options.segmentIndex !== void 0) {\n          if (options.segmentIndex < 0 || options.segmentIndex >= options.segmentCount) throw new Error(\"segmentIndex must be between 0 and \".concat(options.segmentCount - 1));\n        }\n      }\n      return {\n        data: await post(_this3.fetch, \"\".concat(_this3.url, \"/ListVectors\"), options, {\n          headers: _this3.headers\n        }),\n        error: null\n      };\n    } catch (error) {\n      if (_this3.shouldThrowOnError) throw error;\n      if (isStorageVectorsError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /** Queries for similar vectors using approximate nearest neighbor search */\n  async queryVectors(options) {\n    var _this4 = this;\n    try {\n      return {\n        data: await post(_this4.fetch, \"\".concat(_this4.url, \"/QueryVectors\"), options, {\n          headers: _this4.headers\n        }),\n        error: null\n      };\n    } catch (error) {\n      if (_this4.shouldThrowOnError) throw error;\n      if (isStorageVectorsError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /** Deletes vectors by their keys in batch (1-500 per request) */\n  async deleteVectors(options) {\n    var _this5 = this;\n    try {\n      if (options.keys.length < 1 || options.keys.length > 500) throw new Error(\"Keys batch size must be between 1 and 500 items\");\n      return {\n        data: (await post(_this5.fetch, \"\".concat(_this5.url, \"/DeleteVectors\"), options, {\n          headers: _this5.headers\n        })) || {},\n        error: null\n      };\n    } catch (error) {\n      if (_this5.shouldThrowOnError) throw error;\n      if (isStorageVectorsError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n};\n\n//#endregion\n//#region src/lib/vectors/VectorBucketApi.ts\n/**\n* @hidden\n* Base implementation for vector bucket operations.\n* Use {@link StorageVectorsClient} via `supabase.storage.vectors` instead.\n*/\nvar VectorBucketApi = class {\n  /** Creates a new VectorBucketApi instance */\n  constructor(url) {\n    let headers = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let fetch$1 = arguments.length > 2 ? arguments[2] : undefined;\n    this.shouldThrowOnError = false;\n    this.url = url.replace(/\\/$/, \"\");\n    this.headers = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), headers);\n    this.fetch = resolveFetch(fetch$1);\n  }\n  /** Enable throwing errors instead of returning them in the response */\n  throwOnError() {\n    this.shouldThrowOnError = true;\n    return this;\n  }\n  /** Creates a new vector bucket */\n  async createBucket(vectorBucketName) {\n    var _this = this;\n    try {\n      return {\n        data: (await post(_this.fetch, \"\".concat(_this.url, \"/CreateVectorBucket\"), {\n          vectorBucketName\n        }, {\n          headers: _this.headers\n        })) || {},\n        error: null\n      };\n    } catch (error) {\n      if (_this.shouldThrowOnError) throw error;\n      if (isStorageVectorsError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /** Retrieves metadata for a specific vector bucket */\n  async getBucket(vectorBucketName) {\n    var _this2 = this;\n    try {\n      return {\n        data: await post(_this2.fetch, \"\".concat(_this2.url, \"/GetVectorBucket\"), {\n          vectorBucketName\n        }, {\n          headers: _this2.headers\n        }),\n        error: null\n      };\n    } catch (error) {\n      if (_this2.shouldThrowOnError) throw error;\n      if (isStorageVectorsError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /** Lists vector buckets with optional filtering and pagination */\n  async listBuckets() {\n    let options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    var _this3 = this;\n    try {\n      return {\n        data: await post(_this3.fetch, \"\".concat(_this3.url, \"/ListVectorBuckets\"), options, {\n          headers: _this3.headers\n        }),\n        error: null\n      };\n    } catch (error) {\n      if (_this3.shouldThrowOnError) throw error;\n      if (isStorageVectorsError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n  /** Deletes a vector bucket (must be empty first) */\n  async deleteBucket(vectorBucketName) {\n    var _this4 = this;\n    try {\n      return {\n        data: (await post(_this4.fetch, \"\".concat(_this4.url, \"/DeleteVectorBucket\"), {\n          vectorBucketName\n        }, {\n          headers: _this4.headers\n        })) || {},\n        error: null\n      };\n    } catch (error) {\n      if (_this4.shouldThrowOnError) throw error;\n      if (isStorageVectorsError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n};\n\n//#endregion\n//#region src/lib/vectors/StorageVectorsClient.ts\n/**\n*\n* @alpha\n*\n* Main client for interacting with S3 Vectors API\n* Provides access to bucket, index, and vector data operations\n*\n* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n*\n* **Usage Patterns:**\n*\n* ```typescript\n* const { data, error } = await supabase\n*  .storage\n*  .vectors\n*  .createBucket('embeddings-prod')\n*\n* // Access index operations via buckets\n* const bucket = supabase.storage.vectors.from('embeddings-prod')\n* await bucket.createIndex({\n*   indexName: 'documents',\n*   dataType: 'float32',\n*   dimension: 1536,\n*   distanceMetric: 'cosine'\n* })\n*\n* // Access vector operations via index\n* const index = bucket.index('documents')\n* await index.putVectors({\n*   vectors: [\n*     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\n*   ]\n* })\n*\n* // Query similar vectors\n* const { data } = await index.queryVectors({\n*   queryVector: { float32: [...] },\n*   topK: 5,\n*   returnDistance: true\n* })\n* ```\n*/\nvar StorageVectorsClient = class extends VectorBucketApi {\n  /**\n  * @alpha\n  *\n  * Creates a StorageVectorsClient that can manage buckets, indexes, and vectors.\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param url - Base URL of the Storage Vectors REST API.\n  * @param options.headers - Optional headers (for example `Authorization`) applied to every request.\n  * @param options.fetch - Optional custom `fetch` implementation for non-browser runtimes.\n  *\n  * @example\n  * ```typescript\n  * const client = new StorageVectorsClient(url, options)\n  * ```\n  */\n  constructor(url) {\n    let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    super(url, options.headers || {}, options.fetch);\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Access operations for a specific vector bucket\n  * Returns a scoped client for index and vector operations within the bucket\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param vectorBucketName - Name of the vector bucket\n  * @returns Bucket-scoped client with index and vector operations\n  *\n  * @example\n  * ```typescript\n  * const bucket = supabase.storage.vectors.from('embeddings-prod')\n  * ```\n  */\n  from(vectorBucketName) {\n    return new VectorBucketScope(this.url, this.headers, vectorBucketName, this.fetch);\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Creates a new vector bucket\n  * Vector buckets are containers for vector indexes and their data\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param vectorBucketName - Unique name for the vector bucket\n  * @returns Promise with empty response on success or error\n  *\n  * @example\n  * ```typescript\n  * const { data, error } = await supabase\n  *   .storage\n  *   .vectors\n  *   .createBucket('embeddings-prod')\n  * ```\n  */\n  async createBucket(vectorBucketName) {\n    var _superprop_getCreateBucket = () => super.createBucket,\n      _this = this;\n    return _superprop_getCreateBucket().call(_this, vectorBucketName);\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Retrieves metadata for a specific vector bucket\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param vectorBucketName - Name of the vector bucket\n  * @returns Promise with bucket metadata or error\n  *\n  * @example\n  * ```typescript\n  * const { data, error } = await supabase\n  *   .storage\n  *   .vectors\n  *   .getBucket('embeddings-prod')\n  *\n  * console.log('Bucket created:', data?.vectorBucket.creationTime)\n  * ```\n  */\n  async getBucket(vectorBucketName) {\n    var _superprop_getGetBucket = () => super.getBucket,\n      _this2 = this;\n    return _superprop_getGetBucket().call(_this2, vectorBucketName);\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Lists all vector buckets with optional filtering and pagination\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param options - Optional filters (prefix, maxResults, nextToken)\n  * @returns Promise with list of buckets or error\n  *\n  * @example\n  * ```typescript\n  * const { data, error } = await supabase\n  *   .storage\n  *   .vectors\n  *   .listBuckets({ prefix: 'embeddings-' })\n  *\n  * data?.vectorBuckets.forEach(bucket => {\n  *   console.log(bucket.vectorBucketName)\n  * })\n  * ```\n  */\n  async listBuckets() {\n    let options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    var _superprop_getListBuckets = () => super.listBuckets,\n      _this3 = this;\n    return _superprop_getListBuckets().call(_this3, options);\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Deletes a vector bucket (bucket must be empty)\n  * All indexes must be deleted before deleting the bucket\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param vectorBucketName - Name of the vector bucket to delete\n  * @returns Promise with empty response on success or error\n  *\n  * @example\n  * ```typescript\n  * const { data, error } = await supabase\n  *   .storage\n  *   .vectors\n  *   .deleteBucket('embeddings-old')\n  * ```\n  */\n  async deleteBucket(vectorBucketName) {\n    var _superprop_getDeleteBucket = () => super.deleteBucket,\n      _this4 = this;\n    return _superprop_getDeleteBucket().call(_this4, vectorBucketName);\n  }\n};\n/**\n*\n* @alpha\n*\n* Scoped client for operations within a specific vector bucket\n* Provides index management and access to vector operations\n*\n* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n*/\nvar VectorBucketScope = class extends VectorIndexApi {\n  /**\n  * @alpha\n  *\n  * Creates a helper that automatically scopes all index operations to the provided bucket.\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @example\n  * ```typescript\n  * const bucket = supabase.storage.vectors.from('embeddings-prod')\n  * ```\n  */\n  constructor(url, headers, vectorBucketName, fetch$1) {\n    super(url, headers, fetch$1);\n    this.vectorBucketName = vectorBucketName;\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Creates a new vector index in this bucket\n  * Convenience method that automatically includes the bucket name\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param options - Index configuration (vectorBucketName is automatically set)\n  * @returns Promise with empty response on success or error\n  *\n  * @example\n  * ```typescript\n  * const bucket = supabase.storage.vectors.from('embeddings-prod')\n  * await bucket.createIndex({\n  *   indexName: 'documents-openai',\n  *   dataType: 'float32',\n  *   dimension: 1536,\n  *   distanceMetric: 'cosine',\n  *   metadataConfiguration: {\n  *     nonFilterableMetadataKeys: ['raw_text']\n  *   }\n  * })\n  * ```\n  */\n  async createIndex(options) {\n    var _superprop_getCreateIndex = () => super.createIndex,\n      _this5 = this;\n    return _superprop_getCreateIndex().call(_this5, _objectSpread2(_objectSpread2({}, options), {}, {\n      vectorBucketName: _this5.vectorBucketName\n    }));\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Lists indexes in this bucket\n  * Convenience method that automatically includes the bucket name\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param options - Listing options (vectorBucketName is automatically set)\n  * @returns Promise with response containing indexes array and pagination token or error\n  *\n  * @example\n  * ```typescript\n  * const bucket = supabase.storage.vectors.from('embeddings-prod')\n  * const { data } = await bucket.listIndexes({ prefix: 'documents-' })\n  * ```\n  */\n  async listIndexes() {\n    let options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    var _superprop_getListIndexes = () => super.listIndexes,\n      _this6 = this;\n    return _superprop_getListIndexes().call(_this6, _objectSpread2(_objectSpread2({}, options), {}, {\n      vectorBucketName: _this6.vectorBucketName\n    }));\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Retrieves metadata for a specific index in this bucket\n  * Convenience method that automatically includes the bucket name\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param indexName - Name of the index to retrieve\n  * @returns Promise with index metadata or error\n  *\n  * @example\n  * ```typescript\n  * const bucket = supabase.storage.vectors.from('embeddings-prod')\n  * const { data } = await bucket.getIndex('documents-openai')\n  * console.log('Dimension:', data?.index.dimension)\n  * ```\n  */\n  async getIndex(indexName) {\n    var _superprop_getGetIndex = () => super.getIndex,\n      _this7 = this;\n    return _superprop_getGetIndex().call(_this7, _this7.vectorBucketName, indexName);\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Deletes an index from this bucket\n  * Convenience method that automatically includes the bucket name\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param indexName - Name of the index to delete\n  * @returns Promise with empty response on success or error\n  *\n  * @example\n  * ```typescript\n  * const bucket = supabase.storage.vectors.from('embeddings-prod')\n  * await bucket.deleteIndex('old-index')\n  * ```\n  */\n  async deleteIndex(indexName) {\n    var _superprop_getDeleteIndex = () => super.deleteIndex,\n      _this8 = this;\n    return _superprop_getDeleteIndex().call(_this8, _this8.vectorBucketName, indexName);\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Access operations for a specific index within this bucket\n  * Returns a scoped client for vector data operations\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param indexName - Name of the index\n  * @returns Index-scoped client with vector data operations\n  *\n  * @example\n  * ```typescript\n  * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n  *\n  * // Insert vectors\n  * await index.putVectors({\n  *   vectors: [\n  *     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\n  *   ]\n  * })\n  *\n  * // Query similar vectors\n  * const { data } = await index.queryVectors({\n  *   queryVector: { float32: [...] },\n  *   topK: 5\n  * })\n  * ```\n  */\n  index(indexName) {\n    return new VectorIndexScope(this.url, this.headers, this.vectorBucketName, indexName, this.fetch);\n  }\n};\n/**\n*\n* @alpha\n*\n* Scoped client for operations within a specific vector index\n* Provides vector data operations (put, get, list, query, delete)\n*\n* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n*/\nvar VectorIndexScope = class extends VectorDataApi {\n  /**\n  *\n  * @alpha\n  *\n  * Creates a helper that automatically scopes all vector operations to the provided bucket/index names.\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @example\n  * ```typescript\n  * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n  * ```\n  */\n  constructor(url, headers, vectorBucketName, indexName, fetch$1) {\n    super(url, headers, fetch$1);\n    this.vectorBucketName = vectorBucketName;\n    this.indexName = indexName;\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Inserts or updates vectors in this index\n  * Convenience method that automatically includes bucket and index names\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param options - Vector insertion options (bucket and index names automatically set)\n  * @returns Promise with empty response on success or error\n  *\n  * @example\n  * ```typescript\n  * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n  * await index.putVectors({\n  *   vectors: [\n  *     {\n  *       key: 'doc-1',\n  *       data: { float32: [0.1, 0.2, ...] },\n  *       metadata: { title: 'Introduction', page: 1 }\n  *     }\n  *   ]\n  * })\n  * ```\n  */\n  async putVectors(options) {\n    var _superprop_getPutVectors = () => super.putVectors,\n      _this9 = this;\n    return _superprop_getPutVectors().call(_this9, _objectSpread2(_objectSpread2({}, options), {}, {\n      vectorBucketName: _this9.vectorBucketName,\n      indexName: _this9.indexName\n    }));\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Retrieves vectors by keys from this index\n  * Convenience method that automatically includes bucket and index names\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param options - Vector retrieval options (bucket and index names automatically set)\n  * @returns Promise with response containing vectors array or error\n  *\n  * @example\n  * ```typescript\n  * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n  * const { data } = await index.getVectors({\n  *   keys: ['doc-1', 'doc-2'],\n  *   returnMetadata: true\n  * })\n  * ```\n  */\n  async getVectors(options) {\n    var _superprop_getGetVectors = () => super.getVectors,\n      _this10 = this;\n    return _superprop_getGetVectors().call(_this10, _objectSpread2(_objectSpread2({}, options), {}, {\n      vectorBucketName: _this10.vectorBucketName,\n      indexName: _this10.indexName\n    }));\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Lists vectors in this index with pagination\n  * Convenience method that automatically includes bucket and index names\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param options - Listing options (bucket and index names automatically set)\n  * @returns Promise with response containing vectors array and pagination token or error\n  *\n  * @example\n  * ```typescript\n  * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n  * const { data } = await index.listVectors({\n  *   maxResults: 500,\n  *   returnMetadata: true\n  * })\n  * ```\n  */\n  async listVectors() {\n    let options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    var _superprop_getListVectors = () => super.listVectors,\n      _this11 = this;\n    return _superprop_getListVectors().call(_this11, _objectSpread2(_objectSpread2({}, options), {}, {\n      vectorBucketName: _this11.vectorBucketName,\n      indexName: _this11.indexName\n    }));\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Queries for similar vectors in this index\n  * Convenience method that automatically includes bucket and index names\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param options - Query options (bucket and index names automatically set)\n  * @returns Promise with response containing matches array of similar vectors ordered by distance or error\n  *\n  * @example\n  * ```typescript\n  * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n  * const { data } = await index.queryVectors({\n  *   queryVector: { float32: [0.1, 0.2, ...] },\n  *   topK: 5,\n  *   filter: { category: 'technical' },\n  *   returnDistance: true,\n  *   returnMetadata: true\n  * })\n  * ```\n  */\n  async queryVectors(options) {\n    var _superprop_getQueryVectors = () => super.queryVectors,\n      _this12 = this;\n    return _superprop_getQueryVectors().call(_this12, _objectSpread2(_objectSpread2({}, options), {}, {\n      vectorBucketName: _this12.vectorBucketName,\n      indexName: _this12.indexName\n    }));\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Deletes vectors by keys from this index\n  * Convenience method that automatically includes bucket and index names\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param options - Deletion options (bucket and index names automatically set)\n  * @returns Promise with empty response on success or error\n  *\n  * @example\n  * ```typescript\n  * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n  * await index.deleteVectors({\n  *   keys: ['doc-1', 'doc-2', 'doc-3']\n  * })\n  * ```\n  */\n  async deleteVectors(options) {\n    var _superprop_getDeleteVectors = () => super.deleteVectors,\n      _this13 = this;\n    return _superprop_getDeleteVectors().call(_this13, _objectSpread2(_objectSpread2({}, options), {}, {\n      vectorBucketName: _this13.vectorBucketName,\n      indexName: _this13.indexName\n    }));\n  }\n};\n\n//#endregion\n//#region src/StorageClient.ts\nvar StorageClient = class extends StorageBucketApi {\n  /**\n  * Creates a client for Storage buckets, files, analytics, and vectors.\n  *\n  * @category File Buckets\n  * @example\n  * ```ts\n  * import { StorageClient } from '@supabase/storage-js'\n  *\n  * const storage = new StorageClient('https://xyzcompany.supabase.co/storage/v1', {\n  *   apikey: 'public-anon-key',\n  * })\n  * const avatars = storage.from('avatars')\n  * ```\n  */\n  constructor(url) {\n    let headers = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let fetch$1 = arguments.length > 2 ? arguments[2] : undefined;\n    let opts = arguments.length > 3 ? arguments[3] : undefined;\n    super(url, headers, fetch$1, opts);\n  }\n  /**\n  * Perform file operation in a bucket.\n  *\n  * @category File Buckets\n  * @param id The bucket id to operate on.\n  *\n  * @example\n  * ```typescript\n  * const avatars = supabase.storage.from('avatars')\n  * ```\n  */\n  from(id) {\n    return new StorageFileApi(this.url, this.headers, id, this.fetch);\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Access vector storage operations.\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @returns A StorageVectorsClient instance configured with the current storage settings.\n  */\n  get vectors() {\n    return new StorageVectorsClient(this.url + \"/vector\", {\n      headers: this.headers,\n      fetch: this.fetch\n    });\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Access analytics storage operations using Iceberg tables.\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Analytics Buckets\n  * @returns A StorageAnalyticsClient instance configured with the current storage settings.\n  */\n  get analytics() {\n    return new StorageAnalyticsClient(this.url + \"/iceberg\", this.headers, this.fetch);\n  }\n};\n\n//#endregion\nexport { StorageAnalyticsClient, StorageApiError, StorageClient, StorageError, StorageUnknownError, StorageVectorsApiError, StorageVectorsClient, StorageVectorsError, StorageVectorsErrorCode, StorageVectorsUnknownError, VectorBucketApi, VectorBucketScope, VectorDataApi, VectorIndexApi, VectorIndexScope, isPlainObject, isStorageError, isStorageVectorsError, normalizeToFloat32, resolveFetch, resolveResponse, validateVectorDimension };","map":{"version":3,"names":["StorageError","Error","constructor","message","__isStorageError","name","isStorageError","error","StorageApiError","status","statusCode","toJSON","StorageUnknownError","originalError","resolveFetch$1","customFetch","arguments","fetch","resolveResponse$1","Response","recursiveToCamel","item","Array","isArray","map","el","Object","result","entries","forEach","_ref","key","value","newKey","replace","c","toUpperCase","isPlainObject$1","prototype","getPrototypeOf","Symbol","toStringTag","iterator","isValidBucketName","bucketName","length","trim","includes","test","_getErrorMessage$1","err","msg","error_description","_err$error","JSON","stringify","handleError$1","handleError","reject","options","noResolveJson","json","then","catch","_getRequestParams$1","method","parameters","body","params","headers","_objectSpread2","duplex","_handleRequest$1","fetcher","url","Promise","resolve","ok","data","get","post$1","put","head","remove","StreamDownloadBuilder","downloadFn","shouldThrowOnError","onfulfilled","onrejected","execute","_this","BlobDownloadBuilder","promise","asStream","getPromise","finally","onfinally","blob","DEFAULT_SEARCH_OPTIONS","limit","offset","sortBy","column","order","DEFAULT_FILE_OPTIONS","cacheControl","contentType","upsert","StorageFileApi","undefined","bucketId","fetch$1","throwOnError","uploadOrUpdate","path","fileBody","fileOptions","String","metadata","Blob","FormData","append","encodeMetadata","has","concat","toBase64","ReadableStream","pipe","cleanPath","_removeEmptyFolders","_path","_getFinalPath","id","Id","fullPath","Key","upload","uploadToSignedUrl","token","_this3","URL","searchParams","set","toString","createSignedUploadUrl","_this4","signedUrl","update","move","fromPath","toPath","_this6","sourceKey","destinationKey","destinationBucket","copy","_this7","createSignedUrl","expiresIn","_this8","transform","downloadQueryParam","download","encodeURI","signedURL","createSignedUrls","paths","_this9","datum","renderPath","transformationQuery","transformOptsToQueryString","queryString","info","_this10","exists","_this11","getPublicUrl","_queryString","push","join","publicUrl","_this12","prefixes","list","prefix","_this13","listV2","_this14","Buffer","from","btoa","width","height","resize","format","quality","version","DEFAULT_HEADERS$1","StorageBucketApi","opts","baseUrl","useNewHostname","hostname","href","listBuckets","listBucketOptionsToQueryString","getBucket","_this2","createBucket","public","type","file_size_limit","fileSizeLimit","allowed_mime_types","allowedMimeTypes","updateBucket","emptyBucket","_this5","deleteBucket","search","sortColumn","sortOrder","keys","URLSearchParams","StorageAnalyticsClient","queryParams","catalog","IcebergRestCatalog","catalogName","auth","getHeaders","Proxy","target","prop","_len","args","_key","apply","DEFAULT_HEADERS","StorageVectorsError","__isStorageVectorsError","isStorageVectorsError","StorageVectorsApiError","StorageVectorsUnknownError","StorageVectorsErrorCode","StorageVectorsErrorCode$1","resolveFetch","resolveResponse","isPlainObject","normalizeToFloat32","values","Float32Array","validateVectorDimension","vector","expectedDimension","float32","_getErrorMessage","responseError","code","statusText","_getRequestParams","_handleRequest","post","VectorIndexApi","createIndex","getIndex","vectorBucketName","indexName","listIndexes","deleteIndex","VectorDataApi","putVectors","vectors","getVectors","listVectors","segmentCount","segmentIndex","queryVectors","deleteVectors","VectorBucketApi","StorageVectorsClient","VectorBucketScope","_superprop_getCreateBucket","call","_superprop_getGetBucket","_superprop_getListBuckets","_superprop_getDeleteBucket","_superprop_getCreateIndex","_superprop_getListIndexes","_superprop_getGetIndex","_superprop_getDeleteIndex","index","VectorIndexScope","_superprop_getPutVectors","_superprop_getGetVectors","_superprop_getListVectors","_superprop_getQueryVectors","_superprop_getDeleteVectors","StorageClient","analytics"],"sources":["/home/steve/amala/client/node_modules/@supabase/storage-js/src/lib/errors.ts","/home/steve/amala/client/node_modules/@supabase/storage-js/src/lib/helpers.ts","/home/steve/amala/client/node_modules/@supabase/storage-js/src/lib/fetch.ts","/home/steve/amala/client/node_modules/@supabase/storage-js/src/packages/StreamDownloadBuilder.ts","/home/steve/amala/client/node_modules/@supabase/storage-js/src/packages/BlobDownloadBuilder.ts","/home/steve/amala/client/node_modules/@supabase/storage-js/src/packages/StorageFileApi.ts","/home/steve/amala/client/node_modules/@supabase/storage-js/src/lib/version.ts","/home/steve/amala/client/node_modules/@supabase/storage-js/src/lib/constants.ts","/home/steve/amala/client/node_modules/@supabase/storage-js/src/packages/StorageBucketApi.ts","/home/steve/amala/client/node_modules/@supabase/storage-js/src/packages/StorageAnalyticsClient.ts","/home/steve/amala/client/node_modules/@supabase/storage-js/src/lib/vectors/constants.ts","/home/steve/amala/client/node_modules/@supabase/storage-js/src/lib/vectors/errors.ts","/home/steve/amala/client/node_modules/@supabase/storage-js/src/lib/vectors/helpers.ts","/home/steve/amala/client/node_modules/@supabase/storage-js/src/lib/vectors/fetch.ts","/home/steve/amala/client/node_modules/@supabase/storage-js/src/lib/vectors/VectorIndexApi.ts","/home/steve/amala/client/node_modules/@supabase/storage-js/src/lib/vectors/VectorDataApi.ts","/home/steve/amala/client/node_modules/@supabase/storage-js/src/lib/vectors/VectorBucketApi.ts","/home/steve/amala/client/node_modules/@supabase/storage-js/src/lib/vectors/StorageVectorsClient.ts","/home/steve/amala/client/node_modules/@supabase/storage-js/src/StorageClient.ts"],"sourcesContent":["export class StorageError extends Error {\n  protected __isStorageError = true\n\n  constructor(message: string) {\n    super(message)\n    this.name = 'StorageError'\n  }\n}\n\nexport function isStorageError(error: unknown): error is StorageError {\n  return typeof error === 'object' && error !== null && '__isStorageError' in error\n}\n\nexport class StorageApiError extends StorageError {\n  status: number\n  statusCode: string\n\n  constructor(message: string, status: number, statusCode: string) {\n    super(message)\n    this.name = 'StorageApiError'\n    this.status = status\n    this.statusCode = statusCode\n  }\n\n  toJSON() {\n    return {\n      name: this.name,\n      message: this.message,\n      status: this.status,\n      statusCode: this.statusCode,\n    }\n  }\n}\n\nexport class StorageUnknownError extends StorageError {\n  originalError: unknown\n\n  constructor(message: string, originalError: unknown) {\n    super(message)\n    this.name = 'StorageUnknownError'\n    this.originalError = originalError\n  }\n}\n","type Fetch = typeof fetch\n\nexport const resolveFetch = (customFetch?: Fetch): Fetch => {\n  if (customFetch) {\n    return (...args) => customFetch(...args)\n  }\n  return (...args) => fetch(...args)\n}\n\nexport const resolveResponse = (): typeof Response => {\n  return Response\n}\n\nexport const recursiveToCamel = (item: Record<string, any>): unknown => {\n  if (Array.isArray(item)) {\n    return item.map((el) => recursiveToCamel(el))\n  } else if (typeof item === 'function' || item !== Object(item)) {\n    return item\n  }\n\n  const result: Record<string, any> = {}\n  Object.entries(item).forEach(([key, value]) => {\n    const newKey = key.replace(/([-_][a-z])/gi, (c) => c.toUpperCase().replace(/[-_]/g, ''))\n    result[newKey] = recursiveToCamel(value)\n  })\n\n  return result\n}\n\n/**\n * Determine if input is a plain object\n * An object is plain if it's created by either {}, new Object(), or Object.create(null)\n * source: https://github.com/sindresorhus/is-plain-obj\n */\nexport const isPlainObject = (value: object): boolean => {\n  if (typeof value !== 'object' || value === null) {\n    return false\n  }\n\n  const prototype = Object.getPrototypeOf(value)\n  return (\n    (prototype === null ||\n      prototype === Object.prototype ||\n      Object.getPrototypeOf(prototype) === null) &&\n    !(Symbol.toStringTag in value) &&\n    !(Symbol.iterator in value)\n  )\n}\n\n/**\n * Validates if a given bucket name is valid according to Supabase Storage API rules\n * Mirrors backend validation from: storage/src/storage/limits.ts:isValidBucketName()\n *\n * Rules:\n * - Length: 1-100 characters\n * - Allowed characters: alphanumeric (a-z, A-Z, 0-9), underscore (_), and safe special characters\n * - Safe special characters: ! - . * ' ( ) space & $ @ = ; : + , ?\n * - Forbidden: path separators (/, \\), path traversal (..), leading/trailing whitespace\n *\n * AWS S3 Reference: https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-keys.html\n *\n * @param bucketName - The bucket name to validate\n * @returns true if valid, false otherwise\n */\nexport const isValidBucketName = (bucketName: string): boolean => {\n  if (!bucketName || typeof bucketName !== 'string') {\n    return false\n  }\n\n  // Check length constraints (1-100 characters)\n  if (bucketName.length === 0 || bucketName.length > 100) {\n    return false\n  }\n\n  // Check for leading/trailing whitespace\n  if (bucketName.trim() !== bucketName) {\n    return false\n  }\n\n  // Explicitly reject path separators (security)\n  // Note: Consecutive periods (..) are allowed by backend - the AWS restriction\n  // on relative paths applies to object keys, not bucket names\n  if (bucketName.includes('/') || bucketName.includes('\\\\')) {\n    return false\n  }\n\n  // Validate against allowed character set\n  // Pattern matches backend regex: /^(\\w|!|-|\\.|\\*|'|\\(|\\)| |&|\\$|@|=|;|:|\\+|,|\\?)*$/\n  // This explicitly excludes path separators (/, \\) and other problematic characters\n  const bucketNameRegex = /^[\\w!.\\*'() &$@=;:+,?-]+$/\n  return bucketNameRegex.test(bucketName)\n}\n","import { StorageApiError, StorageUnknownError } from './errors'\nimport { isPlainObject, resolveResponse } from './helpers'\nimport { FetchParameters } from './types'\n\nexport type Fetch = typeof fetch\n\nexport interface FetchOptions {\n  headers?: {\n    [key: string]: string\n  }\n  duplex?: string\n  noResolveJson?: boolean\n}\n\nexport type RequestMethodType = 'GET' | 'POST' | 'PUT' | 'DELETE' | 'HEAD'\n\nconst _getErrorMessage = (err: any): string =>\n  err.msg ||\n  err.message ||\n  err.error_description ||\n  (typeof err.error === 'string' ? err.error : err.error?.message) ||\n  JSON.stringify(err)\n\nconst handleError = async (\n  error: unknown,\n  reject: (reason?: any) => void,\n  options?: FetchOptions\n) => {\n  const Res = await resolveResponse()\n\n  if (error instanceof Res && !options?.noResolveJson) {\n    error\n      .json()\n      .then((err) => {\n        const status = error.status || 500\n        const statusCode = err?.statusCode || status + ''\n        reject(new StorageApiError(_getErrorMessage(err), status, statusCode))\n      })\n      .catch((err) => {\n        reject(new StorageUnknownError(_getErrorMessage(err), err))\n      })\n  } else {\n    reject(new StorageUnknownError(_getErrorMessage(error), error))\n  }\n}\n\nconst _getRequestParams = (\n  method: RequestMethodType,\n  options?: FetchOptions,\n  parameters?: FetchParameters,\n  body?: object\n) => {\n  const params: { [k: string]: any } = { method, headers: options?.headers || {} }\n\n  if (method === 'GET' || !body) {\n    return params\n  }\n\n  if (isPlainObject(body)) {\n    params.headers = { 'Content-Type': 'application/json', ...options?.headers }\n    params.body = JSON.stringify(body)\n  } else {\n    params.body = body\n  }\n\n  if (options?.duplex) {\n    params.duplex = options.duplex\n  }\n\n  return { ...params, ...parameters }\n}\n\nasync function _handleRequest(\n  fetcher: Fetch,\n  method: RequestMethodType,\n  url: string,\n  options?: FetchOptions,\n  parameters?: FetchParameters,\n  body?: object\n): Promise<any> {\n  return new Promise((resolve, reject) => {\n    fetcher(url, _getRequestParams(method, options, parameters, body))\n      .then((result) => {\n        if (!result.ok) throw result\n        if (options?.noResolveJson) return result\n        return result.json()\n      })\n      .then((data) => resolve(data))\n      .catch((error) => handleError(error, reject, options))\n  })\n}\n\nexport async function get(\n  fetcher: Fetch,\n  url: string,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'GET', url, options, parameters)\n}\n\nexport async function post(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'POST', url, options, parameters, body)\n}\n\nexport async function put(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'PUT', url, options, parameters, body)\n}\n\nexport async function head(\n  fetcher: Fetch,\n  url: string,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(\n    fetcher,\n    'HEAD',\n    url,\n    {\n      ...options,\n      noResolveJson: true,\n    },\n    parameters\n  )\n}\n\nexport async function remove(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'DELETE', url, options, parameters, body)\n}\n","import { isStorageError } from '../lib/errors'\nimport { DownloadResult } from '../lib/types'\n\nexport default class StreamDownloadBuilder implements PromiseLike<DownloadResult<ReadableStream>> {\n  constructor(\n    private downloadFn: () => Promise<Response>,\n    private shouldThrowOnError: boolean\n  ) {}\n\n  then<TResult1 = DownloadResult<ReadableStream>, TResult2 = never>(\n    onfulfilled?:\n      | ((value: DownloadResult<ReadableStream>) => TResult1 | PromiseLike<TResult1>)\n      | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | null\n  ): Promise<TResult1 | TResult2> {\n    return this.execute().then(onfulfilled, onrejected)\n  }\n\n  private async execute(): Promise<DownloadResult<ReadableStream>> {\n    try {\n      const result = await this.downloadFn()\n\n      return {\n        data: result.body as ReadableStream,\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n}\n","import { isStorageError } from '../lib/errors'\nimport { DownloadResult } from '../lib/types'\nimport StreamDownloadBuilder from './StreamDownloadBuilder'\n\nexport default class BlobDownloadBuilder implements Promise<DownloadResult<Blob>> {\n  readonly [Symbol.toStringTag]: string = 'BlobDownloadBuilder'\n  private promise: Promise<DownloadResult<Blob>> | null = null\n\n  constructor(\n    private downloadFn: () => Promise<Response>,\n    private shouldThrowOnError: boolean\n  ) {}\n\n  asStream(): StreamDownloadBuilder {\n    return new StreamDownloadBuilder(this.downloadFn, this.shouldThrowOnError)\n  }\n\n  then<TResult1 = DownloadResult<Blob>, TResult2 = never>(\n    onfulfilled?: ((value: DownloadResult<Blob>) => TResult1 | PromiseLike<TResult1>) | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | null\n  ): Promise<TResult1 | TResult2> {\n    return this.getPromise().then(onfulfilled, onrejected)\n  }\n\n  catch<TResult = never>(\n    onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | null\n  ): Promise<DownloadResult<Blob> | TResult> {\n    return this.getPromise().catch(onrejected)\n  }\n\n  finally(onfinally?: (() => void) | null): Promise<DownloadResult<Blob>> {\n    return this.getPromise().finally(onfinally)\n  }\n\n  private getPromise(): Promise<DownloadResult<Blob>> {\n    if (!this.promise) {\n      this.promise = this.execute()\n    }\n    return this.promise\n  }\n\n  private async execute(): Promise<DownloadResult<Blob>> {\n    try {\n      const result = await this.downloadFn()\n\n      return {\n        data: await result.blob(),\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n}\n","import { isStorageError, StorageError, StorageUnknownError } from '../lib/errors'\nimport { Fetch, get, head, post, put, remove } from '../lib/fetch'\nimport { recursiveToCamel, resolveFetch } from '../lib/helpers'\nimport {\n  FileObject,\n  FileOptions,\n  SearchOptions,\n  FetchParameters,\n  TransformOptions,\n  DestinationOptions,\n  FileObjectV2,\n  Camelize,\n  SearchV2Options,\n  SearchV2Result,\n} from '../lib/types'\nimport BlobDownloadBuilder from './BlobDownloadBuilder'\n\nconst DEFAULT_SEARCH_OPTIONS = {\n  limit: 100,\n  offset: 0,\n  sortBy: {\n    column: 'name',\n    order: 'asc',\n  },\n}\n\nconst DEFAULT_FILE_OPTIONS: FileOptions = {\n  cacheControl: '3600',\n  contentType: 'text/plain;charset=UTF-8',\n  upsert: false,\n}\n\ntype FileBody =\n  | ArrayBuffer\n  | ArrayBufferView\n  | Blob\n  | Buffer\n  | File\n  | FormData\n  | NodeJS.ReadableStream\n  | ReadableStream<Uint8Array>\n  | URLSearchParams\n  | string\n\nexport default class StorageFileApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected bucketId?: string\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    bucketId?: string,\n    fetch?: Fetch\n  ) {\n    this.url = url\n    this.headers = headers\n    this.bucketId = bucketId\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /**\n   * Enable throwing errors instead of returning them.\n   *\n   * @category File Buckets\n   */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /**\n   * Uploads a file to an existing bucket or replaces an existing file at the specified path with a new one.\n   *\n   * @param method HTTP method.\n   * @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param fileBody The body of the file to be stored in the bucket.\n   */\n  private async uploadOrUpdate(\n    method: 'POST' | 'PUT',\n    path: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      let body\n      const options = { ...DEFAULT_FILE_OPTIONS, ...fileOptions }\n      let headers: Record<string, string> = {\n        ...this.headers,\n        ...(method === 'POST' && { 'x-upsert': String(options.upsert as boolean) }),\n      }\n\n      const metadata = options.metadata\n\n      if (typeof Blob !== 'undefined' && fileBody instanceof Blob) {\n        body = new FormData()\n        body.append('cacheControl', options.cacheControl as string)\n        if (metadata) {\n          body.append('metadata', this.encodeMetadata(metadata))\n        }\n        body.append('', fileBody)\n      } else if (typeof FormData !== 'undefined' && fileBody instanceof FormData) {\n        body = fileBody\n        // Only append if not already present\n        if (!body.has('cacheControl')) {\n          body.append('cacheControl', options.cacheControl as string)\n        }\n        if (metadata && !body.has('metadata')) {\n          body.append('metadata', this.encodeMetadata(metadata))\n        }\n      } else {\n        body = fileBody\n        headers['cache-control'] = `max-age=${options.cacheControl}`\n        headers['content-type'] = options.contentType as string\n\n        if (metadata) {\n          headers['x-metadata'] = this.toBase64(this.encodeMetadata(metadata))\n        }\n\n        // Node.js streams require duplex option for fetch in Node 20+\n        // Check for both web ReadableStream and Node.js streams\n        const isStream =\n          (typeof ReadableStream !== 'undefined' && body instanceof ReadableStream) ||\n          (body && typeof body === 'object' && 'pipe' in body && typeof body.pipe === 'function')\n\n        if (isStream && !options.duplex) {\n          options.duplex = 'half'\n        }\n      }\n\n      if (fileOptions?.headers) {\n        headers = { ...headers, ...fileOptions.headers }\n      }\n\n      const cleanPath = this._removeEmptyFolders(path)\n      const _path = this._getFinalPath(cleanPath)\n      const data = await (method == 'PUT' ? put : post)(\n        this.fetch,\n        `${this.url}/object/${_path}`,\n        body as object,\n        { headers, ...(options?.duplex ? { duplex: options.duplex } : {}) }\n      )\n\n      return {\n        data: { path: cleanPath, id: data.Id, fullPath: data.Key },\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Uploads a file to an existing bucket.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param fileBody The body of the file to be stored in the bucket.\n   * @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\n   * @returns Promise with response containing file path, id, and fullPath or error\n   *\n   * @example Upload file\n   * ```js\n   * const avatarFile = event.target.files[0]\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .upload('public/avatar1.png', avatarFile, {\n   *     cacheControl: '3600',\n   *     upsert: false\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"public/avatar1.png\",\n   *     \"fullPath\": \"avatars/public/avatar1.png\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Upload file using `ArrayBuffer` from base64 file data\n   * ```js\n   * import { decode } from 'base64-arraybuffer'\n   *\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .upload('public/avatar1.png', decode('base64FileData'), {\n   *     contentType: 'image/png'\n   *   })\n   * ```\n   */\n  async upload(\n    path: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.uploadOrUpdate('POST', path, fileBody, fileOptions)\n  }\n\n  /**\n   * Upload a file with a token generated from `createSignedUploadUrl`.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param token The token generated from `createSignedUploadUrl`\n   * @param fileBody The body of the file to be stored in the bucket.\n   * @param fileOptions HTTP headers (cacheControl, contentType, etc.).\n   * **Note:** The `upsert` option has no effect here. To enable upsert behavior,\n   * pass `{ upsert: true }` when calling `createSignedUploadUrl()` instead.\n   * @returns Promise with response containing file path and fullPath or error\n   *\n   * @example Upload to a signed URL\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .uploadToSignedUrl('folder/cat.jpg', 'token-from-createSignedUploadUrl', file)\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"folder/cat.jpg\",\n   *     \"fullPath\": \"avatars/folder/cat.jpg\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async uploadToSignedUrl(\n    path: string,\n    token: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ) {\n    const cleanPath = this._removeEmptyFolders(path)\n    const _path = this._getFinalPath(cleanPath)\n\n    const url = new URL(this.url + `/object/upload/sign/${_path}`)\n    url.searchParams.set('token', token)\n\n    try {\n      let body\n      const options = { upsert: DEFAULT_FILE_OPTIONS.upsert, ...fileOptions }\n      const headers: Record<string, string> = {\n        ...this.headers,\n        ...{ 'x-upsert': String(options.upsert as boolean) },\n      }\n\n      if (typeof Blob !== 'undefined' && fileBody instanceof Blob) {\n        body = new FormData()\n        body.append('cacheControl', options.cacheControl as string)\n        body.append('', fileBody)\n      } else if (typeof FormData !== 'undefined' && fileBody instanceof FormData) {\n        body = fileBody\n        body.append('cacheControl', options.cacheControl as string)\n      } else {\n        body = fileBody\n        headers['cache-control'] = `max-age=${options.cacheControl}`\n        headers['content-type'] = options.contentType as string\n      }\n\n      const data = await put(this.fetch, url.toString(), body as object, { headers })\n\n      return {\n        data: { path: cleanPath, fullPath: data.Key },\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Creates a signed upload URL.\n   * Signed upload URLs can be used to upload files to the bucket without further authentication.\n   * They are valid for 2 hours.\n   *\n   * @category File Buckets\n   * @param path The file path, including the current file name. For example `folder/image.png`.\n   * @param options.upsert If set to true, allows the file to be overwritten if it already exists.\n   * @returns Promise with response containing signed upload URL, token, and path or error\n   *\n   * @example Create Signed Upload URL\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUploadUrl('folder/cat.jpg')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"signedUrl\": \"https://example.supabase.co/storage/v1/object/upload/sign/avatars/folder/cat.jpg?token=<TOKEN>\",\n   *     \"path\": \"folder/cat.jpg\",\n   *     \"token\": \"<TOKEN>\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createSignedUploadUrl(\n    path: string,\n    options?: { upsert: boolean }\n  ): Promise<\n    | {\n        data: { signedUrl: string; token: string; path: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      let _path = this._getFinalPath(path)\n\n      const headers = { ...this.headers }\n\n      if (options?.upsert) {\n        headers['x-upsert'] = 'true'\n      }\n\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/upload/sign/${_path}`,\n        {},\n        { headers }\n      )\n\n      const url = new URL(this.url + data.url)\n\n      const token = url.searchParams.get('token')\n\n      if (!token) {\n        throw new StorageError('No token returned by API')\n      }\n\n      return { data: { signedUrl: url.toString(), path, token }, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Replaces an existing file at the specified path with a new one.\n   *\n   * @category File Buckets\n   * @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to update.\n   * @param fileBody The body of the file to be stored in the bucket.\n   * @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\n   * @returns Promise with response containing file path, id, and fullPath or error\n   *\n   * @example Update file\n   * ```js\n   * const avatarFile = event.target.files[0]\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .update('public/avatar1.png', avatarFile, {\n   *     cacheControl: '3600',\n   *     upsert: true\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"public/avatar1.png\",\n   *     \"fullPath\": \"avatars/public/avatar1.png\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Update file using `ArrayBuffer` from base64 file data\n   * ```js\n   * import {decode} from 'base64-arraybuffer'\n   *\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .update('public/avatar1.png', decode('base64FileData'), {\n   *     contentType: 'image/png'\n   *   })\n   * ```\n   */\n  async update(\n    path: string,\n    fileBody:\n      | ArrayBuffer\n      | ArrayBufferView\n      | Blob\n      | Buffer\n      | File\n      | FormData\n      | NodeJS.ReadableStream\n      | ReadableStream<Uint8Array>\n      | URLSearchParams\n      | string,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.uploadOrUpdate('PUT', path, fileBody, fileOptions)\n  }\n\n  /**\n   * Moves an existing file to a new path in the same bucket.\n   *\n   * @category File Buckets\n   * @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n   * @param toPath The new file path, including the new file name. For example `folder/image-new.png`.\n   * @param options The destination options.\n   * @returns Promise with response containing success message or error\n   *\n   * @example Move file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .move('public/avatar1.png', 'private/avatar2.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully moved\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async move(\n    fromPath: string,\n    toPath: string,\n    options?: DestinationOptions\n  ): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/move`,\n        {\n          bucketId: this.bucketId,\n          sourceKey: fromPath,\n          destinationKey: toPath,\n          destinationBucket: options?.destinationBucket,\n        },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Copies an existing file to a new path in the same bucket.\n   *\n   * @category File Buckets\n   * @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n   * @param toPath The new file path, including the new file name. For example `folder/image-copy.png`.\n   * @param options The destination options.\n   * @returns Promise with response containing copied file path or error\n   *\n   * @example Copy file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .copy('public/avatar1.png', 'private/avatar2.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"avatars/private/avatar2.png\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async copy(\n    fromPath: string,\n    toPath: string,\n    options?: DestinationOptions\n  ): Promise<\n    | {\n        data: { path: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/copy`,\n        {\n          bucketId: this.bucketId,\n          sourceKey: fromPath,\n          destinationKey: toPath,\n          destinationBucket: options?.destinationBucket,\n        },\n        { headers: this.headers }\n      )\n      return { data: { path: data.Key }, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Creates a signed URL. Use a signed URL to share a file for a fixed amount of time.\n   *\n   * @category File Buckets\n   * @param path The file path, including the current file name. For example `folder/image.png`.\n   * @param expiresIn The number of seconds until the signed URL expires. For example, `60` for a URL which is valid for one minute.\n   * @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   * @param options.transform Transform the asset before serving it to the client.\n   * @returns Promise with response containing signed URL or error\n   *\n   * @example Create Signed URL\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrl('folder/avatar1.png', 60)\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Create a signed URL for an asset with transformations\n   * ```js\n   * const { data } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrl('folder/avatar1.png', 60, {\n   *     transform: {\n   *       width: 100,\n   *       height: 100,\n   *     }\n   *   })\n   * ```\n   *\n   * @example Create a signed URL which triggers the download of the asset\n   * ```js\n   * const { data } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrl('folder/avatar1.png', 60, {\n   *     download: true,\n   *   })\n   * ```\n   */\n  async createSignedUrl(\n    path: string,\n    expiresIn: number,\n    options?: { download?: string | boolean; transform?: TransformOptions }\n  ): Promise<\n    | {\n        data: { signedUrl: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      let _path = this._getFinalPath(path)\n\n      let data = await post(\n        this.fetch,\n        `${this.url}/object/sign/${_path}`,\n        { expiresIn, ...(options?.transform ? { transform: options.transform } : {}) },\n        { headers: this.headers }\n      )\n      const downloadQueryParam = options?.download\n        ? `&download=${options.download === true ? '' : options.download}`\n        : ''\n      const signedUrl = encodeURI(`${this.url}${data.signedURL}${downloadQueryParam}`)\n      data = { signedUrl }\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Creates multiple signed URLs. Use a signed URL to share a file for a fixed amount of time.\n   *\n   * @category File Buckets\n   * @param paths The file paths to be downloaded, including the current file names. For example `['folder/image.png', 'folder2/image2.png']`.\n   * @param expiresIn The number of seconds until the signed URLs expire. For example, `60` for URLs which are valid for one minute.\n   * @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   * @returns Promise with response containing array of objects with signedUrl, path, and error or error\n   *\n   * @example Create Signed URLs\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrls(['folder/avatar1.png', 'folder/avatar2.png'], 60)\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [\n   *     {\n   *       \"error\": null,\n   *       \"path\": \"folder/avatar1.png\",\n   *       \"signedURL\": \"/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\",\n   *       \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\"\n   *     },\n   *     {\n   *       \"error\": null,\n   *       \"path\": \"folder/avatar2.png\",\n   *       \"signedURL\": \"/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\",\n   *       \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\"\n   *     }\n   *   ],\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createSignedUrls(\n    paths: string[],\n    expiresIn: number,\n    options?: { download: string | boolean }\n  ): Promise<\n    | {\n        data: { error: string | null; path: string | null; signedUrl: string }[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/sign/${this.bucketId}`,\n        { expiresIn, paths },\n        { headers: this.headers }\n      )\n\n      const downloadQueryParam = options?.download\n        ? `&download=${options.download === true ? '' : options.download}`\n        : ''\n      return {\n        data: data.map((datum: { signedURL: string }) => ({\n          ...datum,\n          signedUrl: datum.signedURL\n            ? encodeURI(`${this.url}${datum.signedURL}${downloadQueryParam}`)\n            : null,\n        })),\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Downloads a file from a private bucket. For public buckets, make a request to the URL returned from `getPublicUrl` instead.\n   *\n   * @category File Buckets\n   * @param path The full path and file name of the file to be downloaded. For example `folder/image.png`.\n   * @param options.transform Transform the asset before serving it to the client.\n   * @returns BlobDownloadBuilder instance for downloading the file\n   *\n   * @example Download file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .download('folder/avatar1.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": <BLOB>,\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Download file with transformations\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .download('folder/avatar1.png', {\n   *     transform: {\n   *       width: 100,\n   *       height: 100,\n   *       quality: 80\n   *     }\n   *   })\n   * ```\n   */\n  download<Options extends { transform?: TransformOptions }>(\n    path: string,\n    options?: Options\n  ): BlobDownloadBuilder {\n    const wantsTransformation = typeof options?.transform !== 'undefined'\n    const renderPath = wantsTransformation ? 'render/image/authenticated' : 'object'\n    const transformationQuery = this.transformOptsToQueryString(options?.transform || {})\n    const queryString = transformationQuery ? `?${transformationQuery}` : ''\n    const _path = this._getFinalPath(path)\n    const downloadFn = () =>\n      get(this.fetch, `${this.url}/${renderPath}/${_path}${queryString}`, {\n        headers: this.headers,\n        noResolveJson: true,\n      })\n    return new BlobDownloadBuilder(downloadFn, this.shouldThrowOnError)\n  }\n\n  /**\n   * Retrieves the details of an existing file.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. For example `folder/image.png`.\n   * @returns Promise with response containing file metadata or error\n   *\n   * @example Get file info\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .info('folder/avatar1.png')\n   * ```\n   */\n  async info(path: string): Promise<\n    | {\n        data: Camelize<FileObjectV2>\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    const _path = this._getFinalPath(path)\n\n    try {\n      const data = await get(this.fetch, `${this.url}/object/info/${_path}`, {\n        headers: this.headers,\n      })\n\n      return { data: recursiveToCamel(data) as Camelize<FileObjectV2>, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Checks the existence of a file.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. For example `folder/image.png`.\n   * @returns Promise with response containing boolean indicating file existence or error\n   *\n   * @example Check file existence\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .exists('folder/avatar1.png')\n   * ```\n   */\n  async exists(path: string): Promise<\n    | {\n        data: boolean\n        error: null\n      }\n    | {\n        data: boolean\n        error: StorageError\n      }\n  > {\n    const _path = this._getFinalPath(path)\n\n    try {\n      await head(this.fetch, `${this.url}/object/${_path}`, {\n        headers: this.headers,\n      })\n\n      return { data: true, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error) && error instanceof StorageUnknownError) {\n        const originalError = error.originalError as unknown as { status: number }\n\n        if ([400, 404].includes(originalError?.status)) {\n          return { data: false, error }\n        }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * A simple convenience function to get the URL for an asset in a public bucket. If you do not want to use this function, you can construct the public URL by concatenating the bucket URL with the path to the asset.\n   * This function does not verify if the bucket is public. If a public URL is created for a bucket which is not public, you will not be able to download the asset.\n   *\n   * @category File Buckets\n   * @param path The path and name of the file to generate the public URL for. For example `folder/image.png`.\n   * @param options.download Triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   * @param options.transform Transform the asset before serving it to the client.\n   * @returns Object with public URL\n   *\n   * @example Returns the URL for an asset in a public bucket\n   * ```js\n   * const { data } = supabase\n   *   .storage\n   *   .from('public-bucket')\n   *   .getPublicUrl('folder/avatar1.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"publicUrl\": \"https://example.supabase.co/storage/v1/object/public/public-bucket/folder/avatar1.png\"\n   *   }\n   * }\n   * ```\n   *\n   * @example Returns the URL for an asset in a public bucket with transformations\n   * ```js\n   * const { data } = supabase\n   *   .storage\n   *   .from('public-bucket')\n   *   .getPublicUrl('folder/avatar1.png', {\n   *     transform: {\n   *       width: 100,\n   *       height: 100,\n   *     }\n   *   })\n   * ```\n   *\n   * @example Returns the URL which triggers the download of an asset in a public bucket\n   * ```js\n   * const { data } = supabase\n   *   .storage\n   *   .from('public-bucket')\n   *   .getPublicUrl('folder/avatar1.png', {\n   *     download: true,\n   *   })\n   * ```\n   */\n  getPublicUrl(\n    path: string,\n    options?: { download?: string | boolean; transform?: TransformOptions }\n  ): { data: { publicUrl: string } } {\n    const _path = this._getFinalPath(path)\n    const _queryString: string[] = []\n\n    const downloadQueryParam = options?.download\n      ? `download=${options.download === true ? '' : options.download}`\n      : ''\n\n    if (downloadQueryParam !== '') {\n      _queryString.push(downloadQueryParam)\n    }\n\n    const wantsTransformation = typeof options?.transform !== 'undefined'\n    const renderPath = wantsTransformation ? 'render/image' : 'object'\n    const transformationQuery = this.transformOptsToQueryString(options?.transform || {})\n\n    if (transformationQuery !== '') {\n      _queryString.push(transformationQuery)\n    }\n\n    let queryString = _queryString.join('&')\n    if (queryString !== '') {\n      queryString = `?${queryString}`\n    }\n\n    return {\n      data: { publicUrl: encodeURI(`${this.url}/${renderPath}/public/${_path}${queryString}`) },\n    }\n  }\n\n  /**\n   * Deletes files within the same bucket\n   *\n   * @category File Buckets\n   * @param paths An array of files to delete, including the path and file name. For example [`'folder/image.png'`].\n   * @returns Promise with response containing array of deleted file objects or error\n   *\n   * @example Delete file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .remove(['folder/avatar1.png'])\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [],\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async remove(paths: string[]): Promise<\n    | {\n        data: FileObject[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await remove(\n        this.fetch,\n        `${this.url}/object/${this.bucketId}`,\n        { prefixes: paths },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Get file metadata\n   * @param id the file id to retrieve metadata\n   */\n  // async getMetadata(\n  //   id: string\n  // ): Promise<\n  //   | {\n  //       data: Metadata\n  //       error: null\n  //     }\n  //   | {\n  //       data: null\n  //       error: StorageError\n  //     }\n  // > {\n  //   try {\n  //     const data = await get(this.fetch, `${this.url}/metadata/${id}`, { headers: this.headers })\n  //     return { data, error: null }\n  //   } catch (error) {\n  //     if (isStorageError(error)) {\n  //       return { data: null, error }\n  //     }\n\n  //     throw error\n  //   }\n  // }\n\n  /**\n   * Update file metadata\n   * @param id the file id to update metadata\n   * @param meta the new file metadata\n   */\n  // async updateMetadata(\n  //   id: string,\n  //   meta: Metadata\n  // ): Promise<\n  //   | {\n  //       data: Metadata\n  //       error: null\n  //     }\n  //   | {\n  //       data: null\n  //       error: StorageError\n  //     }\n  // > {\n  //   try {\n  //     const data = await post(\n  //       this.fetch,\n  //       `${this.url}/metadata/${id}`,\n  //       { ...meta },\n  //       { headers: this.headers }\n  //     )\n  //     return { data, error: null }\n  //   } catch (error) {\n  //     if (isStorageError(error)) {\n  //       return { data: null, error }\n  //     }\n\n  //     throw error\n  //   }\n  // }\n\n  /**\n   * Lists all the files and folders within a path of the bucket.\n   *\n   * @category File Buckets\n   * @param path The folder path.\n   * @param options Search options including limit (defaults to 100), offset, sortBy, and search\n   * @param parameters Optional fetch parameters including signal for cancellation\n   * @returns Promise with response containing array of files or error\n   *\n   * @example List files in a bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .list('folder', {\n   *     limit: 100,\n   *     offset: 0,\n   *     sortBy: { column: 'name', order: 'asc' },\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [\n   *     {\n   *       \"name\": \"avatar1.png\",\n   *       \"id\": \"e668cf7f-821b-4a2f-9dce-7dfa5dd1cfd2\",\n   *       \"updated_at\": \"2024-05-22T23:06:05.580Z\",\n   *       \"created_at\": \"2024-05-22T23:04:34.443Z\",\n   *       \"last_accessed_at\": \"2024-05-22T23:04:34.443Z\",\n   *       \"metadata\": {\n   *         \"eTag\": \"\\\"c5e8c553235d9af30ef4f6e280790b92\\\"\",\n   *         \"size\": 32175,\n   *         \"mimetype\": \"image/png\",\n   *         \"cacheControl\": \"max-age=3600\",\n   *         \"lastModified\": \"2024-05-22T23:06:05.574Z\",\n   *         \"contentLength\": 32175,\n   *         \"httpStatusCode\": 200\n   *       }\n   *     }\n   *   ],\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Search files in a bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .list('folder', {\n   *     limit: 100,\n   *     offset: 0,\n   *     sortBy: { column: 'name', order: 'asc' },\n   *     search: 'jon'\n   *   })\n   * ```\n   */\n  async list(\n    path?: string,\n    options?: SearchOptions,\n    parameters?: FetchParameters\n  ): Promise<\n    | {\n        data: FileObject[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const body = { ...DEFAULT_SEARCH_OPTIONS, ...options, prefix: path || '' }\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/list/${this.bucketId}`,\n        body,\n        { headers: this.headers },\n        parameters\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * @experimental this method signature might change in the future\n   *\n   * @category File Buckets\n   * @param options search options\n   * @param parameters\n   */\n  async listV2(\n    options?: SearchV2Options,\n    parameters?: FetchParameters\n  ): Promise<\n    | {\n        data: SearchV2Result\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const body = { ...options }\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/list-v2/${this.bucketId}`,\n        body,\n        { headers: this.headers },\n        parameters\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  protected encodeMetadata(metadata: Record<string, any>) {\n    return JSON.stringify(metadata)\n  }\n\n  toBase64(data: string) {\n    if (typeof Buffer !== 'undefined') {\n      return Buffer.from(data).toString('base64')\n    }\n    return btoa(data)\n  }\n\n  private _getFinalPath(path: string) {\n    return `${this.bucketId}/${path.replace(/^\\/+/, '')}`\n  }\n\n  private _removeEmptyFolders(path: string) {\n    return path.replace(/^\\/|\\/$/g, '').replace(/\\/+/g, '/')\n  }\n\n  private transformOptsToQueryString(transform: TransformOptions) {\n    const params: string[] = []\n    if (transform.width) {\n      params.push(`width=${transform.width}`)\n    }\n\n    if (transform.height) {\n      params.push(`height=${transform.height}`)\n    }\n\n    if (transform.resize) {\n      params.push(`resize=${transform.resize}`)\n    }\n\n    if (transform.format) {\n      params.push(`format=${transform.format}`)\n    }\n\n    if (transform.quality) {\n      params.push(`quality=${transform.quality}`)\n    }\n\n    return params.join('&')\n  }\n}\n","// Generated automatically during releases by scripts/update-version-files.ts\n// This file provides runtime access to the package version for:\n// - HTTP request headers (e.g., X-Client-Info header for API requests)\n// - Debugging and support (identifying which version is running)\n// - Telemetry and logging (version reporting in errors/analytics)\n// - Ensuring build artifacts match the published package version\nexport const version = '2.90.1'\n","import { version } from './version'\nexport const DEFAULT_HEADERS = {\n  'X-Client-Info': `storage-js/${version}`,\n}\n","import { DEFAULT_HEADERS } from '../lib/constants'\nimport { isStorageError, StorageError } from '../lib/errors'\nimport { Fetch, get, post, put, remove } from '../lib/fetch'\nimport { resolveFetch } from '../lib/helpers'\nimport { Bucket, BucketType, ListBucketOptions } from '../lib/types'\nimport { StorageClientOptions } from '../StorageClient'\n\nexport default class StorageBucketApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    fetch?: Fetch,\n    opts?: StorageClientOptions\n  ) {\n    const baseUrl = new URL(url)\n\n    // if legacy uri is used, replace with new storage host (disables request buffering to allow > 50GB uploads)\n    // \"project-ref.supabase.co\" becomes \"project-ref.storage.supabase.co\"\n    if (opts?.useNewHostname) {\n      const isSupabaseHost = /supabase\\.(co|in|red)$/.test(baseUrl.hostname)\n      if (isSupabaseHost && !baseUrl.hostname.includes('storage.supabase.')) {\n        baseUrl.hostname = baseUrl.hostname.replace('supabase.', 'storage.supabase.')\n      }\n    }\n\n    this.url = baseUrl.href.replace(/\\/$/, '')\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /**\n   * Enable throwing errors instead of returning them.\n   *\n   * @category File Buckets\n   */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /**\n   * Retrieves the details of all Storage buckets within an existing project.\n   *\n   * @category File Buckets\n   * @param options Query parameters for listing buckets\n   * @param options.limit Maximum number of buckets to return\n   * @param options.offset Number of buckets to skip\n   * @param options.sortColumn Column to sort by ('id', 'name', 'created_at', 'updated_at')\n   * @param options.sortOrder Sort order ('asc' or 'desc')\n   * @param options.search Search term to filter bucket names\n   * @returns Promise with response containing array of buckets or error\n   *\n   * @example List buckets\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .listBuckets()\n   * ```\n   *\n   * @example List buckets with options\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .listBuckets({\n   *     limit: 10,\n   *     offset: 0,\n   *     sortColumn: 'created_at',\n   *     sortOrder: 'desc',\n   *     search: 'prod'\n   *   })\n   * ```\n   */\n  async listBuckets(options?: ListBucketOptions): Promise<\n    | {\n        data: Bucket[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const queryString = this.listBucketOptionsToQueryString(options)\n      const data = await get(this.fetch, `${this.url}/bucket${queryString}`, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Retrieves the details of an existing Storage bucket.\n   *\n   * @category File Buckets\n   * @param id The unique identifier of the bucket you would like to retrieve.\n   * @returns Promise with response containing bucket details or error\n   *\n   * @example Get bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .getBucket('avatars')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"id\": \"avatars\",\n   *     \"name\": \"avatars\",\n   *     \"owner\": \"\",\n   *     \"public\": false,\n   *     \"file_size_limit\": 1024,\n   *     \"allowed_mime_types\": [\n   *       \"image/png\"\n   *     ],\n   *     \"created_at\": \"2024-05-22T22:26:05.100Z\",\n   *     \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async getBucket(id: string): Promise<\n    | {\n        data: Bucket\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await get(this.fetch, `${this.url}/bucket/${id}`, { headers: this.headers })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Creates a new Storage bucket\n   *\n   * @category File Buckets\n   * @param id A unique identifier for the bucket you are creating.\n   * @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations. By default, buckets are private.\n   * @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n   * The global file size limit takes precedence over this value.\n   * The default value is null, which doesn't set a per bucket file size limit.\n   * @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n   * The default value is null, which allows files with all mime types to be uploaded.\n   * Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n   * @param options.type (private-beta) specifies the bucket type. see `BucketType` for more details.\n   *   - default bucket type is `STANDARD`\n   * @returns Promise with response containing newly created bucket name or error\n   *\n   * @example Create bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .createBucket('avatars', {\n   *     public: false,\n   *     allowedMimeTypes: ['image/png'],\n   *     fileSizeLimit: 1024\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"name\": \"avatars\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createBucket(\n    id: string,\n    options: {\n      public: boolean\n      fileSizeLimit?: number | string | null\n      allowedMimeTypes?: string[] | null\n      type?: BucketType\n    } = {\n      public: false,\n    }\n  ): Promise<\n    | {\n        data: Pick<Bucket, 'name'>\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/bucket`,\n        {\n          id,\n          name: id,\n          type: options.type,\n          public: options.public,\n          file_size_limit: options.fileSizeLimit,\n          allowed_mime_types: options.allowedMimeTypes,\n        },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Updates a Storage bucket\n   *\n   * @category File Buckets\n   * @param id A unique identifier for the bucket you are updating.\n   * @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations.\n   * @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n   * The global file size limit takes precedence over this value.\n   * The default value is null, which doesn't set a per bucket file size limit.\n   * @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n   * The default value is null, which allows files with all mime types to be uploaded.\n   * Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n   * @returns Promise with response containing success message or error\n   *\n   * @example Update bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .updateBucket('avatars', {\n   *     public: false,\n   *     allowedMimeTypes: ['image/png'],\n   *     fileSizeLimit: 1024\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully updated\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async updateBucket(\n    id: string,\n    options: {\n      public: boolean\n      fileSizeLimit?: number | string | null\n      allowedMimeTypes?: string[] | null\n    }\n  ): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await put(\n        this.fetch,\n        `${this.url}/bucket/${id}`,\n        {\n          id,\n          name: id,\n          public: options.public,\n          file_size_limit: options.fileSizeLimit,\n          allowed_mime_types: options.allowedMimeTypes,\n        },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Removes all objects inside a single bucket.\n   *\n   * @category File Buckets\n   * @param id The unique identifier of the bucket you would like to empty.\n   * @returns Promise with success message or error\n   *\n   * @example Empty bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .emptyBucket('avatars')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully emptied\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async emptyBucket(id: string): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/bucket/${id}/empty`,\n        {},\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Deletes an existing bucket. A bucket can't be deleted with existing objects inside it.\n   * You must first `empty()` the bucket.\n   *\n   * @category File Buckets\n   * @param id The unique identifier of the bucket you would like to delete.\n   * @returns Promise with success message or error\n   *\n   * @example Delete bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .deleteBucket('avatars')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully deleted\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async deleteBucket(id: string): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await remove(\n        this.fetch,\n        `${this.url}/bucket/${id}`,\n        {},\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  private listBucketOptionsToQueryString(options?: ListBucketOptions): string {\n    const params: Record<string, string> = {}\n    if (options) {\n      if ('limit' in options) {\n        params.limit = String(options.limit)\n      }\n      if ('offset' in options) {\n        params.offset = String(options.offset)\n      }\n      if (options.search) {\n        params.search = options.search\n      }\n      if (options.sortColumn) {\n        params.sortColumn = options.sortColumn\n      }\n      if (options.sortOrder) {\n        params.sortOrder = options.sortOrder\n      }\n    }\n    return Object.keys(params).length > 0 ? '?' + new URLSearchParams(params).toString() : ''\n  }\n}\n","import { IcebergRestCatalog, IcebergError } from 'iceberg-js'\nimport { DEFAULT_HEADERS } from '../lib/constants'\nimport { isStorageError, StorageError } from '../lib/errors'\nimport { Fetch, get, post, remove } from '../lib/fetch'\nimport { isValidBucketName, resolveFetch } from '../lib/helpers'\nimport { AnalyticBucket } from '../lib/types'\n\ntype WrapAsyncMethod<T> = T extends (...args: infer A) => Promise<infer R>\n  ? (...args: A) => Promise<{ data: R; error: null } | { data: null; error: IcebergError }>\n  : T\n\nexport type WrappedIcebergRestCatalog = {\n  [K in keyof IcebergRestCatalog]: WrapAsyncMethod<IcebergRestCatalog[K]>\n}\n\n/**\n * Client class for managing Analytics Buckets using Iceberg tables\n * Provides methods for creating, listing, and deleting analytics buckets\n */\nexport default class StorageAnalyticsClient {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  /**\n   * @alpha\n   *\n   * Creates a new StorageAnalyticsClient instance\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param url - The base URL for the storage API\n   * @param headers - HTTP headers to include in requests\n   * @param fetch - Optional custom fetch implementation\n   *\n   * @example\n   * ```typescript\n   * const client = new StorageAnalyticsClient(url, headers)\n   * ```\n   */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    this.url = url.replace(/\\/$/, '')\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /**\n   * @alpha\n   *\n   * Enable throwing errors instead of returning them in the response\n   * When enabled, failed operations will throw instead of returning { data: null, error }\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @returns This instance for method chaining\n   */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /**\n   * @alpha\n   *\n   * Creates a new analytics bucket using Iceberg tables\n   * Analytics buckets are optimized for analytical queries and data processing\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param name A unique name for the bucket you are creating\n   * @returns Promise with response containing newly created analytics bucket or error\n   *\n   * @example Create analytics bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .analytics\n   *   .createBucket('analytics-data')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"name\": \"analytics-data\",\n   *     \"type\": \"ANALYTICS\",\n   *     \"format\": \"iceberg\",\n   *     \"created_at\": \"2024-05-22T22:26:05.100Z\",\n   *     \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createBucket(name: string): Promise<\n    | {\n        data: AnalyticBucket\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(this.fetch, `${this.url}/bucket`, { name }, { headers: this.headers })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * @alpha\n   *\n   * Retrieves the details of all Analytics Storage buckets within an existing project\n   * Only returns buckets of type 'ANALYTICS'\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param options Query parameters for listing buckets\n   * @param options.limit Maximum number of buckets to return\n   * @param options.offset Number of buckets to skip\n   * @param options.sortColumn Column to sort by ('name', 'created_at', 'updated_at')\n   * @param options.sortOrder Sort order ('asc' or 'desc')\n   * @param options.search Search term to filter bucket names\n   * @returns Promise with response containing array of analytics buckets or error\n   *\n   * @example List analytics buckets\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .analytics\n   *   .listBuckets({\n   *     limit: 10,\n   *     offset: 0,\n   *     sortColumn: 'created_at',\n   *     sortOrder: 'desc'\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [\n   *     {\n   *       \"name\": \"analytics-data\",\n   *       \"type\": \"ANALYTICS\",\n   *       \"format\": \"iceberg\",\n   *       \"created_at\": \"2024-05-22T22:26:05.100Z\",\n   *       \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n   *     }\n   *   ],\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async listBuckets(options?: {\n    limit?: number\n    offset?: number\n    sortColumn?: 'name' | 'created_at' | 'updated_at'\n    sortOrder?: 'asc' | 'desc'\n    search?: string\n  }): Promise<\n    | {\n        data: AnalyticBucket[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      // Build query string from options\n      const queryParams = new URLSearchParams()\n      if (options?.limit !== undefined) queryParams.set('limit', options.limit.toString())\n      if (options?.offset !== undefined) queryParams.set('offset', options.offset.toString())\n      if (options?.sortColumn) queryParams.set('sortColumn', options.sortColumn)\n      if (options?.sortOrder) queryParams.set('sortOrder', options.sortOrder)\n      if (options?.search) queryParams.set('search', options.search)\n\n      const queryString = queryParams.toString()\n      const url = queryString ? `${this.url}/bucket?${queryString}` : `${this.url}/bucket`\n\n      const data = await get(this.fetch, url, { headers: this.headers })\n\n      return { data: data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * @alpha\n   *\n   * Deletes an existing analytics bucket\n   * A bucket can't be deleted with existing objects inside it\n   * You must first empty the bucket before deletion\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param bucketName The unique identifier of the bucket you would like to delete\n   * @returns Promise with response containing success message or error\n   *\n   * @example Delete analytics bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .analytics\n   *   .deleteBucket('analytics-data')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully deleted\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async deleteBucket(bucketName: string): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await remove(\n        this.fetch,\n        `${this.url}/bucket/${bucketName}`,\n        {},\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * @alpha\n   *\n   * Get an Iceberg REST Catalog client configured for a specific analytics bucket\n   * Use this to perform advanced table and namespace operations within the bucket\n   * The returned client provides full access to the Apache Iceberg REST Catalog API\n   * with the Supabase `{ data, error }` pattern for consistent error handling on all operations.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param bucketName - The name of the analytics bucket (warehouse) to connect to\n   * @returns The wrapped Iceberg catalog client\n   * @throws {StorageError} If the bucket name is invalid\n   *\n   * @example Get catalog and create table\n   * ```js\n   * // First, create an analytics bucket\n   * const { data: bucket, error: bucketError } = await supabase\n   *   .storage\n   *   .analytics\n   *   .createBucket('analytics-data')\n   *\n   * // Get the Iceberg catalog for that bucket\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // Create a namespace\n   * const { error: nsError } = await catalog.createNamespace({ namespace: ['default'] })\n   *\n   * // Create a table with schema\n   * const { data: tableMetadata, error: tableError } = await catalog.createTable(\n   *   { namespace: ['default'] },\n   *   {\n   *     name: 'events',\n   *     schema: {\n   *       type: 'struct',\n   *       fields: [\n   *         { id: 1, name: 'id', type: 'long', required: true },\n   *         { id: 2, name: 'timestamp', type: 'timestamp', required: true },\n   *         { id: 3, name: 'user_id', type: 'string', required: false }\n   *       ],\n   *       'schema-id': 0,\n   *       'identifier-field-ids': [1]\n   *     },\n   *     'partition-spec': {\n   *       'spec-id': 0,\n   *       fields: []\n   *     },\n   *     'write-order': {\n   *       'order-id': 0,\n   *       fields: []\n   *     },\n   *     properties: {\n   *       'write.format.default': 'parquet'\n   *     }\n   *   }\n   * )\n   * ```\n   *\n   * @example List tables in namespace\n   * ```js\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // List all tables in the default namespace\n   * const { data: tables, error: listError } = await catalog.listTables({ namespace: ['default'] })\n   * if (listError) {\n   *   if (listError.isNotFound()) {\n   *     console.log('Namespace not found')\n   *   }\n   *   return\n   * }\n   * console.log(tables) // [{ namespace: ['default'], name: 'events' }]\n   * ```\n   *\n   * @example Working with namespaces\n   * ```js\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // List all namespaces\n   * const { data: namespaces } = await catalog.listNamespaces()\n   *\n   * // Create namespace with properties\n   * await catalog.createNamespace(\n   *   { namespace: ['production'] },\n   *   { properties: { owner: 'data-team', env: 'prod' } }\n   * )\n   * ```\n   *\n   * @example Cleanup operations\n   * ```js\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // Drop table with purge option (removes all data)\n   * const { error: dropError } = await catalog.dropTable(\n   *   { namespace: ['default'], name: 'events' },\n   *   { purge: true }\n   * )\n   *\n   * if (dropError?.isNotFound()) {\n   *   console.log('Table does not exist')\n   * }\n   *\n   * // Drop namespace (must be empty)\n   * await catalog.dropNamespace({ namespace: ['default'] })\n   * ```\n   *\n   * @remarks\n   * This method provides a bridge between Supabase's bucket management and the standard\n   * Apache Iceberg REST Catalog API. The bucket name maps to the Iceberg warehouse parameter.\n   * All authentication and configuration is handled automatically using your Supabase credentials.\n   *\n   * **Error Handling**: Invalid bucket names throw immediately. All catalog\n   * operations return `{ data, error }` where errors are `IcebergError` instances from iceberg-js.\n   * Use helper methods like `error.isNotFound()` or check `error.status` for specific error handling.\n   * Use `.throwOnError()` on the analytics client if you prefer exceptions for catalog operations.\n   *\n   * **Cleanup Operations**: When using `dropTable`, the `purge: true` option permanently\n   * deletes all table data. Without it, the table is marked as deleted but data remains.\n   *\n   * **Library Dependency**: The returned catalog wraps `IcebergRestCatalog` from iceberg-js.\n   * For complete API documentation and advanced usage, refer to the\n   * [iceberg-js documentation](https://supabase.github.io/iceberg-js/).\n   */\n  from(bucketName: string): WrappedIcebergRestCatalog {\n    // Validate bucket name using same rules as Supabase Storage API backend\n    if (!isValidBucketName(bucketName)) {\n      throw new StorageError(\n        'Invalid bucket name: File, folder, and bucket names must follow AWS object key naming guidelines ' +\n          'and should avoid the use of any other characters.'\n      )\n    }\n\n    // Construct the Iceberg REST Catalog URL\n    // The base URL is /storage/v1/iceberg\n    // Note: IcebergRestCatalog from iceberg-js automatically adds /v1/ prefix to API paths\n    // so we should NOT append /v1 here (it would cause double /v1/v1/ in the URL)\n    const catalog = new IcebergRestCatalog({\n      baseUrl: this.url,\n      catalogName: bucketName, // Maps to the warehouse parameter in Supabase's implementation\n      auth: {\n        type: 'custom',\n        getHeaders: async () => this.headers,\n      },\n      fetch: this.fetch,\n    })\n\n    const shouldThrowOnError = this.shouldThrowOnError\n\n    const wrappedCatalog = new Proxy(catalog, {\n      get(target, prop: keyof IcebergRestCatalog) {\n        const value = target[prop]\n        if (typeof value !== 'function') {\n          return value\n        }\n\n        return async (...args: unknown[]) => {\n          try {\n            const data = await (value as Function).apply(target, args)\n            return { data, error: null }\n          } catch (error) {\n            if (shouldThrowOnError) {\n              throw error\n            }\n            return { data: null, error: error as IcebergError }\n          }\n        }\n      },\n    }) as unknown as WrappedIcebergRestCatalog\n\n    return wrappedCatalog\n  }\n}\n","import { version } from '../version'\nexport const DEFAULT_HEADERS = {\n  'X-Client-Info': `storage-js/${version}`,\n  'Content-Type': 'application/json',\n}\n","/**\n * Base error class for all Storage Vectors errors\n */\nexport class StorageVectorsError extends Error {\n  protected __isStorageVectorsError = true\n\n  constructor(message: string) {\n    super(message)\n    this.name = 'StorageVectorsError'\n  }\n}\n\n/**\n * Type guard to check if an error is a StorageVectorsError\n * @param error - The error to check\n * @returns True if the error is a StorageVectorsError\n */\nexport function isStorageVectorsError(error: unknown): error is StorageVectorsError {\n  return typeof error === 'object' && error !== null && '__isStorageVectorsError' in error\n}\n\n/**\n * API error returned from S3 Vectors service\n * Includes HTTP status code and service-specific error code\n */\nexport class StorageVectorsApiError extends StorageVectorsError {\n  status: number\n  statusCode: string\n\n  constructor(message: string, status: number, statusCode: string) {\n    super(message)\n    this.name = 'StorageVectorsApiError'\n    this.status = status\n    this.statusCode = statusCode\n  }\n\n  toJSON() {\n    return {\n      name: this.name,\n      message: this.message,\n      status: this.status,\n      statusCode: this.statusCode,\n    }\n  }\n}\n\n/**\n * Unknown error that doesn't match expected error patterns\n * Wraps the original error for debugging\n */\nexport class StorageVectorsUnknownError extends StorageVectorsError {\n  originalError: unknown\n\n  constructor(message: string, originalError: unknown) {\n    super(message)\n    this.name = 'StorageVectorsUnknownError'\n    this.originalError = originalError\n  }\n}\n\n/**\n * Error codes specific to S3 Vectors API\n * Maps AWS service errors to application-friendly error codes\n */\nexport enum StorageVectorsErrorCode {\n  /** Internal server fault (HTTP 500) */\n  InternalError = 'InternalError',\n  /** Resource already exists / conflict (HTTP 409) */\n  S3VectorConflictException = 'S3VectorConflictException',\n  /** Resource not found (HTTP 404) */\n  S3VectorNotFoundException = 'S3VectorNotFoundException',\n  /** Delete bucket while not empty (HTTP 400) */\n  S3VectorBucketNotEmpty = 'S3VectorBucketNotEmpty',\n  /** Exceeds bucket quota/limit (HTTP 400) */\n  S3VectorMaxBucketsExceeded = 'S3VectorMaxBucketsExceeded',\n  /** Exceeds index quota/limit (HTTP 400) */\n  S3VectorMaxIndexesExceeded = 'S3VectorMaxIndexesExceeded',\n}\n","type Fetch = typeof fetch\n\n/**\n * Resolves the fetch implementation to use\n * Uses custom fetch if provided, otherwise uses native fetch\n *\n * @param customFetch - Optional custom fetch implementation\n * @returns Resolved fetch function\n */\nexport const resolveFetch = (customFetch?: Fetch): Fetch => {\n  if (customFetch) {\n    return (...args) => customFetch(...args)\n  }\n  return (...args) => fetch(...args)\n}\n\n/**\n * Resolves the Response constructor to use\n * Returns native Response constructor\n *\n * @returns Response constructor\n */\nexport const resolveResponse = (): typeof Response => {\n  return Response\n}\n\n/**\n * Determine if input is a plain object\n * An object is plain if it's created by either {}, new Object(), or Object.create(null)\n *\n * @param value - Value to check\n * @returns True if value is a plain object\n * @source https://github.com/sindresorhus/is-plain-obj\n */\nexport const isPlainObject = (value: object): boolean => {\n  if (typeof value !== 'object' || value === null) {\n    return false\n  }\n\n  const prototype = Object.getPrototypeOf(value)\n  return (\n    (prototype === null ||\n      prototype === Object.prototype ||\n      Object.getPrototypeOf(prototype) === null) &&\n    !(Symbol.toStringTag in value) &&\n    !(Symbol.iterator in value)\n  )\n}\n\n/**\n * Normalizes a number array to float32 format\n * Ensures all vector values are valid 32-bit floats\n *\n * @param values - Array of numbers to normalize\n * @returns Normalized float32 array\n */\nexport const normalizeToFloat32 = (values: number[]): number[] => {\n  // Use Float32Array to ensure proper precision\n  return Array.from(new Float32Array(values))\n}\n\n/**\n * Validates vector dimensions match expected dimension\n * Throws error if dimensions don't match\n *\n * @param vector - Vector data to validate\n * @param expectedDimension - Expected vector dimension\n * @throws Error if dimensions don't match\n */\nexport const validateVectorDimension = (\n  vector: { float32: number[] },\n  expectedDimension?: number\n): void => {\n  if (expectedDimension !== undefined && vector.float32.length !== expectedDimension) {\n    throw new Error(\n      `Vector dimension mismatch: expected ${expectedDimension}, got ${vector.float32.length}`\n    )\n  }\n}\n","import { StorageVectorsApiError, StorageVectorsUnknownError } from './errors'\nimport { isPlainObject, resolveResponse } from './helpers'\nimport { VectorFetchParameters } from './types'\n\nexport type Fetch = typeof fetch\n\n/**\n * Options for fetch requests\n * @property headers - Custom HTTP headers\n * @property noResolveJson - If true, return raw Response instead of parsing JSON\n */\nexport interface FetchOptions {\n  headers?: {\n    [key: string]: string\n  }\n  noResolveJson?: boolean\n}\n\n/**\n * HTTP methods supported by the API\n */\nexport type RequestMethodType = 'GET' | 'POST' | 'PUT' | 'DELETE'\n\n/**\n * Extracts error message from various error response formats\n * @param err - Error object from API\n * @returns Human-readable error message\n */\nconst _getErrorMessage = (err: any): string =>\n  err.msg || err.message || err.error_description || err.error || JSON.stringify(err)\n\n/**\n * Handles fetch errors and converts them to StorageVectors error types\n * @param error - The error caught from fetch\n * @param reject - Promise rejection function\n * @param options - Fetch options that may affect error handling\n */\nconst handleError = async (\n  error: unknown,\n  reject: (reason?: any) => void,\n  options?: FetchOptions\n) => {\n  // Check if error is a Response-like object (has status and ok properties)\n  // This is more reliable than instanceof which can fail across realms\n  const isResponseLike =\n    error &&\n    typeof error === 'object' &&\n    'status' in error &&\n    'ok' in error &&\n    typeof (error as any).status === 'number'\n\n  if (isResponseLike && !options?.noResolveJson) {\n    const status = (error as any).status || 500\n    const responseError = error as any\n\n    // Try to parse JSON body if available\n    if (typeof responseError.json === 'function') {\n      responseError\n        .json()\n        .then((err: any) => {\n          const statusCode = err?.statusCode || err?.code || status + ''\n          reject(new StorageVectorsApiError(_getErrorMessage(err), status, statusCode))\n        })\n        .catch(() => {\n          // If JSON parsing fails, create an ApiError with the HTTP status code\n          const statusCode = status + ''\n          const message = responseError.statusText || `HTTP ${status} error`\n          reject(new StorageVectorsApiError(message, status, statusCode))\n        })\n    } else {\n      // No json() method available, create error from status\n      const statusCode = status + ''\n      const message = responseError.statusText || `HTTP ${status} error`\n      reject(new StorageVectorsApiError(message, status, statusCode))\n    }\n  } else {\n    reject(new StorageVectorsUnknownError(_getErrorMessage(error), error))\n  }\n}\n\n/**\n * Builds request parameters for fetch calls\n * @param method - HTTP method\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters like AbortSignal\n * @param body - Request body (will be JSON stringified if plain object)\n * @returns Complete fetch request parameters\n */\nconst _getRequestParams = (\n  method: RequestMethodType,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters,\n  body?: object\n) => {\n  const params: { [k: string]: any } = { method, headers: options?.headers || {} }\n\n  if (method === 'GET' || !body) {\n    return params\n  }\n\n  if (isPlainObject(body)) {\n    params.headers = { 'Content-Type': 'application/json', ...options?.headers }\n    params.body = JSON.stringify(body)\n  } else {\n    params.body = body\n  }\n\n  return { ...params, ...parameters }\n}\n\n/**\n * Internal request handler that wraps fetch with error handling\n * @param fetcher - Fetch function to use\n * @param method - HTTP method\n * @param url - Request URL\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @param body - Request body\n * @returns Promise with parsed response or error\n */\nasync function _handleRequest(\n  fetcher: Fetch,\n  method: RequestMethodType,\n  url: string,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters,\n  body?: object\n): Promise<any> {\n  return new Promise((resolve, reject) => {\n    fetcher(url, _getRequestParams(method, options, parameters, body))\n      .then((result) => {\n        if (!result.ok) throw result\n        if (options?.noResolveJson) return result\n        // Handle empty responses (204, empty body)\n        const contentType = result.headers.get('content-type')\n        if (!contentType || !contentType.includes('application/json')) {\n          return {}\n        }\n        return result.json()\n      })\n      .then((data) => resolve(data))\n      .catch((error) => handleError(error, reject, options))\n  })\n}\n\n/**\n * Performs a GET request\n * @param fetcher - Fetch function to use\n * @param url - Request URL\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @returns Promise with parsed response\n */\nexport async function get(\n  fetcher: Fetch,\n  url: string,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'GET', url, options, parameters)\n}\n\n/**\n * Performs a POST request\n * @param fetcher - Fetch function to use\n * @param url - Request URL\n * @param body - Request body to be JSON stringified\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @returns Promise with parsed response\n */\nexport async function post(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'POST', url, options, parameters, body)\n}\n\n/**\n * Performs a PUT request\n * @param fetcher - Fetch function to use\n * @param url - Request URL\n * @param body - Request body to be JSON stringified\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @returns Promise with parsed response\n */\nexport async function put(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'PUT', url, options, parameters, body)\n}\n\n/**\n * Performs a DELETE request\n * @param fetcher - Fetch function to use\n * @param url - Request URL\n * @param body - Request body to be JSON stringified\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @returns Promise with parsed response\n */\nexport async function remove(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'DELETE', url, options, parameters, body)\n}\n","import { DEFAULT_HEADERS } from './constants'\nimport { isStorageVectorsError } from './errors'\nimport { Fetch, post } from './fetch'\nimport { resolveFetch } from './helpers'\nimport {\n  ApiResponse,\n  VectorIndex,\n  ListIndexesOptions,\n  ListIndexesResponse,\n  VectorDataType,\n  DistanceMetric,\n  MetadataConfiguration,\n} from './types'\n\n/**\n * @alpha\n *\n * Options for creating a vector index\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport interface CreateIndexOptions {\n  vectorBucketName: string\n  indexName: string\n  dataType: VectorDataType\n  dimension: number\n  distanceMetric: DistanceMetric\n  metadataConfiguration?: MetadataConfiguration\n}\n\n/**\n * @hidden\n * Base implementation for vector index operations.\n * Use {@link VectorBucketScope} via `supabase.storage.vectors.from('bucket')` instead.\n */\nexport default class VectorIndexApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  /** Creates a new VectorIndexApi instance */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    this.url = url.replace(/\\/$/, '')\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /** Enable throwing errors instead of returning them in the response */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /** Creates a new vector index within a bucket */\n  async createIndex(options: CreateIndexOptions): Promise<ApiResponse<undefined>> {\n    try {\n      const data = await post(this.fetch, `${this.url}/CreateIndex`, options, {\n        headers: this.headers,\n      })\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Retrieves metadata for a specific vector index */\n  async getIndex(\n    vectorBucketName: string,\n    indexName: string\n  ): Promise<ApiResponse<{ index: VectorIndex }>> {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/GetIndex`,\n        { vectorBucketName, indexName },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Lists vector indexes within a bucket with optional filtering and pagination */\n  async listIndexes(options: ListIndexesOptions): Promise<ApiResponse<ListIndexesResponse>> {\n    try {\n      const data = await post(this.fetch, `${this.url}/ListIndexes`, options, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Deletes a vector index and all its data */\n  async deleteIndex(vectorBucketName: string, indexName: string): Promise<ApiResponse<undefined>> {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/DeleteIndex`,\n        { vectorBucketName, indexName },\n        { headers: this.headers }\n      )\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n}\n","import { DEFAULT_HEADERS } from './constants'\nimport { isStorageVectorsError } from './errors'\nimport { Fetch, post } from './fetch'\nimport { resolveFetch } from './helpers'\nimport {\n  ApiResponse,\n  PutVectorsOptions,\n  GetVectorsOptions,\n  GetVectorsResponse,\n  DeleteVectorsOptions,\n  ListVectorsOptions,\n  ListVectorsResponse,\n  QueryVectorsOptions,\n  QueryVectorsResponse,\n} from './types'\n\n/**\n * @hidden\n * Base implementation for vector data operations.\n * Use {@link VectorIndexScope} via `supabase.storage.vectors.from('bucket').index('idx')` instead.\n */\nexport default class VectorDataApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  /** Creates a new VectorDataApi instance */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    this.url = url.replace(/\\/$/, '')\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /** Enable throwing errors instead of returning them in the response */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /** Inserts or updates vectors in batch (1-500 per request) */\n  async putVectors(options: PutVectorsOptions): Promise<ApiResponse<undefined>> {\n    try {\n      // Validate batch size\n      if (options.vectors.length < 1 || options.vectors.length > 500) {\n        throw new Error('Vector batch size must be between 1 and 500 items')\n      }\n\n      const data = await post(this.fetch, `${this.url}/PutVectors`, options, {\n        headers: this.headers,\n      })\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Retrieves vectors by their keys in batch */\n  async getVectors(options: GetVectorsOptions): Promise<ApiResponse<GetVectorsResponse>> {\n    try {\n      const data = await post(this.fetch, `${this.url}/GetVectors`, options, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Lists vectors in an index with pagination */\n  async listVectors(options: ListVectorsOptions): Promise<ApiResponse<ListVectorsResponse>> {\n    try {\n      // Validate segment configuration\n      if (options.segmentCount !== undefined) {\n        if (options.segmentCount < 1 || options.segmentCount > 16) {\n          throw new Error('segmentCount must be between 1 and 16')\n        }\n        if (options.segmentIndex !== undefined) {\n          if (options.segmentIndex < 0 || options.segmentIndex >= options.segmentCount) {\n            throw new Error(`segmentIndex must be between 0 and ${options.segmentCount - 1}`)\n          }\n        }\n      }\n\n      const data = await post(this.fetch, `${this.url}/ListVectors`, options, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Queries for similar vectors using approximate nearest neighbor search */\n  async queryVectors(options: QueryVectorsOptions): Promise<ApiResponse<QueryVectorsResponse>> {\n    try {\n      const data = await post(this.fetch, `${this.url}/QueryVectors`, options, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Deletes vectors by their keys in batch (1-500 per request) */\n  async deleteVectors(options: DeleteVectorsOptions): Promise<ApiResponse<undefined>> {\n    try {\n      // Validate batch size\n      if (options.keys.length < 1 || options.keys.length > 500) {\n        throw new Error('Keys batch size must be between 1 and 500 items')\n      }\n\n      const data = await post(this.fetch, `${this.url}/DeleteVectors`, options, {\n        headers: this.headers,\n      })\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n}\n","import { DEFAULT_HEADERS } from './constants'\nimport { isStorageVectorsError } from './errors'\nimport { Fetch, post } from './fetch'\nimport { resolveFetch } from './helpers'\nimport {\n  ApiResponse,\n  VectorBucket,\n  ListVectorBucketsOptions,\n  ListVectorBucketsResponse,\n} from './types'\n\n/**\n * @hidden\n * Base implementation for vector bucket operations.\n * Use {@link StorageVectorsClient} via `supabase.storage.vectors` instead.\n */\nexport default class VectorBucketApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  /** Creates a new VectorBucketApi instance */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    this.url = url.replace(/\\/$/, '')\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /** Enable throwing errors instead of returning them in the response */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /** Creates a new vector bucket */\n  async createBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/CreateVectorBucket`,\n        { vectorBucketName },\n        { headers: this.headers }\n      )\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Retrieves metadata for a specific vector bucket */\n  async getBucket(vectorBucketName: string): Promise<ApiResponse<{ vectorBucket: VectorBucket }>> {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/GetVectorBucket`,\n        { vectorBucketName },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Lists vector buckets with optional filtering and pagination */\n  async listBuckets(\n    options: ListVectorBucketsOptions = {}\n  ): Promise<ApiResponse<ListVectorBucketsResponse>> {\n    try {\n      const data = await post(this.fetch, `${this.url}/ListVectorBuckets`, options, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Deletes a vector bucket (must be empty first) */\n  async deleteBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/DeleteVectorBucket`,\n        { vectorBucketName },\n        { headers: this.headers }\n      )\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n}\n","import VectorIndexApi, { CreateIndexOptions } from './VectorIndexApi'\nimport VectorDataApi from './VectorDataApi'\nimport { Fetch } from './fetch'\nimport VectorBucketApi from './VectorBucketApi'\nimport {\n  ApiResponse,\n  DeleteVectorsOptions,\n  GetVectorsOptions,\n  ListIndexesOptions,\n  ListVectorsOptions,\n  ListVectorBucketsOptions,\n  ListVectorBucketsResponse,\n  PutVectorsOptions,\n  QueryVectorsOptions,\n  VectorBucket,\n} from './types'\n\n/**\n *\n * @alpha\n *\n * Configuration options for the Storage Vectors client\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport interface StorageVectorsClientOptions {\n  /**\n   * Custom headers to include in all requests\n   */\n  headers?: { [key: string]: string }\n  /**\n   * Custom fetch implementation (optional)\n   * Useful for testing or custom request handling\n   */\n  fetch?: Fetch\n}\n\n/**\n *\n * @alpha\n *\n * Main client for interacting with S3 Vectors API\n * Provides access to bucket, index, and vector data operations\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n *\n * **Usage Patterns:**\n *\n * ```typescript\n * const { data, error } = await supabase\n *  .storage\n *  .vectors\n *  .createBucket('embeddings-prod')\n *\n * // Access index operations via buckets\n * const bucket = supabase.storage.vectors.from('embeddings-prod')\n * await bucket.createIndex({\n *   indexName: 'documents',\n *   dataType: 'float32',\n *   dimension: 1536,\n *   distanceMetric: 'cosine'\n * })\n *\n * // Access vector operations via index\n * const index = bucket.index('documents')\n * await index.putVectors({\n *   vectors: [\n *     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\n *   ]\n * })\n *\n * // Query similar vectors\n * const { data } = await index.queryVectors({\n *   queryVector: { float32: [...] },\n *   topK: 5,\n *   returnDistance: true\n * })\n * ```\n */\nexport class StorageVectorsClient extends VectorBucketApi {\n  /**\n   * @alpha\n   *\n   * Creates a StorageVectorsClient that can manage buckets, indexes, and vectors.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param url - Base URL of the Storage Vectors REST API.\n   * @param options.headers - Optional headers (for example `Authorization`) applied to every request.\n   * @param options.fetch - Optional custom `fetch` implementation for non-browser runtimes.\n   *\n   * @example\n   * ```typescript\n   * const client = new StorageVectorsClient(url, options)\n   * ```\n   */\n  constructor(url: string, options: StorageVectorsClientOptions = {}) {\n    super(url, options.headers || {}, options.fetch)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access operations for a specific vector bucket\n   * Returns a scoped client for index and vector operations within the bucket\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Name of the vector bucket\n   * @returns Bucket-scoped client with index and vector operations\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * ```\n   */\n  from(vectorBucketName: string): VectorBucketScope {\n    return new VectorBucketScope(this.url, this.headers, vectorBucketName, this.fetch)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Creates a new vector bucket\n   * Vector buckets are containers for vector indexes and their data\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Unique name for the vector bucket\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .createBucket('embeddings-prod')\n   * ```\n   */\n  async createBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    return super.createBucket(vectorBucketName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Retrieves metadata for a specific vector bucket\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Name of the vector bucket\n   * @returns Promise with bucket metadata or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .getBucket('embeddings-prod')\n   *\n   * console.log('Bucket created:', data?.vectorBucket.creationTime)\n   * ```\n   */\n  async getBucket(vectorBucketName: string): Promise<ApiResponse<{ vectorBucket: VectorBucket }>> {\n    return super.getBucket(vectorBucketName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Lists all vector buckets with optional filtering and pagination\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Optional filters (prefix, maxResults, nextToken)\n   * @returns Promise with list of buckets or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .listBuckets({ prefix: 'embeddings-' })\n   *\n   * data?.vectorBuckets.forEach(bucket => {\n   *   console.log(bucket.vectorBucketName)\n   * })\n   * ```\n   */\n  async listBuckets(\n    options: ListVectorBucketsOptions = {}\n  ): Promise<ApiResponse<ListVectorBucketsResponse>> {\n    return super.listBuckets(options)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Deletes a vector bucket (bucket must be empty)\n   * All indexes must be deleted before deleting the bucket\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Name of the vector bucket to delete\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .deleteBucket('embeddings-old')\n   * ```\n   */\n  async deleteBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    return super.deleteBucket(vectorBucketName)\n  }\n}\n\n/**\n *\n * @alpha\n *\n * Scoped client for operations within a specific vector bucket\n * Provides index management and access to vector operations\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport class VectorBucketScope extends VectorIndexApi {\n  private vectorBucketName: string\n\n  /**\n   * @alpha\n   *\n   * Creates a helper that automatically scopes all index operations to the provided bucket.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * ```\n   */\n  constructor(\n    url: string,\n    headers: { [key: string]: string },\n    vectorBucketName: string,\n    fetch?: Fetch\n  ) {\n    super(url, headers, fetch)\n    this.vectorBucketName = vectorBucketName\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Creates a new vector index in this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Index configuration (vectorBucketName is automatically set)\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * await bucket.createIndex({\n   *   indexName: 'documents-openai',\n   *   dataType: 'float32',\n   *   dimension: 1536,\n   *   distanceMetric: 'cosine',\n   *   metadataConfiguration: {\n   *     nonFilterableMetadataKeys: ['raw_text']\n   *   }\n   * })\n   * ```\n   */\n  override async createIndex(options: Omit<CreateIndexOptions, 'vectorBucketName'>) {\n    return super.createIndex({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Lists indexes in this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Listing options (vectorBucketName is automatically set)\n   * @returns Promise with response containing indexes array and pagination token or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * const { data } = await bucket.listIndexes({ prefix: 'documents-' })\n   * ```\n   */\n  override async listIndexes(options: Omit<ListIndexesOptions, 'vectorBucketName'> = {}) {\n    return super.listIndexes({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Retrieves metadata for a specific index in this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param indexName - Name of the index to retrieve\n   * @returns Promise with index metadata or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * const { data } = await bucket.getIndex('documents-openai')\n   * console.log('Dimension:', data?.index.dimension)\n   * ```\n   */\n  override async getIndex(indexName: string) {\n    return super.getIndex(this.vectorBucketName, indexName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Deletes an index from this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param indexName - Name of the index to delete\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * await bucket.deleteIndex('old-index')\n   * ```\n   */\n  override async deleteIndex(indexName: string) {\n    return super.deleteIndex(this.vectorBucketName, indexName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access operations for a specific index within this bucket\n   * Returns a scoped client for vector data operations\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param indexName - Name of the index\n   * @returns Index-scoped client with vector data operations\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   *\n   * // Insert vectors\n   * await index.putVectors({\n   *   vectors: [\n   *     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\n   *   ]\n   * })\n   *\n   * // Query similar vectors\n   * const { data } = await index.queryVectors({\n   *   queryVector: { float32: [...] },\n   *   topK: 5\n   * })\n   * ```\n   */\n  index(indexName: string): VectorIndexScope {\n    return new VectorIndexScope(\n      this.url,\n      this.headers,\n      this.vectorBucketName,\n      indexName,\n      this.fetch\n    )\n  }\n}\n\n/**\n *\n * @alpha\n *\n * Scoped client for operations within a specific vector index\n * Provides vector data operations (put, get, list, query, delete)\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport class VectorIndexScope extends VectorDataApi {\n  private vectorBucketName: string\n  private indexName: string\n\n  /**\n   *\n   * @alpha\n   *\n   * Creates a helper that automatically scopes all vector operations to the provided bucket/index names.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * ```\n   */\n  constructor(\n    url: string,\n    headers: { [key: string]: string },\n    vectorBucketName: string,\n    indexName: string,\n    fetch?: Fetch\n  ) {\n    super(url, headers, fetch)\n    this.vectorBucketName = vectorBucketName\n    this.indexName = indexName\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Inserts or updates vectors in this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Vector insertion options (bucket and index names automatically set)\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * await index.putVectors({\n   *   vectors: [\n   *     {\n   *       key: 'doc-1',\n   *       data: { float32: [0.1, 0.2, ...] },\n   *       metadata: { title: 'Introduction', page: 1 }\n   *     }\n   *   ]\n   * })\n   * ```\n   */\n  override async putVectors(options: Omit<PutVectorsOptions, 'vectorBucketName' | 'indexName'>) {\n    return super.putVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Retrieves vectors by keys from this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Vector retrieval options (bucket and index names automatically set)\n   * @returns Promise with response containing vectors array or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * const { data } = await index.getVectors({\n   *   keys: ['doc-1', 'doc-2'],\n   *   returnMetadata: true\n   * })\n   * ```\n   */\n  override async getVectors(options: Omit<GetVectorsOptions, 'vectorBucketName' | 'indexName'>) {\n    return super.getVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Lists vectors in this index with pagination\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Listing options (bucket and index names automatically set)\n   * @returns Promise with response containing vectors array and pagination token or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * const { data } = await index.listVectors({\n   *   maxResults: 500,\n   *   returnMetadata: true\n   * })\n   * ```\n   */\n  override async listVectors(\n    options: Omit<ListVectorsOptions, 'vectorBucketName' | 'indexName'> = {}\n  ) {\n    return super.listVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Queries for similar vectors in this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Query options (bucket and index names automatically set)\n   * @returns Promise with response containing matches array of similar vectors ordered by distance or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * const { data } = await index.queryVectors({\n   *   queryVector: { float32: [0.1, 0.2, ...] },\n   *   topK: 5,\n   *   filter: { category: 'technical' },\n   *   returnDistance: true,\n   *   returnMetadata: true\n   * })\n   * ```\n   */\n  override async queryVectors(\n    options: Omit<QueryVectorsOptions, 'vectorBucketName' | 'indexName'>\n  ) {\n    return super.queryVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Deletes vectors by keys from this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Deletion options (bucket and index names automatically set)\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * await index.deleteVectors({\n   *   keys: ['doc-1', 'doc-2', 'doc-3']\n   * })\n   * ```\n   */\n  override async deleteVectors(\n    options: Omit<DeleteVectorsOptions, 'vectorBucketName' | 'indexName'>\n  ) {\n    return super.deleteVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n}\n","import StorageFileApi from './packages/StorageFileApi'\nimport StorageBucketApi from './packages/StorageBucketApi'\nimport StorageAnalyticsClient from './packages/StorageAnalyticsClient'\nimport { Fetch } from './lib/fetch'\nimport { StorageVectorsClient } from './lib/vectors'\n\nexport interface StorageClientOptions {\n  useNewHostname?: boolean\n}\n\nexport class StorageClient extends StorageBucketApi {\n  /**\n   * Creates a client for Storage buckets, files, analytics, and vectors.\n   *\n   * @category File Buckets\n   * @example\n   * ```ts\n   * import { StorageClient } from '@supabase/storage-js'\n   *\n   * const storage = new StorageClient('https://xyzcompany.supabase.co/storage/v1', {\n   *   apikey: 'public-anon-key',\n   * })\n   * const avatars = storage.from('avatars')\n   * ```\n   */\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    fetch?: Fetch,\n    opts?: StorageClientOptions\n  ) {\n    super(url, headers, fetch, opts)\n  }\n\n  /**\n   * Perform file operation in a bucket.\n   *\n   * @category File Buckets\n   * @param id The bucket id to operate on.\n   *\n   * @example\n   * ```typescript\n   * const avatars = supabase.storage.from('avatars')\n   * ```\n   */\n  from(id: string): StorageFileApi {\n    return new StorageFileApi(this.url, this.headers, id, this.fetch)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access vector storage operations.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @returns A StorageVectorsClient instance configured with the current storage settings.\n   */\n  get vectors(): StorageVectorsClient {\n    return new StorageVectorsClient(this.url + '/vector', {\n      headers: this.headers,\n      fetch: this.fetch,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access analytics storage operations using Iceberg tables.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @returns A StorageAnalyticsClient instance configured with the current storage settings.\n   */\n  get analytics(): StorageAnalyticsClient {\n    return new StorageAnalyticsClient(this.url + '/iceberg', this.headers, this.fetch)\n  }\n}\n"],"mappings":";;;AAAA,IAAaA,YAAA,GAAb,cAAkCC,KAAA,CAAM;EAGtCC,YAAYC,OAAA,EAAiB;IAC3B,MAAMA,OAAA,CAAQ;SAHNC,gBAAA,GAAmB;IAI3B,KAAKC,IAAA,GAAO;;;AAIhB,SAAgBC,eAAeC,KAAA,EAAuC;EACpE,OAAO,OAAOA,KAAA,KAAU,YAAYA,KAAA,KAAU,QAAQ,sBAAsBA,KAAA;;AAG9E,IAAaC,eAAA,GAAb,cAAqCR,YAAA,CAAa;EAIhDE,YAAYC,OAAA,EAAiBM,MAAA,EAAgBC,UAAA,EAAoB;IAC/D,MAAMP,OAAA,CAAQ;IACd,KAAKE,IAAA,GAAO;IACZ,KAAKI,MAAA,GAASA,MAAA;IACd,KAAKC,UAAA,GAAaA,UAAA;;EAGpBC,OAAA,EAAS;IACP,OAAO;MACLN,IAAA,EAAM,KAAKA,IAAA;MACXF,OAAA,EAAS,KAAKA,OAAA;MACdM,MAAA,EAAQ,KAAKA,MAAA;MACbC,UAAA,EAAY,KAAKA;KAClB;;;AAIL,IAAaE,mBAAA,GAAb,cAAyCZ,YAAA,CAAa;EAGpDE,YAAYC,OAAA,EAAiBU,aAAA,EAAwB;IACnD,MAAMV,OAAA,CAAQ;IACd,KAAKE,IAAA,GAAO;IACZ,KAAKQ,aAAA,GAAgBA,aAAA;;;;;;ACtCzB,MAAaC,cAAA,GAAgBC,WAAA,IAA+B;EAC1D,IAAIA,WAAA,EACF;IAAA,OAAoBA,WAAA,CAAY,GAAAC,SAAG,CAAK;EAAA;EAE1C;IAAA,OAAoBC,KAAA,CAAM,GAAAD,SAAG,CAAK;EAAA;;AAGpC,MAAaE,iBAAA,GAAAA,CAAA,KAAyC;EACpD,OAAOC,QAAA;;AAGT,MAAaC,gBAAA,GAAoBC,IAAA,IAAuC;EACtE,IAAIC,KAAA,CAAMC,OAAA,CAAQF,IAAA,CAAK,EACrB,OAAOA,IAAA,CAAKG,GAAA,CAAKC,EAAA,IAAOL,gBAAA,CAAiBK,EAAA,CAAG,CAAC,M,IACpC,OAAOJ,IAAA,KAAS,cAAcA,IAAA,KAASK,MAAA,CAAOL,IAAA,CAAK,EAC5D,OAAOA,IAAA;EAGT,MAAMM,MAAA,GAA8B,EAAE;EACtCD,MAAA,CAAOE,OAAA,CAAQP,IAAA,CAAK,CAACQ,OAAA,CAAAC,IAAA,IAA0B;IAAA,IAAjB,CAACC,GAAA,EAAKC,KAAA,IAAAF,IAAA;IAClC,MAAMG,MAAA,GAASF,GAAA,CAAIG,OAAA,CAAQ,iBAAkBC,CAAA,IAAMA,CAAA,CAAEC,WAAA,EAAa,CAACF,OAAA,CAAQ,SAAS,GAAG,CAAC;IACxFP,MAAA,CAAOM,MAAA,IAAUb,gBAAA,CAAiBY,KAAA,CAAM;IACxC;EAEF,OAAOL,MAAA;;;;;;;AAQT,MAAaU,eAAA,GAAiBL,KAAA,IAA2B;EACvD,IAAI,OAAOA,KAAA,KAAU,YAAYA,KAAA,KAAU,MACzC,OAAO;EAGT,MAAMM,SAAA,GAAYZ,MAAA,CAAOa,cAAA,CAAeP,KAAA,CAAM;EAC9C,QACGM,SAAA,KAAc,QACbA,SAAA,KAAcZ,MAAA,CAAOY,SAAA,IACrBZ,MAAA,CAAOa,cAAA,CAAeD,SAAA,CAAU,KAAK,SACvC,EAAEE,MAAA,CAAOC,WAAA,IAAeT,KAAA,KACxB,EAAEQ,MAAA,CAAOE,QAAA,IAAYV,KAAA;;;;;;;;;;;;;;;;;AAmBzB,MAAaW,iBAAA,GAAqBC,UAAA,IAAgC;EAChE,IAAI,CAACA,UAAA,IAAc,OAAOA,UAAA,KAAe,UACvC,OAAO;EAIT,IAAIA,UAAA,CAAWC,MAAA,KAAW,KAAKD,UAAA,CAAWC,MAAA,GAAS,KACjD,OAAO;EAIT,IAAID,UAAA,CAAWE,IAAA,EAAM,KAAKF,UAAA,EACxB,OAAO;EAMT,IAAIA,UAAA,CAAWG,QAAA,CAAS,IAAI,IAAIH,UAAA,CAAWG,QAAA,CAAS,KAAK,EACvD,OAAO;EAOT,OADwB,4BACDC,IAAA,CAAKJ,UAAA,CAAW;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC1EzC,MAAMK,kBAAA,GAAoBC,GAAA,IACxB;;aAAIC,GAAA,IACJD,GAAA,CAAI/C,OAAA,IACJ+C,GAAA,CAAIE,iBAAA,KACH,OAAOF,GAAA,CAAI3C,KAAA,KAAU,WAAW2C,GAAA,CAAI3C,KAAA,IAAA8C,UAAA,GAAQH,GAAA,CAAI3C,KAAA,cAAA8C,UAAA,uBAAAA,UAAA,CAAOlD,OAAA,KACxDmD,IAAA,CAAKC,SAAA,CAAUL,GAAA,CAAI;;AAErB,MAAMM,aAAA,GAAc,MAAAC,CAClBlD,KAAA,EACAmD,MAAA,EACAC,OAAA,KACG;EAGH,IAAIpD,KAAA,aAFQ,MAAMW,iBAAA,EAAiB,KAEP,EAAAyC,OAAA,aAAAA,OAAA,uBAACA,OAAA,CAASC,aAAA,GACpCrD,KAAA,CACGsD,IAAA,EAAM,CACNC,IAAA,CAAMZ,GAAA,IAAQ;IACb,MAAMzC,MAAA,GAASF,KAAA,CAAME,MAAA,IAAU;IAC/B,MAAMC,UAAA,IAAAwC,GAAA,aAAAA,GAAA,uBAAaA,GAAA,CAAKxC,UAAA,KAAcD,MAAA,GAAS;IAC/CiD,MAAA,CAAO,IAAIlD,eAAA,CAAgByC,kBAAA,CAAiBC,GAAA,CAAI,EAAEzC,MAAA,EAAQC,UAAA,CAAW,CAAC;IACtE,CACDqD,KAAA,CAAOb,GAAA,IAAQ;IACdQ,MAAA,CAAO,IAAI9C,mBAAA,CAAoBqC,kBAAA,CAAiBC,GAAA,CAAI,EAAEA,GAAA,CAAI,CAAC;IAC3D,MAEJQ,MAAA,CAAO,IAAI9C,mBAAA,CAAoBqC,kBAAA,CAAiB1C,KAAA,CAAM,EAAEA,KAAA,CAAM,CAAC;;AAInE,MAAMyD,mBAAA,GAAAA,CACJC,MAAA,EACAN,OAAA,EACAO,UAAA,EACAC,IAAA,KACG;EACH,MAAMC,MAAA,GAA+B;IAAEH,MAAA;IAAQI,OAAA,GAAAV,OAAA,aAAAA,OAAA,uBAASA,OAAA,CAASU,OAAA,KAAW;GAAI;EAEhF,IAAIJ,MAAA,KAAW,SAAS,CAACE,IAAA,EACvB,OAAOC,MAAA;EAGT,IAAI/B,eAAA,CAAc8B,IAAA,CAAK,EAAE;IACvBC,MAAA,CAAOC,OAAA,GAAAC,cAAA;MAAY,gBAAgB;IAAA,GAAAX,OAAA,aAAAA,OAAA,uBAAuBA,OAAA,CAASU,OAAA;IACnED,MAAA,CAAOD,IAAA,GAAOb,IAAA,CAAKC,SAAA,CAAUY,IAAA,CAAK;SAElCC,MAAA,CAAOD,IAAA,GAAOA,IAAA;EAGhB,IAAAR,OAAA,aAAAA,OAAA,uBAAIA,OAAA,CAASY,MAAA,EACXH,MAAA,CAAOG,MAAA,GAASZ,OAAA,CAAQY,MAAA;EAG1B,OAAAD,cAAA,CAAAA,cAAA,KAAYF,MAAA,GAAWF,UAAA;;AAGzB,eAAeM,iBACbC,OAAA,EACAR,MAAA,EACAS,GAAA,EACAf,OAAA,EACAO,UAAA,EACAC,IAAA,EACc;EACd,OAAO,IAAIQ,OAAA,EAASC,OAAA,EAASlB,MAAA,KAAW;IACtCe,OAAA,CAAQC,GAAA,EAAKV,mBAAA,CAAkBC,MAAA,EAAQN,OAAA,EAASO,UAAA,EAAYC,IAAA,CAAK,CAAC,CAC/DL,IAAA,CAAMnC,MAAA,IAAW;MAChB,IAAI,CAACA,MAAA,CAAOkD,EAAA,EAAI,MAAMlD,MAAA;MACtB,IAAAgC,OAAA,aAAAA,OAAA,uBAAIA,OAAA,CAASC,aAAA,EAAe,OAAOjC,MAAA;MACnC,OAAOA,MAAA,CAAOkC,IAAA,EAAM;MACpB,CACDC,IAAA,CAAMgB,IAAA,IAASF,OAAA,CAAQE,IAAA,CAAK,CAAC,CAC7Bf,KAAA,CAAOxD,KAAA,IAAUiD,aAAA,CAAYjD,KAAA,EAAOmD,MAAA,EAAQC,OAAA,CAAQ,CAAC;IACxD;;AAGJ,eAAsBoB,IACpBN,OAAA,EACAC,GAAA,EACAf,OAAA,EACAO,UAAA,EACc;EACd,OAAOM,gBAAA,CAAeC,OAAA,EAAS,OAAOC,GAAA,EAAKf,OAAA,EAASO,UAAA,CAAW;;AAGjE,eAAsBc,OACpBP,OAAA,EACAC,GAAA,EACAP,IAAA,EACAR,OAAA,EACAO,UAAA,EACc;EACd,OAAOM,gBAAA,CAAeC,OAAA,EAAS,QAAQC,GAAA,EAAKf,OAAA,EAASO,UAAA,EAAYC,IAAA,CAAK;;AAGxE,eAAsBc,IACpBR,OAAA,EACAC,GAAA,EACAP,IAAA,EACAR,OAAA,EACAO,UAAA,EACc;EACd,OAAOM,gBAAA,CAAeC,OAAA,EAAS,OAAOC,GAAA,EAAKf,OAAA,EAASO,UAAA,EAAYC,IAAA,CAAK;;AAGvE,eAAsBe,KACpBT,OAAA,EACAC,GAAA,EACAf,OAAA,EACAO,UAAA,EACc;EACd,OAAOM,gBAAA,CACLC,OAAA,EACA,QACAC,GAAA,EAAAJ,cAAA,CAAAA,cAAA,KAEKX,OAAA;IACHC,aAAA,EAAe;EAAA,IAEjBM,UAAA,CACD;;AAGH,eAAsBiB,OACpBV,OAAA,EACAC,GAAA,EACAP,IAAA,EACAR,OAAA,EACAO,UAAA,EACc;EACd,OAAOM,gBAAA,CAAeC,OAAA,EAAS,UAAUC,GAAA,EAAKf,OAAA,EAASO,UAAA,EAAYC,IAAA,CAAK;;;;;AC/I1E,IAAqBiB,qBAAA,GAArB,MAAkG;EAChGlF,YACEmF,UAAQ,EACRC,kBAAQ,EACR;IAFQ,KAAAD,UAAA,GAAAA,UAAA;IACA,KAAAC,kBAAA,GAAAA,kBAAA;;EAGVxB,KACEyB,WAAA,EAGAC,UAAA,EAC8B;IAC9B,OAAO,KAAKC,OAAA,EAAS,CAAC3B,IAAA,CAAKyB,WAAA,EAAaC,UAAA,CAAW;;EAGrD,MAAcC,QAAA,EAAmD;;IAC/D,IAAI;MAGF,OAAO;QACLX,IAAA,GAHa,MAAMY,KAAA,CAAKL,UAAA,EAAY,EAGvBlB,IAAA;QACb5D,KAAA,EAAO;OACR;aACMA,KAAA,EAAO;MACd,IAAImF,KAAA,CAAKJ,kBAAA,EACP,MAAM/E,KAAA;MAGR,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;;;;;;sBC9BAiC,MAAA,CAAOC,WAAA;AADnB,IAAqBkD,mBAAA,GAArB,MAAkF;EAIhFzF,YACEmF,UAAQ,EACRC,kBAAQ,EACR;IAFQ,KAAAD,UAAA,GAAAA,UAAA;IACA,KAAAC,kBAAA,GAAAA,kBAAA;gCAL8B;SAChCM,OAAA,GAAgD;;EAOxDC,SAAA,EAAkC;IAChC,OAAO,IAAIT,qBAAA,CAAsB,KAAKC,UAAA,EAAY,KAAKC,kBAAA,CAAmB;;EAG5ExB,KACEyB,WAAA,EACAC,UAAA,EAC8B;IAC9B,OAAO,KAAKM,UAAA,EAAY,CAAChC,IAAA,CAAKyB,WAAA,EAAaC,UAAA,CAAW;;EAGxDzB,MACEyB,UAAA,EACyC;IACzC,OAAO,KAAKM,UAAA,EAAY,CAAC/B,KAAA,CAAMyB,UAAA,CAAW;;EAG5CO,QAAQC,SAAA,EAAgE;IACtE,OAAO,KAAKF,UAAA,EAAY,CAACC,OAAA,CAAQC,SAAA,CAAU;;EAG7CF,UAAQA,CAAA,EAA4C;IAClD,IAAI,CAAC,KAAKF,OAAA,EACR,KAAKA,OAAA,GAAU,KAAKH,OAAA,EAAS;IAE/B,OAAO,KAAKG,OAAA;;EAGd,MAAcH,QAAA,EAAyC;;IACrD,IAAI;MAGF,OAAO;QACLX,IAAA,EAAM,OAHO,MAAMY,KAAA,CAAKL,UAAA,EAAY,EAGjBY,IAAA,EAAM;QACzB1F,KAAA,EAAO;OACR;aACMA,KAAA,EAAO;MACd,IAAImF,KAAA,CAAKJ,kBAAA,EACP,MAAM/E,KAAA;MAGR,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;;;;;ACzCZ,MAAM2F,sBAAA,GAAyB;EAC7BC,KAAA,EAAO;EACPC,MAAA,EAAQ;EACRC,MAAA,EAAQ;IACNC,MAAA,EAAQ;IACRC,KAAA,EAAO;;CAEV;AAED,MAAMC,oBAAA,GAAoC;EACxCC,YAAA,EAAc;EACdC,WAAA,EAAa;EACbC,MAAA,EAAQ;CACT;AAcD,IAAqBC,cAAA,GAArB,MAAoC;EAOlC1G,YACEwE,GAAA,EAIA;IAAA,IAHAL,OAAA,GAAArD,SAAA,CAAA6B,MAAA,QAAA7B,SAAA,QAAA6F,SAAA,GAAA7F,SAAA,MAAqC,EAAE;IAAA,IACvC8F,QAAA,GAAA9F,SAAA,CAAA6B,MAAA,OAAA7B,SAAA,MAAA6F,SAAA;IAAA,IACAE,OAAA,GAAA/F,SAAA,CAAA6B,MAAA,OAAA7B,SAAA,MAAA6F,SAAA;SANQvB,kBAAA,GAAqB;IAQ7B,KAAKZ,GAAA,GAAMA,GAAA;IACX,KAAKL,OAAA,GAAUA,OAAA;IACf,KAAKyC,QAAA,GAAWA,QAAA;IAChB,KAAK7F,KAAA,GAAQH,cAAA,CAAaiG,OAAA,CAAM;;;;;;;EAQlCC,YAAOA,CAAA,EAAqB;IAC1B,KAAK1B,kBAAA,GAAqB;IAC1B,OAAO;;;;;;;;;EAUT,MAAc2B,eACZhD,MAAA,EACAiD,IAAA,EACAC,QAAA,EACAC,WAAA,EAUA;;IACA,IAAI;MACF,IAAIjD,IAAA;MACJ,MAAMR,OAAA,GAAAW,cAAA,CAAAA,cAAA,KAAekC,oBAAA,GAAyBY,WAAA;MAC9C,IAAI/C,OAAA,GAAAC,cAAA,CAAAA,cAAA,KACCoB,KAAA,CAAKrB,OAAA,GACJJ,MAAA,KAAW,UAAU;QAAE,YAAYoD,MAAA,CAAO1D,OAAA,CAAQgD,MAAA;MAAkB,CAAE;MAG5E,MAAMW,QAAA,GAAW3D,OAAA,CAAQ2D,QAAA;MAEzB,IAAI,OAAOC,IAAA,KAAS,eAAeJ,QAAA,YAAoBI,IAAA,EAAM;QAC3DpD,IAAA,GAAO,IAAIqD,QAAA,EAAU;QACrBrD,IAAA,CAAKsD,MAAA,CAAO,gBAAgB9D,OAAA,CAAQ8C,YAAA,CAAuB;QAC3D,IAAIa,QAAA,EACFnD,IAAA,CAAKsD,MAAA,CAAO,YAAY/B,KAAA,CAAKgC,cAAA,CAAeJ,QAAA,CAAS,CAAC;QAExDnD,IAAA,CAAKsD,MAAA,CAAO,IAAIN,QAAA,CAAS;iBAChB,OAAOK,QAAA,KAAa,eAAeL,QAAA,YAAoBK,QAAA,EAAU;QAC1ErD,IAAA,GAAOgD,QAAA;QAEP,IAAI,CAAChD,IAAA,CAAKwD,GAAA,CAAI,eAAe,EAC3BxD,IAAA,CAAKsD,MAAA,CAAO,gBAAgB9D,OAAA,CAAQ8C,YAAA,CAAuB;QAE7D,IAAIa,QAAA,IAAY,CAACnD,IAAA,CAAKwD,GAAA,CAAI,WAAW,EACnCxD,IAAA,CAAKsD,MAAA,CAAO,YAAY/B,KAAA,CAAKgC,cAAA,CAAeJ,QAAA,CAAS,CAAC;aAEnD;QACLnD,IAAA,GAAOgD,QAAA;QACP9C,OAAA,CAAQ,8BAAAuD,MAAA,CAA8BjE,OAAA,CAAQ8C,YAAA;QAC9CpC,OAAA,CAAQ,kBAAkBV,OAAA,CAAQ+C,WAAA;QAElC,IAAIY,QAAA,EACFjD,OAAA,CAAQ,gBAAgBqB,KAAA,CAAKmC,QAAA,CAASnC,KAAA,CAAKgC,cAAA,CAAeJ,QAAA,CAAS,CAAC;QAStE,KAHG,OAAOQ,cAAA,KAAmB,eAAe3D,IAAA,YAAgB2D,cAAA,IACzD3D,IAAA,IAAQ,OAAOA,IAAA,KAAS,YAAY,UAAUA,IAAA,IAAQ,OAAOA,IAAA,CAAK4D,IAAA,KAAS,eAE9D,CAACpE,OAAA,CAAQY,MAAA,EACvBZ,OAAA,CAAQY,MAAA,GAAS;;MAIrB,IAAA6C,WAAA,aAAAA,WAAA,uBAAIA,WAAA,CAAa/C,OAAA,EACfA,OAAA,GAAAC,cAAA,CAAAA,cAAA,KAAeD,OAAA,GAAY+C,WAAA,CAAY/C,OAAA;MAGzC,MAAM2D,SAAA,GAAYtC,KAAA,CAAKuC,mBAAA,CAAoBf,IAAA,CAAK;MAChD,MAAMgB,KAAA,GAAQxC,KAAA,CAAKyC,aAAA,CAAcH,SAAA,CAAU;MAC3C,MAAMlD,IAAA,GAAO,OAAOb,MAAA,IAAU,QAAQgB,GAAA,GAAMD,MAAA,EAC1CU,KAAA,CAAKzE,KAAA,KAAA2G,MAAA,CACFlC,KAAA,CAAKhB,GAAA,cAAAkD,MAAA,CAAcM,KAAA,GACtB/D,IAAA,EAAAG,cAAA;QACED;MAAA,IAAAV,OAAA,aAAAA,OAAA,uBAAaA,OAAA,CAASY,MAAA,IAAS;QAAEA,MAAA,EAAQZ,OAAA,CAAQY;MAAA,CAAQ,GAAG,EAAE,EACjE;MAED,OAAO;QACLO,IAAA,EAAM;UAAEoC,IAAA,EAAMc,SAAA;UAAWI,EAAA,EAAItD,IAAA,CAAKuD,EAAA;UAAIC,QAAA,EAAUxD,IAAA,CAAKyD;SAAK;QAC1DhI,KAAA,EAAO;OACR;aACMA,KAAA,EAAO;MACd,IAAImF,KAAA,CAAKJ,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAgDV,MAAMiI,OACJtB,IAAA,EACAC,QAAA,EACAC,WAAA,EAUA;IACA,YAAYH,cAAA,CAAe,QAAQC,IAAA,EAAMC,QAAA,EAAUC,WAAA,CAAY;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAkCjE,MAAMqB,kBACJvB,IAAA,EACAwB,KAAA,EACAvB,QAAA,EACAC,WAAA,EACA;;IACA,MAAMY,SAAA,GAAYW,MAAA,CAAKV,mBAAA,CAAoBf,IAAA,CAAK;IAChD,MAAMgB,KAAA,GAAQS,MAAA,CAAKR,aAAA,CAAcH,SAAA,CAAU;IAE3C,MAAMtD,GAAA,GAAM,IAAIkE,GAAA,CAAID,MAAA,CAAKjE,GAAA,0BAAAkD,MAAA,CAA6BM,KAAA,EAAQ;IAC9DxD,GAAA,CAAImE,YAAA,CAAaC,GAAA,CAAI,SAASJ,KAAA,CAAM;IAEpC,IAAI;MACF,IAAIvE,IAAA;MACJ,MAAMR,OAAA,GAAAW,cAAA;QAAYqC,MAAA,EAAQH,oBAAA,CAAqBG;MAAA,GAAWS,WAAA;MAC1D,MAAM/C,OAAA,GAAAC,cAAA,CAAAA,cAAA,KACDqE,MAAA,CAAKtE,OAAA,GACL;QAAE,YAAYgD,MAAA,CAAO1D,OAAA,CAAQgD,MAAA;MAAkB,CAAE;MAGtD,IAAI,OAAOY,IAAA,KAAS,eAAeJ,QAAA,YAAoBI,IAAA,EAAM;QAC3DpD,IAAA,GAAO,IAAIqD,QAAA,EAAU;QACrBrD,IAAA,CAAKsD,MAAA,CAAO,gBAAgB9D,OAAA,CAAQ8C,YAAA,CAAuB;QAC3DtC,IAAA,CAAKsD,MAAA,CAAO,IAAIN,QAAA,CAAS;iBAChB,OAAOK,QAAA,KAAa,eAAeL,QAAA,YAAoBK,QAAA,EAAU;QAC1ErD,IAAA,GAAOgD,QAAA;QACPhD,IAAA,CAAKsD,MAAA,CAAO,gBAAgB9D,OAAA,CAAQ8C,YAAA,CAAuB;aACtD;QACLtC,IAAA,GAAOgD,QAAA;QACP9C,OAAA,CAAQ,8BAAAuD,MAAA,CAA8BjE,OAAA,CAAQ8C,YAAA;QAC9CpC,OAAA,CAAQ,kBAAkBV,OAAA,CAAQ+C,WAAA;;MAKpC,OAAO;QACL5B,IAAA,EAAM;UAAEoC,IAAA,EAAMc,SAAA;UAAWM,QAAA,GAHd,MAAMrD,GAAA,CAAI0D,MAAA,CAAK1H,KAAA,EAAOyD,GAAA,CAAIqE,QAAA,EAAU,EAAE5E,IAAA,EAAgB;YAAEE;UAAA,CAAS,CAAC,EAGrCkE;SAAK;QAC7ChI,KAAA,EAAO;OACR;aACMA,KAAA,EAAO;MACd,IAAIoI,MAAA,CAAKrD,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAkCV,MAAMyI,sBACJ9B,IAAA,EACAvD,OAAA,EAUA;;IACA,IAAI;MACF,IAAIuE,KAAA,GAAQe,MAAA,CAAKd,aAAA,CAAcjB,IAAA,CAAK;MAEpC,MAAM7C,OAAA,GAAAC,cAAA,KAAe2E,MAAA,CAAK5E,OAAA;MAE1B,IAAAV,OAAA,aAAAA,OAAA,uBAAIA,OAAA,CAASgD,MAAA,EACXtC,OAAA,CAAQ,cAAc;MAGxB,MAAMS,IAAA,GAAO,MAAME,MAAA,CACjBiE,MAAA,CAAKhI,KAAA,KAAA2G,MAAA,CACFqB,MAAA,CAAKvE,GAAA,0BAAAkD,MAAA,CAA0BM,KAAA,GAClC,EAAE,EACF;QAAE7D;MAAA,CAAS,CACZ;MAED,MAAMK,GAAA,GAAM,IAAIkE,GAAA,CAAIK,MAAA,CAAKvE,GAAA,GAAMI,IAAA,CAAKJ,GAAA,CAAI;MAExC,MAAMgE,KAAA,GAAQhE,GAAA,CAAImE,YAAA,CAAa9D,GAAA,CAAI,QAAQ;MAE3C,IAAI,CAAC2D,KAAA,EACH,MAAM,IAAI1I,YAAA,CAAa,2BAA2B;MAGpD,OAAO;QAAE8E,IAAA,EAAM;UAAEoE,SAAA,EAAWxE,GAAA,CAAIqE,QAAA,EAAU;UAAE7B,IAAA;UAAMwB;SAAO;QAAEnI,KAAA,EAAO;OAAM;aACjEA,KAAA,EAAO;MACd,IAAI0I,MAAA,CAAK3D,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAgDV,MAAM4I,OACJjC,IAAA,EACAC,QAAA,EAWAC,WAAA,EAUA;IACA,YAAYH,cAAA,CAAe,OAAOC,IAAA,EAAMC,QAAA,EAAUC,WAAA,CAAY;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA8BhE,MAAMgC,KACJC,QAAA,EACAC,MAAA,EACA3F,OAAA,EAUA;;IACA,IAAI;MAYF,OAAO;QAAEmB,IAAA,EAXI,MAAME,MAAA,CACjBuE,MAAA,CAAKtI,KAAA,KAAA2G,MAAA,CACF2B,MAAA,CAAK7E,GAAA,mBACR;UACEoC,QAAA,EAAUyC,MAAA,CAAKzC,QAAA;UACf0C,SAAA,EAAWH,QAAA;UACXI,cAAA,EAAgBH,MAAA;UAChBI,iBAAA,EAAA/F,OAAA,aAAAA,OAAA,uBAAmBA,OAAA,CAAS+F;SAC7B,EACD;UAAErF,OAAA,EAASkF,MAAA,CAAKlF;QAAA,CAAS,CAC1B;QACc9D,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAIgJ,MAAA,CAAKjE,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA+BV,MAAMoJ,KACJN,QAAA,EACAC,MAAA,EACA3F,OAAA,EAUA;;IACA,IAAI;MAYF,OAAO;QAAEmB,IAAA,EAAM;UAAEoC,IAAA,GAXJ,MAAMlC,MAAA,CACjB4E,MAAA,CAAK3I,KAAA,KAAA2G,MAAA,CACFgC,MAAA,CAAKlF,GAAA,mBACR;YACEoC,QAAA,EAAU8C,MAAA,CAAK9C,QAAA;YACf0C,SAAA,EAAWH,QAAA;YACXI,cAAA,EAAgBH,MAAA;YAChBI,iBAAA,EAAA/F,OAAA,aAAAA,OAAA,uBAAmBA,OAAA,CAAS+F;WAC7B,EACD;YAAErF,OAAA,EAASuF,MAAA,CAAKvF;UAAA,CAAS,CAC1B,EAC2BkE;QAAA,CAAK;QAAEhI,KAAA,EAAO;OAAM;aACzCA,KAAA,EAAO;MACd,IAAIqJ,MAAA,CAAKtE,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAuDV,MAAMsJ,gBACJ3C,IAAA,EACA4C,SAAA,EACAnG,OAAA,EAUA;;IACA,IAAI;MACF,IAAIuE,KAAA,GAAQ6B,MAAA,CAAK5B,aAAA,CAAcjB,IAAA,CAAK;MAEpC,IAAIpC,IAAA,GAAO,MAAME,MAAA,CACf+E,MAAA,CAAK9I,KAAA,KAAA2G,MAAA,CACFmC,MAAA,CAAKrF,GAAA,mBAAAkD,MAAA,CAAmBM,KAAA,GAAA5D,cAAA;QACzBwF;MAAA,IAAAnG,OAAA,aAAAA,OAAA,uBAAeA,OAAA,CAASqG,SAAA,IAAY;QAAEA,SAAA,EAAWrG,OAAA,CAAQqG;MAAA,CAAW,GAAG,EAAE,GAC3E;QAAE3F,OAAA,EAAS0F,MAAA,CAAK1F;MAAA,CAAS,CAC1B;MACD,MAAM4F,kBAAA,IAAAtG,OAAA,aAAAA,OAAA,uBAAqBA,OAAA,CAASuG,QAAA,iBAAAtC,MAAA,CACnBjE,OAAA,CAAQuG,QAAA,KAAa,OAAO,KAAKvG,OAAA,CAAQuG,QAAA,IACtD;MAEJpF,IAAA,GAAO;QAAEoE,SAAA,EADSiB,SAAA,IAAAvC,MAAA,CAAamC,MAAA,CAAKrF,GAAA,EAAAkD,MAAA,CAAM9C,IAAA,CAAKsF,SAAA,EAAAxC,MAAA,CAAYqC,kBAAA;MAAqB,CAC5D;MACpB,OAAO;QAAEnF,IAAA;QAAMvE,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAIwJ,MAAA,CAAKzE,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA0CV,MAAM8J,iBACJC,KAAA,EACAR,SAAA,EACAnG,OAAA,EAUA;;IACA,IAAI;MACF,MAAMmB,IAAA,GAAO,MAAME,MAAA,CACjBuF,MAAA,CAAKtJ,KAAA,KAAA2G,MAAA,CACF2C,MAAA,CAAK7F,GAAA,mBAAAkD,MAAA,CAAmB2C,MAAA,CAAKzD,QAAA,GAChC;QAAEgD,SAAA;QAAWQ;OAAO,EACpB;QAAEjG,OAAA,EAASkG,MAAA,CAAKlG;MAAA,CAAS,CAC1B;MAED,MAAM4F,kBAAA,IAAAtG,OAAA,aAAAA,OAAA,uBAAqBA,OAAA,CAASuG,QAAA,iBAAAtC,MAAA,CACnBjE,OAAA,CAAQuG,QAAA,KAAa,OAAO,KAAKvG,OAAA,CAAQuG,QAAA,IACtD;MACJ,OAAO;QACLpF,IAAA,EAAMA,IAAA,CAAKtD,GAAA,CAAKgJ,KAAA,IAAAlG,cAAA,CAAAA,cAAA,KACXkG,KAAA;UACHtB,SAAA,EAAWsB,KAAA,CAAMJ,SAAA,GACbD,SAAA,IAAAvC,MAAA,CAAa2C,MAAA,CAAK7F,GAAA,EAAAkD,MAAA,CAAM4C,KAAA,CAAMJ,SAAA,EAAAxC,MAAA,CAAYqC,kBAAA,EAAqB,GAC/D;QAAA,GACH;QACH1J,KAAA,EAAO;OACR;aACMA,KAAA,EAAO;MACd,IAAIgK,MAAA,CAAKjF,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA0CV2J,SACEhD,IAAA,EACAvD,OAAA,EACqB;IAErB,MAAM8G,UAAA,GADsB,QAAA9G,OAAA,aAAAA,OAAA,uBAAOA,OAAA,CAASqG,SAAA,MAAc,cACjB,+BAA+B;IACxE,MAAMU,mBAAA,GAAsB,KAAKC,0BAAA,EAAAhH,OAAA,aAAAA,OAAA,uBAA2BA,OAAA,CAASqG,SAAA,KAAa,EAAE,CAAC;IACrF,MAAMY,WAAA,GAAcF,mBAAA,OAAA9C,MAAA,CAA0B8C,mBAAA,IAAwB;IACtE,MAAMxC,KAAA,GAAQ,KAAKC,aAAA,CAAcjB,IAAA,CAAK;IACtC,MAAM7B,UAAA,GAAAA,CAAA,KACJN,GAAA,CAAI,KAAK9D,KAAA,KAAA2G,MAAA,CAAU,KAAKlD,GAAA,OAAAkD,MAAA,CAAO6C,UAAA,OAAA7C,MAAA,CAAcM,KAAA,EAAAN,MAAA,CAAQgD,WAAA,GAAe;MAClEvG,OAAA,EAAS,KAAKA,OAAA;MACdT,aAAA,EAAe;KAChB,CAAC;IACJ,OAAO,IAAI+B,mBAAA,CAAoBN,UAAA,EAAY,KAAKC,kBAAA,CAAmB;;;;;;;;;;;;;;;;;EAkBrE,MAAMuF,KAAK3D,IAAA,EAST;;IACA,MAAMgB,KAAA,GAAQ4C,OAAA,CAAK3C,aAAA,CAAcjB,IAAA,CAAK;IAEtC,IAAI;MAKF,OAAO;QAAEpC,IAAA,EAAM1D,gBAAA,CAJF,MAAM2D,GAAA,CAAI+F,OAAA,CAAK7J,KAAA,KAAA2G,MAAA,CAAUkD,OAAA,CAAKpG,GAAA,mBAAAkD,MAAA,CAAmBM,KAAA,GAAS;UACrE7D,OAAA,EAASyG,OAAA,CAAKzG;QAAA,CACf,CAAC,CAEmC;QAA4B9D,KAAA,EAAO;OAAM;aACvEA,KAAA,EAAO;MACd,IAAIuK,OAAA,CAAKxF,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;;;;;;;;;;;;;;;;EAmBV,MAAMwK,OAAO7D,IAAA,EASX;;IACA,MAAMgB,KAAA,GAAQ8C,OAAA,CAAK7C,aAAA,CAAcjB,IAAA,CAAK;IAEtC,IAAI;MACF,MAAMhC,IAAA,CAAK8F,OAAA,CAAK/J,KAAA,KAAA2G,MAAA,CAAUoD,OAAA,CAAKtG,GAAA,cAAAkD,MAAA,CAAcM,KAAA,GAAS;QACpD7D,OAAA,EAAS2G,OAAA,CAAK3G;MAAA,CACf,CAAC;MAEF,OAAO;QAAES,IAAA,EAAM;QAAMvE,KAAA,EAAO;OAAM;aAC3BA,KAAA,EAAO;MACd,IAAIyK,OAAA,CAAK1F,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,IAAIA,KAAA,YAAiBK,mBAAA,EAAqB;QACjE,MAAMC,aAAA,GAAgBN,KAAA,CAAMM,aAAA;QAE5B,IAAI,CAAC,KAAK,IAAI,CAACkC,QAAA,CAAAlC,aAAA,aAAAA,aAAA,uBAASA,aAAA,CAAeJ,MAAA,CAAO,EAC5C,OAAO;UAAEqE,IAAA,EAAM;UAAOvE;SAAO;;MAIjC,MAAMA,KAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAsDV0K,aACE/D,IAAA,EACAvD,OAAA,EACiC;IACjC,MAAMuE,KAAA,GAAQ,KAAKC,aAAA,CAAcjB,IAAA,CAAK;IACtC,MAAMgE,YAAA,GAAyB,EAAE;IAEjC,MAAMjB,kBAAA,IAAAtG,OAAA,aAAAA,OAAA,uBAAqBA,OAAA,CAASuG,QAAA,gBAAAtC,MAAA,CACpBjE,OAAA,CAAQuG,QAAA,KAAa,OAAO,KAAKvG,OAAA,CAAQuG,QAAA,IACrD;IAEJ,IAAID,kBAAA,KAAuB,IACzBiB,YAAA,CAAaC,IAAA,CAAKlB,kBAAA,CAAmB;IAIvC,MAAMQ,UAAA,GADsB,QAAA9G,OAAA,aAAAA,OAAA,uBAAOA,OAAA,CAASqG,SAAA,MAAc,cACjB,iBAAiB;IAC1D,MAAMU,mBAAA,GAAsB,KAAKC,0BAAA,EAAAhH,OAAA,aAAAA,OAAA,uBAA2BA,OAAA,CAASqG,SAAA,KAAa,EAAE,CAAC;IAErF,IAAIU,mBAAA,KAAwB,IAC1BQ,YAAA,CAAaC,IAAA,CAAKT,mBAAA,CAAoB;IAGxC,IAAIE,WAAA,GAAcM,YAAA,CAAaE,IAAA,CAAK,IAAI;IACxC,IAAIR,WAAA,KAAgB,IAClBA,WAAA,OAAAhD,MAAA,CAAkBgD,WAAA;IAGpB,OAAO;MACL9F,IAAA,EAAM;QAAEuG,SAAA,EAAWlB,SAAA,IAAAvC,MAAA,CAAa,KAAKlD,GAAA,OAAAkD,MAAA,CAAO6C,UAAA,cAAA7C,MAAA,CAAqBM,KAAA,EAAAN,MAAA,CAAQgD,WAAA;MAAc;IAAE,CAC1F;;;;;;;;;;;;;;;;;;;;;;;;;EA0BH,MAAMzF,OAAOmF,KAAA,EASX;;IACA,IAAI;MAOF,OAAO;QAAExF,IAAA,EANI,MAAMK,MAAA,CACjBmG,OAAA,CAAKrK,KAAA,KAAA2G,MAAA,CACF0D,OAAA,CAAK5G,GAAA,cAAAkD,MAAA,CAAc0D,OAAA,CAAKxE,QAAA,GAC3B;UAAEyE,QAAA,EAAUjB;QAAA,CAAO,EACnB;UAAEjG,OAAA,EAASiH,OAAA,CAAKjH;QAAA,CAAS,CAC1B;QACc9D,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAI+K,OAAA,CAAKhG,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA8HV,MAAMiL,KACJtE,IAAA,EACAvD,OAAA,EACAO,UAAA,EAUA;;IACA,IAAI;MACF,MAAMC,IAAA,GAAAG,cAAA,CAAAA,cAAA,CAAAA,cAAA,KAAY4B,sBAAA,GAA2BvC,OAAA;QAAS8H,MAAA,EAAQvE,IAAA,IAAQ;MAAA;MAQtE,OAAO;QAAEpC,IAAA,EAPI,MAAME,MAAA,CACjB0G,OAAA,CAAKzK,KAAA,KAAA2G,MAAA,CACF8D,OAAA,CAAKhH,GAAA,mBAAAkD,MAAA,CAAmB8D,OAAA,CAAK5E,QAAA,GAChC3C,IAAA,EACA;UAAEE,OAAA,EAASqH,OAAA,CAAKrH;QAAA,CAAS,EACzBH,UAAA,CACD;QACc3D,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAImL,OAAA,CAAKpG,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;;;;;;;;EAWV,MAAMoL,OACJhI,OAAA,EACAO,UAAA,EAUA;;IACA,IAAI;MACF,MAAMC,IAAA,GAAAG,cAAA,KAAYX,OAAA;MAQlB,OAAO;QAAEmB,IAAA,EAPI,MAAME,MAAA,CACjB4G,OAAA,CAAK3K,KAAA,KAAA2G,MAAA,CACFgE,OAAA,CAAKlH,GAAA,sBAAAkD,MAAA,CAAsBgE,OAAA,CAAK9E,QAAA,GACnC3C,IAAA,EACA;UAAEE,OAAA,EAASuH,OAAA,CAAKvH;QAAA,CAAS,EACzBH,UAAA,CACD;QACc3D,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAIqL,OAAA,CAAKtG,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;EAIVmH,cAAUA,CAAeJ,QAAA,EAA+B;IACtD,OAAOhE,IAAA,CAAKC,SAAA,CAAU+D,QAAA,CAAS;;EAGjCO,SAAS/C,IAAA,EAAc;IACrB,IAAI,OAAO+G,MAAA,KAAW,aACpB,OAAOA,MAAA,CAAOC,IAAA,CAAKhH,IAAA,CAAK,CAACiE,QAAA,CAAS,SAAS;IAE7C,OAAOgD,IAAA,CAAKjH,IAAA,CAAK;;EAGnBqD,aAAQA,CAAcjB,IAAA,EAAc;IAClC,UAAAU,MAAA,CAAU,KAAKd,QAAA,OAAAc,MAAA,CAAYV,IAAA,CAAKhF,OAAA,CAAQ,QAAQ,GAAG;;EAGrD+F,mBAAQA,CAAoBf,IAAA,EAAc;IACxC,OAAOA,IAAA,CAAKhF,OAAA,CAAQ,YAAY,GAAG,CAACA,OAAA,CAAQ,QAAQ,IAAI;;EAG1DyI,0BAAQA,CAA2BX,SAAA,EAA6B;IAC9D,MAAM5F,MAAA,GAAmB,EAAE;IAC3B,IAAI4F,SAAA,CAAUgC,KAAA,EACZ5H,MAAA,CAAO+G,IAAA,UAAAvD,MAAA,CAAcoC,SAAA,CAAUgC,KAAA,EAAQ;IAGzC,IAAIhC,SAAA,CAAUiC,MAAA,EACZ7H,MAAA,CAAO+G,IAAA,WAAAvD,MAAA,CAAeoC,SAAA,CAAUiC,MAAA,EAAS;IAG3C,IAAIjC,SAAA,CAAUkC,MAAA,EACZ9H,MAAA,CAAO+G,IAAA,WAAAvD,MAAA,CAAeoC,SAAA,CAAUkC,MAAA,EAAS;IAG3C,IAAIlC,SAAA,CAAUmC,MAAA,EACZ/H,MAAA,CAAO+G,IAAA,WAAAvD,MAAA,CAAeoC,SAAA,CAAUmC,MAAA,EAAS;IAG3C,IAAInC,SAAA,CAAUoC,OAAA,EACZhI,MAAA,CAAO+G,IAAA,YAAAvD,MAAA,CAAgBoC,SAAA,CAAUoC,OAAA,EAAU;IAG7C,OAAOhI,MAAA,CAAOgH,IAAA,CAAK,IAAI;;;;;;AC5wC3B,MAAaiB,OAAA,GAAU;;;;ACLvB,MAAaC,iBAAA,GAAkB;EAC7B,+BAAA1E,MAAA,CAA+ByE,OAAA;AAAA,CAChC;;;;ACID,IAAqBE,gBAAA,GAArB,MAAsC;EAMpCrM,YACEwE,GAAA,EAIA;IAAA,IAHAL,OAAA,GAAArD,SAAA,CAAA6B,MAAA,QAAA7B,SAAA,QAAA6F,SAAA,GAAA7F,SAAA,MAAqC,EAAE;IAAA,IACvC+F,OAAA,GAAA/F,SAAA,CAAA6B,MAAA,OAAA7B,SAAA,MAAA6F,SAAA;IAAA,IACA2F,IAAA,GAAAxL,SAAA,CAAA6B,MAAA,OAAA7B,SAAA,MAAA6F,SAAA;SANQvB,kBAAA,GAAqB;IAQ7B,MAAMmH,OAAA,GAAU,IAAI7D,GAAA,CAAIlE,GAAA,CAAI;IAI5B,IAAA8H,IAAA,aAAAA,IAAA,uBAAIA,IAAA,CAAME,cAAA,EAER;UADuB,yBAAyB1J,IAAA,CAAKyJ,OAAA,CAAQE,QAAA,CAAS,IAChD,CAACF,OAAA,CAAQE,QAAA,CAAS5J,QAAA,CAAS,oBAAoB,EACnE0J,OAAA,CAAQE,QAAA,GAAWF,OAAA,CAAQE,QAAA,CAASzK,OAAA,CAAQ,aAAa,oBAAoB;;IAIjF,KAAKwC,GAAA,GAAM+H,OAAA,CAAQG,IAAA,CAAK1K,OAAA,CAAQ,OAAO,GAAG;IAC1C,KAAKmC,OAAA,GAAAC,cAAA,CAAAA,cAAA,KAAegI,iBAAA,GAAoBjI,OAAA;IACxC,KAAKpD,KAAA,GAAQH,cAAA,CAAaiG,OAAA,CAAM;;;;;;;EAQlCC,YAAOA,CAAA,EAAqB;IAC1B,KAAK1B,kBAAA,GAAqB;IAC1B,OAAO;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAmCT,MAAMuH,YAAYlJ,OAAA,EAShB;;IACA,IAAI;MACF,MAAMiH,WAAA,GAAclF,KAAA,CAAKoH,8BAAA,CAA+BnJ,OAAA,CAAQ;MAIhE,OAAO;QAAEmB,IAAA,EAHI,MAAMC,GAAA,CAAIW,KAAA,CAAKzE,KAAA,KAAA2G,MAAA,CAAUlC,KAAA,CAAKhB,GAAA,aAAAkD,MAAA,CAAagD,WAAA,GAAe;UACrEvG,OAAA,EAASqB,KAAA,CAAKrB;QAAA,CACf,CAAC;QACa9D,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAImF,KAAA,CAAKJ,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAqCV,MAAMwM,UAAU3E,EAAA,EASd;;IACA,IAAI;MAEF,OAAO;QAAEtD,IAAA,EADI,MAAMC,GAAA,CAAIiI,MAAA,CAAK/L,KAAA,KAAA2G,MAAA,CAAUoF,MAAA,CAAKtI,GAAA,cAAAkD,MAAA,CAAcQ,EAAA,GAAM;UAAE/D,OAAA,EAAS2I,MAAA,CAAK3I;QAAA,CAAS,CAAC;QAC1E9D,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAIyM,MAAA,CAAK1H,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAyCV,MAAM0M,aACJ7E,EAAA,EAkBA;IAAA,IAjBAzE,OAAA,GAAA3C,SAAA,CAAA6B,MAAA,QAAA7B,SAAA,QAAA6F,SAAA,GAAA7F,SAAA,MAKI;MACFkM,MAAA,EAAQ;IAAA,CACT;;IAWD,IAAI;MAcF,OAAO;QAAEpI,IAAA,EAbI,MAAME,MAAA,CACjB2D,MAAA,CAAK1H,KAAA,KAAA2G,MAAA,CACFe,MAAA,CAAKjE,GAAA,cACR;UACE0D,EAAA;UACA/H,IAAA,EAAM+H,EAAA;UACN+E,IAAA,EAAMxJ,OAAA,CAAQwJ,IAAA;UACdD,MAAA,EAAQvJ,OAAA,CAAQuJ,MAAA;UAChBE,eAAA,EAAiBzJ,OAAA,CAAQ0J,aAAA;UACzBC,kBAAA,EAAoB3J,OAAA,CAAQ4J;SAC7B,EACD;UAAElJ,OAAA,EAASsE,MAAA,CAAKtE;QAAA,CAAS,CAC1B;QACc9D,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAIoI,MAAA,CAAKrD,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAuCV,MAAMiN,aACJpF,EAAA,EACAzE,OAAA,EAcA;;IACA,IAAI;MAaF,OAAO;QAAEmB,IAAA,EAZI,MAAMG,GAAA,CACjBgE,MAAA,CAAKhI,KAAA,KAAA2G,MAAA,CACFqB,MAAA,CAAKvE,GAAA,cAAAkD,MAAA,CAAcQ,EAAA,GACtB;UACEA,EAAA;UACA/H,IAAA,EAAM+H,EAAA;UACN8E,MAAA,EAAQvJ,OAAA,CAAQuJ,MAAA;UAChBE,eAAA,EAAiBzJ,OAAA,CAAQ0J,aAAA;UACzBC,kBAAA,EAAoB3J,OAAA,CAAQ4J;SAC7B,EACD;UAAElJ,OAAA,EAAS4E,MAAA,CAAK5E;QAAA,CAAS,CAC1B;QACc9D,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAI0I,MAAA,CAAK3D,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;EA4BV,MAAMkN,YAAYrF,EAAA,EAShB;;IACA,IAAI;MAOF,OAAO;QAAEtD,IAAA,EANI,MAAME,MAAA,CACjB0I,MAAA,CAAKzM,KAAA,KAAA2G,MAAA,CACF8F,MAAA,CAAKhJ,GAAA,cAAAkD,MAAA,CAAcQ,EAAA,aACtB,EAAE,EACF;UAAE/D,OAAA,EAASqJ,MAAA,CAAKrJ;QAAA,CAAS,CAC1B;QACc9D,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAImN,MAAA,CAAKpI,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA6BV,MAAMoN,aAAavF,EAAA,EASjB;;IACA,IAAI;MAOF,OAAO;QAAEtD,IAAA,EANI,MAAMK,MAAA,CACjBoE,MAAA,CAAKtI,KAAA,KAAA2G,MAAA,CACF2B,MAAA,CAAK7E,GAAA,cAAAkD,MAAA,CAAcQ,EAAA,GACtB,EAAE,EACF;UAAE/D,OAAA,EAASkF,MAAA,CAAKlF;QAAA,CAAS,CAC1B;QACc9D,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAIgJ,MAAA,CAAKjE,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;EAIVuM,8BAAQA,CAA+BnJ,OAAA,EAAqC;IAC1E,MAAMS,MAAA,GAAiC,EAAE;IACzC,IAAIT,OAAA,EAAS;MACX,IAAI,WAAWA,OAAA,EACbS,MAAA,CAAO+B,KAAA,GAAQkB,MAAA,CAAO1D,OAAA,CAAQwC,KAAA,CAAM;MAEtC,IAAI,YAAYxC,OAAA,EACdS,MAAA,CAAOgC,MAAA,GAASiB,MAAA,CAAO1D,OAAA,CAAQyC,MAAA,CAAO;MAExC,IAAIzC,OAAA,CAAQiK,MAAA,EACVxJ,MAAA,CAAOwJ,MAAA,GAASjK,OAAA,CAAQiK,MAAA;MAE1B,IAAIjK,OAAA,CAAQkK,UAAA,EACVzJ,MAAA,CAAOyJ,UAAA,GAAalK,OAAA,CAAQkK,UAAA;MAE9B,IAAIlK,OAAA,CAAQmK,SAAA,EACV1J,MAAA,CAAO0J,SAAA,GAAYnK,OAAA,CAAQmK,SAAA;;IAG/B,OAAOpM,MAAA,CAAOqM,IAAA,CAAK3J,MAAA,CAAO,CAACvB,MAAA,GAAS,IAAI,MAAM,IAAImL,eAAA,CAAgB5J,MAAA,CAAO,CAAC2E,QAAA,EAAU,GAAG;;;;;;;;;;AClb3F,IAAqBkF,sBAAA,GAArB,MAA4C;;;;;;;;;;;;;;;;;;EAuB1C/N,YAAYwE,GAAA,EAAqE;IAAA,IAAxDL,OAAA,GAAArD,SAAA,CAAA6B,MAAA,QAAA7B,SAAA,QAAA6F,SAAA,GAAA7F,SAAA,MAAqC,EAAE;IAAA,IAAE+F,OAAA,GAAA/F,SAAA,CAAA6B,MAAA,OAAA7B,SAAA,MAAA6F,SAAA;SAnBxDvB,kBAAA,GAAqB;IAoB7B,KAAKZ,GAAA,GAAMA,GAAA,CAAIxC,OAAA,CAAQ,OAAO,GAAG;IACjC,KAAKmC,OAAA,GAAAC,cAAA,CAAAA,cAAA,KAAegI,iBAAA,GAAoBjI,OAAA;IACxC,KAAKpD,KAAA,GAAQH,cAAA,CAAaiG,OAAA,CAAM;;;;;;;;;;;;;EAclCC,YAAOA,CAAA,EAAqB;IAC1B,KAAK1B,kBAAA,GAAqB;IAC1B,OAAO;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAqCT,MAAM2H,aAAa5M,IAAA,EASjB;;IACA,IAAI;MAEF,OAAO;QAAEyE,IAAA,EADI,MAAME,MAAA,CAAKU,KAAA,CAAKzE,KAAA,KAAA2G,MAAA,CAAUlC,KAAA,CAAKhB,GAAA,cAAc;UAAErE;QAAA,CAAM,EAAE;UAAEgE,OAAA,EAASqB,KAAA,CAAKrB;QAAA,CAAS,CAAC;QAC/E9D,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAImF,KAAA,CAAKJ,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAkDV,MAAMsM,YAAYlJ,OAAA,EAehB;;IACA,IAAI;MAEF,MAAMuK,WAAA,GAAc,IAAIF,eAAA,EAAiB;MACzC,KAAArK,OAAA,aAAAA,OAAA,uBAAIA,OAAA,CAASwC,KAAA,MAAU,QAAW+H,WAAA,CAAYpF,GAAA,CAAI,SAASnF,OAAA,CAAQwC,KAAA,CAAM4C,QAAA,EAAU,CAAC;MACpF,KAAApF,OAAA,aAAAA,OAAA,uBAAIA,OAAA,CAASyC,MAAA,MAAW,QAAW8H,WAAA,CAAYpF,GAAA,CAAI,UAAUnF,OAAA,CAAQyC,MAAA,CAAO2C,QAAA,EAAU,CAAC;MACvF,IAAApF,OAAA,aAAAA,OAAA,uBAAIA,OAAA,CAASkK,UAAA,EAAYK,WAAA,CAAYpF,GAAA,CAAI,cAAcnF,OAAA,CAAQkK,UAAA,CAAW;MAC1E,IAAAlK,OAAA,aAAAA,OAAA,uBAAIA,OAAA,CAASmK,SAAA,EAAWI,WAAA,CAAYpF,GAAA,CAAI,aAAanF,OAAA,CAAQmK,SAAA,CAAU;MACvE,IAAAnK,OAAA,aAAAA,OAAA,uBAAIA,OAAA,CAASiK,MAAA,EAAQM,WAAA,CAAYpF,GAAA,CAAI,UAAUnF,OAAA,CAAQiK,MAAA,CAAO;MAE9D,MAAMhD,WAAA,GAAcsD,WAAA,CAAYnF,QAAA,EAAU;MAC1C,MAAMrE,GAAA,GAAMkG,WAAA,MAAAhD,MAAA,CAAiBoF,MAAA,CAAKtI,GAAA,cAAAkD,MAAA,CAAcgD,WAAA,OAAAhD,MAAA,CAAmBoF,MAAA,CAAKtI,GAAA,YAAI;MAI5E,OAAO;QAAEI,IAAA,EAFI,MAAMC,GAAA,CAAIiI,MAAA,CAAK/L,KAAA,EAAOyD,GAAA,EAAK;UAAEL,OAAA,EAAS2I,MAAA,CAAK3I;QAAA,CAAS,CAAC;QAE7C9D,KAAA,EAAO;OAAM;aAC3BA,KAAA,EAAO;MACd,IAAIyM,MAAA,CAAK1H,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAmCV,MAAMoN,aAAa/K,UAAA,EASjB;;IACA,IAAI;MAOF,OAAO;QAAEkC,IAAA,EANI,MAAMK,MAAA,CACjBwD,MAAA,CAAK1H,KAAA,KAAA2G,MAAA,CACFe,MAAA,CAAKjE,GAAA,cAAAkD,MAAA,CAAchF,UAAA,GACtB,EAAE,EACF;UAAEyB,OAAA,EAASsE,MAAA,CAAKtE;QAAA,CAAS,CAC1B;QACc9D,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAIoI,MAAA,CAAKrD,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAG9B,MAAMA,KAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA+HVuL,KAAKlJ,UAAA,EAA+C;;IAElD,IAAI,CAACD,iBAAA,CAAkBC,UAAA,CAAW,EAChC,MAAM,IAAI5C,YAAA,CACR,qJAED;IAOH,MAAMmO,OAAA,GAAU,IAAIC,kBAAA,CAAmB;MACrC3B,OAAA,EAAS,KAAK/H,GAAA;MACd2J,WAAA,EAAazL,UAAA;MACb0L,IAAA,EAAM;QACJnB,IAAA,EAAM;QACNoB,UAAA,EAAY,MAAAA,CAAA,KAAYtF,MAAA,CAAK5E;OAC9B;MACDpD,KAAA,EAAO,KAAKA;KACb,CAAC;IAEF,MAAMqE,kBAAA,GAAqB,KAAKA,kBAAA;IAuBhC,OArBuB,IAAIkJ,KAAA,CAAML,OAAA,EAAS;MACxCpJ,IAAI0J,MAAA,EAAQC,IAAA,EAAgC;QAC1C,MAAM1M,KAAA,GAAQyM,MAAA,CAAOC,IAAA;QACrB,IAAI,OAAO1M,KAAA,KAAU,YACnB,OAAOA,KAAA;QAGT,OAAO,kBAA8B;UACnC,IAAI;YAAA,SAAA2M,IAAA,GAAA3N,SAAA,CAAA6B,MAAA,EADW+L,IAAA,OAAAtN,KAAA,CAAAqN,IAAA,GAAAE,IAAA,MAAAA,IAAA,GAAAF,IAAA,EAAAE,IAAA;cAAAD,IAAA,CAAAC,IAAA,IAAA7N,SAAA,CAAA6N,IAAA;YAAA;YAGb,OAAO;cAAE/J,IAAA,EADI,MAAO9C,KAAA,CAAmB8M,KAAA,CAAML,MAAA,EAAQG,IAAA,CAAK;cAC3CrO,KAAA,EAAO;aAAM;mBACrBA,KAAA,EAAO;YACd,IAAI+E,kBAAA,EACF,MAAM/E,KAAA;YAER,OAAO;cAAEuE,IAAA,EAAM;cAAavE;aAAuB;;;;KAI1D,CAAC;;;;;;ACvbN,MAAawO,eAAA,GAAkB;EAC7B,+BAAAnH,MAAA,CAA+ByE,OAAA;EAC/B,gBAAgB;CACjB;;;;;;;ACDD,IAAa2C,mBAAA,GAAb,cAAyC/O,KAAA,CAAM;EAG7CC,YAAYC,OAAA,EAAiB;IAC3B,MAAMA,OAAA,CAAQ;SAHN8O,uBAAA,GAA0B;IAIlC,KAAK5O,IAAA,GAAO;;;;;;;;AAShB,SAAgB6O,sBAAsB3O,KAAA,EAA8C;EAClF,OAAO,OAAOA,KAAA,KAAU,YAAYA,KAAA,KAAU,QAAQ,6BAA6BA,KAAA;;;;;;AAOrF,IAAa4O,sBAAA,GAAb,cAA4CH,mBAAA,CAAoB;EAI9D9O,YAAYC,OAAA,EAAiBM,MAAA,EAAgBC,UAAA,EAAoB;IAC/D,MAAMP,OAAA,CAAQ;IACd,KAAKE,IAAA,GAAO;IACZ,KAAKI,MAAA,GAASA,MAAA;IACd,KAAKC,UAAA,GAAaA,UAAA;;EAGpBC,OAAA,EAAS;IACP,OAAO;MACLN,IAAA,EAAM,KAAKA,IAAA;MACXF,OAAA,EAAS,KAAKA,OAAA;MACdM,MAAA,EAAQ,KAAKA,MAAA;MACbC,UAAA,EAAY,KAAKA;KAClB;;;;;;;AAQL,IAAa0O,0BAAA,GAAb,cAAgDJ,mBAAA,CAAoB;EAGlE9O,YAAYC,OAAA,EAAiBU,aAAA,EAAwB;IACnD,MAAMV,OAAA,CAAQ;IACd,KAAKE,IAAA,GAAO;IACZ,KAAKQ,aAAA,GAAgBA,aAAA;;;;;;;AAQzB,IAAYwO,uBAAA,4BAAAC,yBAAA,EAAL;;EAELA,yBAAA;;EAEAA,yBAAA;;EAEAA,yBAAA;;EAEAA,yBAAA;;EAEAA,yBAAA;;EAEAA,yBAAA;;;;;;;;;;;;;ACnEF,MAAaC,YAAA,GAAgBxO,WAAA,IAA+B;EAC1D,IAAIA,WAAA,EACF;IAAA,OAAoBA,WAAA,CAAY,GAAAC,SAAG,CAAK;EAAA;EAE1C;IAAA,OAAoBC,KAAA,CAAM,GAAAD,SAAG,CAAK;EAAA;;;;;;;;AASpC,MAAawO,eAAA,GAAAA,CAAA,KAAyC;EACpD,OAAOrO,QAAA;;;;;;;;;;AAWT,MAAasO,aAAA,GAAiBzN,KAAA,IAA2B;EACvD,IAAI,OAAOA,KAAA,KAAU,YAAYA,KAAA,KAAU,MACzC,OAAO;EAGT,MAAMM,SAAA,GAAYZ,MAAA,CAAOa,cAAA,CAAeP,KAAA,CAAM;EAC9C,QACGM,SAAA,KAAc,QACbA,SAAA,KAAcZ,MAAA,CAAOY,SAAA,IACrBZ,MAAA,CAAOa,cAAA,CAAeD,SAAA,CAAU,KAAK,SACvC,EAAEE,MAAA,CAAOC,WAAA,IAAeT,KAAA,KACxB,EAAEQ,MAAA,CAAOE,QAAA,IAAYV,KAAA;;;;;;;;;AAWzB,MAAa0N,kBAAA,GAAsBC,MAAA,IAA+B;EAEhE,OAAOrO,KAAA,CAAMwK,IAAA,CAAK,IAAI8D,YAAA,CAAaD,MAAA,CAAO,CAAC;;;;;;;;;;AAW7C,MAAaE,uBAAA,GAAAA,CACXC,MAAA,EACAC,iBAAA,KACS;EACT,IAAIA,iBAAA,KAAsB,UAAaD,MAAA,CAAOE,OAAA,CAAQnN,MAAA,KAAWkN,iBAAA,EAC/D,MAAM,IAAI9P,KAAA,wCAAA2H,MAAA,CAC+BmI,iBAAA,YAAAnI,MAAA,CAA0BkI,MAAA,CAAOE,OAAA,CAAQnN,MAAA,EACjF;;;;;;;;;;AChDL,MAAMoN,gBAAA,GAAoB/M,GAAA,IACxBA,GAAA,CAAIC,GAAA,IAAOD,GAAA,CAAI/C,OAAA,IAAW+C,GAAA,CAAIE,iBAAA,IAAqBF,GAAA,CAAI3C,KAAA,IAAS+C,IAAA,CAAKC,SAAA,CAAUL,GAAA,CAAI;;;;;;;AAQrF,MAAMO,WAAA,GAAc,MAAAA,CAClBlD,KAAA,EACAmD,MAAA,EACAC,OAAA,KACG;EAUH,IANEpD,KAAA,IACA,OAAOA,KAAA,KAAU,YACjB,YAAYA,KAAA,IACZ,QAAQA,KAAA,IACR,OAAQA,KAAA,CAAcE,MAAA,KAAW,YAEb,EAAAkD,OAAA,aAAAA,OAAA,uBAACA,OAAA,CAASC,aAAA,GAAe;IAC7C,MAAMnD,MAAA,GAAUF,KAAA,CAAcE,MAAA,IAAU;IACxC,MAAMyP,aAAA,GAAgB3P,KAAA;IAGtB,IAAI,OAAO2P,aAAA,CAAcrM,IAAA,KAAS,YAChCqM,aAAA,CACGrM,IAAA,EAAM,CACNC,IAAA,CAAMZ,GAAA,IAAa;MAClB,MAAMxC,UAAA,IAAAwC,GAAA,aAAAA,GAAA,uBAAaA,GAAA,CAAKxC,UAAA,MAAAwC,GAAA,aAAAA,GAAA,uBAAcA,GAAA,CAAKiN,IAAA,KAAQ1P,MAAA,GAAS;MAC5DiD,MAAA,CAAO,IAAIyL,sBAAA,CAAuBc,gBAAA,CAAiB/M,GAAA,CAAI,EAAEzC,MAAA,EAAQC,UAAA,CAAW,CAAC;MAC7E,CACDqD,KAAA,OAAY;MAEX,MAAMrD,UAAA,GAAaD,MAAA,GAAS;MAE5BiD,MAAA,CAAO,IAAIyL,sBAAA,CADKe,aAAA,CAAcE,UAAA,YAAAxI,MAAA,CAAsBnH,MAAA,WAAO,EAChBA,MAAA,EAAQC,UAAA,CAAW,CAAC;MAC/D,MACC;MAEL,MAAMA,UAAA,GAAaD,MAAA,GAAS;MAE5BiD,MAAA,CAAO,IAAIyL,sBAAA,CADKe,aAAA,CAAcE,UAAA,YAAAxI,MAAA,CAAsBnH,MAAA,WAAO,EAChBA,MAAA,EAAQC,UAAA,CAAW,CAAC;;SAGjEgD,MAAA,CAAO,IAAI0L,0BAAA,CAA2Ba,gBAAA,CAAiB1P,KAAA,CAAM,EAAEA,KAAA,CAAM,CAAC;;;;;;;;;;AAY1E,MAAM8P,iBAAA,GAAAA,CACJpM,MAAA,EACAN,OAAA,EACAO,UAAA,EACAC,IAAA,KACG;EACH,MAAMC,MAAA,GAA+B;IAAEH,MAAA;IAAQI,OAAA,GAAAV,OAAA,aAAAA,OAAA,uBAASA,OAAA,CAASU,OAAA,KAAW;GAAI;EAEhF,IAAIJ,MAAA,KAAW,SAAS,CAACE,IAAA,EACvB,OAAOC,MAAA;EAGT,IAAIqL,aAAA,CAActL,IAAA,CAAK,EAAE;IACvBC,MAAA,CAAOC,OAAA,GAAAC,cAAA;MAAY,gBAAgB;IAAA,GAAAX,OAAA,aAAAA,OAAA,uBAAuBA,OAAA,CAASU,OAAA;IACnED,MAAA,CAAOD,IAAA,GAAOb,IAAA,CAAKC,SAAA,CAAUY,IAAA,CAAK;SAElCC,MAAA,CAAOD,IAAA,GAAOA,IAAA;EAGhB,OAAAG,cAAA,CAAAA,cAAA,KAAYF,MAAA,GAAWF,UAAA;;;;;;;;;;;;AAazB,eAAeoM,eACb7L,OAAA,EACAR,MAAA,EACAS,GAAA,EACAf,OAAA,EACAO,UAAA,EACAC,IAAA,EACc;EACd,OAAO,IAAIQ,OAAA,EAASC,OAAA,EAASlB,MAAA,KAAW;IACtCe,OAAA,CAAQC,GAAA,EAAK2L,iBAAA,CAAkBpM,MAAA,EAAQN,OAAA,EAASO,UAAA,EAAYC,IAAA,CAAK,CAAC,CAC/DL,IAAA,CAAMnC,MAAA,IAAW;MAChB,IAAI,CAACA,MAAA,CAAOkD,EAAA,EAAI,MAAMlD,MAAA;MACtB,IAAAgC,OAAA,aAAAA,OAAA,uBAAIA,OAAA,CAASC,aAAA,EAAe,OAAOjC,MAAA;MAEnC,MAAM+E,WAAA,GAAc/E,MAAA,CAAO0C,OAAA,CAAQU,GAAA,CAAI,eAAe;MACtD,IAAI,CAAC2B,WAAA,IAAe,CAACA,WAAA,CAAY3D,QAAA,CAAS,mBAAmB,EAC3D,OAAO,EAAE;MAEX,OAAOpB,MAAA,CAAOkC,IAAA,EAAM;MACpB,CACDC,IAAA,CAAMgB,IAAA,IAASF,OAAA,CAAQE,IAAA,CAAK,CAAC,CAC7Bf,KAAA,CAAOxD,KAAA,IAAUkD,WAAA,CAAYlD,KAAA,EAAOmD,MAAA,EAAQC,OAAA,CAAQ,CAAC;IACxD;;;;;;;;;;;AA6BJ,eAAsB4M,KACpB9L,OAAA,EACAC,GAAA,EACAP,IAAA,EACAR,OAAA,EACAO,UAAA,EACc;EACd,OAAOoM,cAAA,CAAe7L,OAAA,EAAS,QAAQC,GAAA,EAAKf,OAAA,EAASO,UAAA,EAAYC,IAAA,CAAK;;;;;;;;;;AC/IxE,IAAqBqM,cAAA,GAArB,MAAoC;;EAOlCtQ,YAAYwE,GAAA,EAAqE;IAAA,IAAxDL,OAAA,GAAArD,SAAA,CAAA6B,MAAA,QAAA7B,SAAA,QAAA6F,SAAA,GAAA7F,SAAA,MAAqC,EAAE;IAAA,IAAE+F,OAAA,GAAA/F,SAAA,CAAA6B,MAAA,OAAA7B,SAAA,MAAA6F,SAAA;SAHxDvB,kBAAA,GAAqB;IAI7B,KAAKZ,GAAA,GAAMA,GAAA,CAAIxC,OAAA,CAAQ,OAAO,GAAG;IACjC,KAAKmC,OAAA,GAAAC,cAAA,CAAAA,cAAA,KAAeyK,eAAA,GAAoB1K,OAAA;IACxC,KAAKpD,KAAA,GAAQsO,YAAA,CAAaxI,OAAA,CAAM;;;EAIlCC,YAAOA,CAAA,EAAqB;IAC1B,KAAK1B,kBAAA,GAAqB;IAC1B,OAAO;;;EAIT,MAAMmL,YAAY9M,OAAA,EAA8D;;IAC9E,IAAI;MAIF,OAAO;QAAEmB,IAAA,EAHI,OAAMyL,IAAA,CAAK7K,KAAA,CAAKzE,KAAA,KAAA2G,MAAA,CAAUlC,KAAA,CAAKhB,GAAA,mBAAmBf,OAAA,EAAS;UACtEU,OAAA,EAASqB,KAAA,CAAKrB;QAAA,CACf,CAAC,KACqB,EAAE;QAAE9D,KAAA,EAAO;OAAM;aACjCA,KAAA,EAAO;MACd,IAAImF,KAAA,CAAKJ,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAI2O,qBAAA,CAAsB3O,KAAA,CAAM,EAC9B,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAE9B,MAAMA,KAAA;;;;EAKV,MAAMmQ,SACJC,gBAAA,EACAC,SAAA,EAC8C;;IAC9C,IAAI;MAOF,OAAO;QAAE9L,IAAA,EANI,MAAMyL,IAAA,CACjBvD,MAAA,CAAK/L,KAAA,KAAA2G,MAAA,CACFoF,MAAA,CAAKtI,GAAA,gBACR;UAAEiM,gBAAA;UAAkBC;SAAW,EAC/B;UAAEvM,OAAA,EAAS2I,MAAA,CAAK3I;QAAA,CAAS,CAC1B;QACc9D,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAIyM,MAAA,CAAK1H,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAI2O,qBAAA,CAAsB3O,KAAA,CAAM,EAC9B,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAE9B,MAAMA,KAAA;;;;EAKV,MAAMsQ,YAAYlN,OAAA,EAAwE;;IACxF,IAAI;MAIF,OAAO;QAAEmB,IAAA,EAHI,MAAMyL,IAAA,CAAK5H,MAAA,CAAK1H,KAAA,KAAA2G,MAAA,CAAUe,MAAA,CAAKjE,GAAA,mBAAmBf,OAAA,EAAS;UACtEU,OAAA,EAASsE,MAAA,CAAKtE;QAAA,CACf,CAAC;QACa9D,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAIoI,MAAA,CAAKrD,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAI2O,qBAAA,CAAsB3O,KAAA,CAAM,EAC9B,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAE9B,MAAMA,KAAA;;;;EAKV,MAAMuQ,YAAYH,gBAAA,EAA0BC,SAAA,EAAoD;;IAC9F,IAAI;MAOF,OAAO;QAAE9L,IAAA,EANI,OAAMyL,IAAA,CACjBtH,MAAA,CAAKhI,KAAA,KAAA2G,MAAA,CACFqB,MAAA,CAAKvE,GAAA,mBACR;UAAEiM,gBAAA;UAAkBC;SAAW,EAC/B;UAAEvM,OAAA,EAAS4E,MAAA,CAAK5E;QAAA,CAAS,CAC1B,KACsB,EAAE;QAAE9D,KAAA,EAAO;OAAM;aACjCA,KAAA,EAAO;MACd,IAAI0I,MAAA,CAAK3D,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAI2O,qBAAA,CAAsB3O,KAAA,CAAM,EAC9B,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAE9B,MAAMA,KAAA;;;;;;;;;;;;AC9GZ,IAAqBwQ,aAAA,GAArB,MAAmC;;EAOjC7Q,YAAYwE,GAAA,EAAqE;IAAA,IAAxDL,OAAA,GAAArD,SAAA,CAAA6B,MAAA,QAAA7B,SAAA,QAAA6F,SAAA,GAAA7F,SAAA,MAAqC,EAAE;IAAA,IAAE+F,OAAA,GAAA/F,SAAA,CAAA6B,MAAA,OAAA7B,SAAA,MAAA6F,SAAA;SAHxDvB,kBAAA,GAAqB;IAI7B,KAAKZ,GAAA,GAAMA,GAAA,CAAIxC,OAAA,CAAQ,OAAO,GAAG;IACjC,KAAKmC,OAAA,GAAAC,cAAA,CAAAA,cAAA,KAAeyK,eAAA,GAAoB1K,OAAA;IACxC,KAAKpD,KAAA,GAAQsO,YAAA,CAAaxI,OAAA,CAAM;;;EAIlCC,YAAOA,CAAA,EAAqB;IAC1B,KAAK1B,kBAAA,GAAqB;IAC1B,OAAO;;;EAIT,MAAM0L,WAAWrN,OAAA,EAA6D;;IAC5E,IAAI;MAEF,IAAIA,OAAA,CAAQsN,OAAA,CAAQpO,MAAA,GAAS,KAAKc,OAAA,CAAQsN,OAAA,CAAQpO,MAAA,GAAS,KACzD,MAAM,IAAI5C,KAAA,CAAM,oDAAoD;MAMtE,OAAO;QAAE6E,IAAA,EAHI,OAAMyL,IAAA,CAAK7K,KAAA,CAAKzE,KAAA,KAAA2G,MAAA,CAAUlC,KAAA,CAAKhB,GAAA,kBAAkBf,OAAA,EAAS;UACrEU,OAAA,EAASqB,KAAA,CAAKrB;QAAA,CACf,CAAC,KACqB,EAAE;QAAE9D,KAAA,EAAO;OAAM;aACjCA,KAAA,EAAO;MACd,IAAImF,KAAA,CAAKJ,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAI2O,qBAAA,CAAsB3O,KAAA,CAAM,EAC9B,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAE9B,MAAMA,KAAA;;;;EAKV,MAAM2Q,WAAWvN,OAAA,EAAsE;;IACrF,IAAI;MAIF,OAAO;QAAEmB,IAAA,EAHI,MAAMyL,IAAA,CAAKvD,MAAA,CAAK/L,KAAA,KAAA2G,MAAA,CAAUoF,MAAA,CAAKtI,GAAA,kBAAkBf,OAAA,EAAS;UACrEU,OAAA,EAAS2I,MAAA,CAAK3I;QAAA,CACf,CAAC;QACa9D,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAIyM,MAAA,CAAK1H,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAI2O,qBAAA,CAAsB3O,KAAA,CAAM,EAC9B,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAE9B,MAAMA,KAAA;;;;EAKV,MAAM4Q,YAAYxN,OAAA,EAAwE;;IACxF,IAAI;MAEF,IAAIA,OAAA,CAAQyN,YAAA,KAAiB,QAAW;QACtC,IAAIzN,OAAA,CAAQyN,YAAA,GAAe,KAAKzN,OAAA,CAAQyN,YAAA,GAAe,IACrD,MAAM,IAAInR,KAAA,CAAM,wCAAwC;QAE1D,IAAI0D,OAAA,CAAQ0N,YAAA,KAAiB,QAC3B;cAAI1N,OAAA,CAAQ0N,YAAA,GAAe,KAAK1N,OAAA,CAAQ0N,YAAA,IAAgB1N,OAAA,CAAQyN,YAAA,EAC9D,MAAM,IAAInR,KAAA,uCAAA2H,MAAA,CAA4CjE,OAAA,CAAQyN,YAAA,GAAe,GAAI;;;MAQvF,OAAO;QAAEtM,IAAA,EAHI,MAAMyL,IAAA,CAAK5H,MAAA,CAAK1H,KAAA,KAAA2G,MAAA,CAAUe,MAAA,CAAKjE,GAAA,mBAAmBf,OAAA,EAAS;UACtEU,OAAA,EAASsE,MAAA,CAAKtE;QAAA,CACf,CAAC;QACa9D,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAIoI,MAAA,CAAKrD,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAI2O,qBAAA,CAAsB3O,KAAA,CAAM,EAC9B,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAE9B,MAAMA,KAAA;;;;EAKV,MAAM+Q,aAAa3N,OAAA,EAA0E;;IAC3F,IAAI;MAIF,OAAO;QAAEmB,IAAA,EAHI,MAAMyL,IAAA,CAAKtH,MAAA,CAAKhI,KAAA,KAAA2G,MAAA,CAAUqB,MAAA,CAAKvE,GAAA,oBAAoBf,OAAA,EAAS;UACvEU,OAAA,EAAS4E,MAAA,CAAK5E;QAAA,CACf,CAAC;QACa9D,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAI0I,MAAA,CAAK3D,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAI2O,qBAAA,CAAsB3O,KAAA,CAAM,EAC9B,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAE9B,MAAMA,KAAA;;;;EAKV,MAAMgR,cAAc5N,OAAA,EAAgE;;IAClF,IAAI;MAEF,IAAIA,OAAA,CAAQoK,IAAA,CAAKlL,MAAA,GAAS,KAAKc,OAAA,CAAQoK,IAAA,CAAKlL,MAAA,GAAS,KACnD,MAAM,IAAI5C,KAAA,CAAM,kDAAkD;MAMpE,OAAO;QAAE6E,IAAA,EAHI,OAAMyL,IAAA,CAAK7C,MAAA,CAAKzM,KAAA,KAAA2G,MAAA,CAAU8F,MAAA,CAAKhJ,GAAA,qBAAqBf,OAAA,EAAS;UACxEU,OAAA,EAASqJ,MAAA,CAAKrJ;QAAA,CACf,CAAC,KACqB,EAAE;QAAE9D,KAAA,EAAO;OAAM;aACjCA,KAAA,EAAO;MACd,IAAImN,MAAA,CAAKpI,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAI2O,qBAAA,CAAsB3O,KAAA,CAAM,EAC9B,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAE9B,MAAMA,KAAA;;;;;;;;;;;;ACpIZ,IAAqBiR,eAAA,GAArB,MAAqC;;EAOnCtR,YAAYwE,GAAA,EAAqE;IAAA,IAAxDL,OAAA,GAAArD,SAAA,CAAA6B,MAAA,QAAA7B,SAAA,QAAA6F,SAAA,GAAA7F,SAAA,MAAqC,EAAE;IAAA,IAAE+F,OAAA,GAAA/F,SAAA,CAAA6B,MAAA,OAAA7B,SAAA,MAAA6F,SAAA;SAHxDvB,kBAAA,GAAqB;IAI7B,KAAKZ,GAAA,GAAMA,GAAA,CAAIxC,OAAA,CAAQ,OAAO,GAAG;IACjC,KAAKmC,OAAA,GAAAC,cAAA,CAAAA,cAAA,KAAeyK,eAAA,GAAoB1K,OAAA;IACxC,KAAKpD,KAAA,GAAQsO,YAAA,CAAaxI,OAAA,CAAM;;;EAIlCC,YAAOA,CAAA,EAAqB;IAC1B,KAAK1B,kBAAA,GAAqB;IAC1B,OAAO;;;EAIT,MAAM2H,aAAa0D,gBAAA,EAA2D;;IAC5E,IAAI;MAOF,OAAO;QAAE7L,IAAA,EANI,OAAMyL,IAAA,CACjB7K,KAAA,CAAKzE,KAAA,KAAA2G,MAAA,CACFlC,KAAA,CAAKhB,GAAA,0BACR;UAAEiM;QAAA,CAAkB,EACpB;UAAEtM,OAAA,EAASqB,KAAA,CAAKrB;QAAA,CAAS,CAC1B,KACsB,EAAE;QAAE9D,KAAA,EAAO;OAAM;aACjCA,KAAA,EAAO;MACd,IAAImF,KAAA,CAAKJ,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAI2O,qBAAA,CAAsB3O,KAAA,CAAM,EAC9B,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAE9B,MAAMA,KAAA;;;;EAKV,MAAMwM,UAAU4D,gBAAA,EAAgF;;IAC9F,IAAI;MAOF,OAAO;QAAE7L,IAAA,EANI,MAAMyL,IAAA,CACjBvD,MAAA,CAAK/L,KAAA,KAAA2G,MAAA,CACFoF,MAAA,CAAKtI,GAAA,uBACR;UAAEiM;QAAA,CAAkB,EACpB;UAAEtM,OAAA,EAAS2I,MAAA,CAAK3I;QAAA,CAAS,CAC1B;QACc9D,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAIyM,MAAA,CAAK1H,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAI2O,qBAAA,CAAsB3O,KAAA,CAAM,EAC9B,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAE9B,MAAMA,KAAA;;;;EAKV,MAAMsM,YAAA,EAE6C;IAAA,IADjDlJ,OAAA,GAAA3C,SAAA,CAAA6B,MAAA,QAAA7B,SAAA,QAAA6F,SAAA,GAAA7F,SAAA,MAAoC,EAAE;;IAEtC,IAAI;MAIF,OAAO;QAAE8D,IAAA,EAHI,MAAMyL,IAAA,CAAK5H,MAAA,CAAK1H,KAAA,KAAA2G,MAAA,CAAUe,MAAA,CAAKjE,GAAA,yBAAyBf,OAAA,EAAS;UAC5EU,OAAA,EAASsE,MAAA,CAAKtE;QAAA,CACf,CAAC;QACa9D,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAIoI,MAAA,CAAKrD,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAI2O,qBAAA,CAAsB3O,KAAA,CAAM,EAC9B,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAE9B,MAAMA,KAAA;;;;EAKV,MAAMoN,aAAagD,gBAAA,EAA2D;;IAC5E,IAAI;MAOF,OAAO;QAAE7L,IAAA,EANI,OAAMyL,IAAA,CACjBtH,MAAA,CAAKhI,KAAA,KAAA2G,MAAA,CACFqB,MAAA,CAAKvE,GAAA,0BACR;UAAEiM;QAAA,CAAkB,EACpB;UAAEtM,OAAA,EAAS4E,MAAA,CAAK5E;QAAA,CAAS,CAC1B,KACsB,EAAE;QAAE9D,KAAA,EAAO;OAAM;aACjCA,KAAA,EAAO;MACd,IAAI0I,MAAA,CAAK3D,kBAAA,EACP,MAAM/E,KAAA;MAER,IAAI2O,qBAAA,CAAsB3O,KAAA,CAAM,EAC9B,OAAO;QAAEuE,IAAA,EAAM;QAAMvE;OAAO;MAE9B,MAAMA,KAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACnCZ,IAAakR,oBAAA,GAAb,cAA0CD,eAAA,CAAgB;;;;;;;;;;;;;;;;;;EAkBxDtR,YAAYwE,GAAA,EAAwD;IAAA,IAA3Cf,OAAA,GAAA3C,SAAA,CAAA6B,MAAA,QAAA7B,SAAA,QAAA6F,SAAA,GAAA7F,SAAA,MAAuC,EAAE;IAChE,MAAM0D,GAAA,EAAKf,OAAA,CAAQU,OAAA,IAAW,EAAE,EAAEV,OAAA,CAAQ1C,KAAA,CAAM;;;;;;;;;;;;;;;;;;;;EAqBlD6K,KAAK6E,gBAAA,EAA6C;IAChD,OAAO,IAAIe,iBAAA,CAAkB,KAAKhN,GAAA,EAAK,KAAKL,OAAA,EAASsM,gBAAA,EAAkB,KAAK1P,KAAA,CAAM;;;;;;;;;;;;;;;;;;;;;;;EAwBpF,MAAMgM,aAAa0D,gBAAA,EAA2D;2CACrE,MAAM1D,YAAA;MAAAvH,KAAA;IAAb,OAAAiM,0BAAA,GAAAC,IAAA,CAAAlM,KAAA,EAA0BiL,gBAAA;;;;;;;;;;;;;;;;;;;;;;;;EAyB5B,MAAM5D,UAAU4D,gBAAA,EAAgF;wCACvF,MAAM5D,SAAA;MAAAC,MAAA;IAAb,OAAA6E,uBAAA,GAAAD,IAAA,CAAA5E,MAAA,EAAuB2D,gBAAA;;;;;;;;;;;;;;;;;;;;;;;;;;EA2BzB,MAAM9D,YAAA,EAE6C;IAAA,IADjDlJ,OAAA,GAAA3C,SAAA,CAAA6B,MAAA,QAAA7B,SAAA,QAAA6F,SAAA,GAAA7F,SAAA,MAAoC,EAAE;0CAE/B,MAAM6L,WAAA;MAAAlE,MAAA;IAAb,OAAAmJ,yBAAA,GAAAF,IAAA,CAAAjJ,MAAA,EAAyBhF,OAAA;;;;;;;;;;;;;;;;;;;;;;;EAwB3B,MAAMgK,aAAagD,gBAAA,EAA2D;2CACrE,MAAMhD,YAAA;MAAA1E,MAAA;IAAb,OAAA8I,0BAAA,GAAAH,IAAA,CAAA3I,MAAA,EAA0B0H,gBAAA;;;;;;;;;;;;AAa9B,IAAae,iBAAA,GAAb,cAAuClB,cAAA,CAAe;;;;;;;;;;;;;;EAgBpDtQ,YACEwE,GAAA,EACAL,OAAA,EACAsM,gBAAA,EACA5J,OAAA,EACA;IACA,MAAMrC,GAAA,EAAKL,OAAA,EAAS0C,OAAA,CAAM;IAC1B,KAAK4J,gBAAA,GAAmBA,gBAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA8B1B,MAAeF,YAAY9M,OAAA,EAAuD;0CACzE,MAAM8M,WAAA;MAAA/C,MAAA;IAAb,OAAAsE,yBAAA,GAAAJ,IAAA,CAAAlE,MAAA,EAAApJ,cAAA,CAAAA,cAAA,KACKX,OAAA;MACHgN,gBAAA,EAAkBjD,MAAA,CAAKiD;IAAA;;;;;;;;;;;;;;;;;;;;;EAuB3B,MAAeE,YAAA,EAAwE;IAAA,IAA5DlN,OAAA,GAAA3C,SAAA,CAAA6B,MAAA,QAAA7B,SAAA,QAAA6F,SAAA,GAAA7F,SAAA,MAAwD,EAAE;0CAC5E,MAAM6P,WAAA;MAAAtH,MAAA;IAAb,OAAA0I,yBAAA,GAAAL,IAAA,CAAArI,MAAA,EAAAjF,cAAA,CAAAA,cAAA,KACKX,OAAA;MACHgN,gBAAA,EAAkBpH,MAAA,CAAKoH;IAAA;;;;;;;;;;;;;;;;;;;;;;EAwB3B,MAAeD,SAASE,SAAA,EAAmB;uCAClC,MAAMF,QAAA;MAAA9G,MAAA;IAAb,OAAAsI,sBAAA,GAAAN,IAAA,CAAAhI,MAAA,EAAsBA,MAAA,CAAK+G,gBAAA,EAAkBC,SAAA;;;;;;;;;;;;;;;;;;;;;EAsB/C,MAAeE,YAAYF,SAAA,EAAmB;0CACrC,MAAME,WAAA;MAAA/G,MAAA;IAAb,OAAAoI,yBAAA,GAAAP,IAAA,CAAA7H,MAAA,EAAyBA,MAAA,CAAK4G,gBAAA,EAAkBC,SAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAkClDwB,MAAMxB,SAAA,EAAqC;IACzC,OAAO,IAAIyB,gBAAA,CACT,KAAK3N,GAAA,EACL,KAAKL,OAAA,EACL,KAAKsM,gBAAA,EACLC,SAAA,EACA,KAAK3P,KAAA,CACN;;;;;;;;;;;;AAaL,IAAaoR,gBAAA,GAAb,cAAsCtB,aAAA,CAAc;;;;;;;;;;;;;;;EAkBlD7Q,YACEwE,GAAA,EACAL,OAAA,EACAsM,gBAAA,EACAC,SAAA,EACA7J,OAAA,EACA;IACA,MAAMrC,GAAA,EAAKL,OAAA,EAAS0C,OAAA,CAAM;IAC1B,KAAK4J,gBAAA,GAAmBA,gBAAA;IACxB,KAAKC,SAAA,GAAYA,SAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA8BnB,MAAeI,WAAWrN,OAAA,EAAoE;yCACrF,MAAMqN,UAAA;MAAAzG,MAAA;IAAb,OAAA+H,wBAAA,GAAAV,IAAA,CAAArH,MAAA,EAAAjG,cAAA,CAAAA,cAAA,KACKX,OAAA;MACHgN,gBAAA,EAAkBpG,MAAA,CAAKoG,gBAAA;MACvBC,SAAA,EAAWrG,MAAA,CAAKqG;;;;;;;;;;;;;;;;;;;;;;;;;EA0BpB,MAAeM,WAAWvN,OAAA,EAAoE;yCACrF,MAAMuN,UAAA;MAAApG,OAAA;IAAb,OAAAyH,wBAAA,GAAAX,IAAA,CAAA9G,OAAA,EAAAxG,cAAA,CAAAA,cAAA,KACKX,OAAA;MACHgN,gBAAA,EAAkB7F,OAAA,CAAK6F,gBAAA;MACvBC,SAAA,EAAW9F,OAAA,CAAK8F;;;;;;;;;;;;;;;;;;;;;;;;;EA0BpB,MAAeO,YAAA,EAEb;IAAA,IADAxN,OAAA,GAAA3C,SAAA,CAAA6B,MAAA,QAAA7B,SAAA,QAAA6F,SAAA,GAAA7F,SAAA,MAAsE,EAAE;0CAEjE,MAAMmQ,WAAA;MAAAnG,OAAA;IAAb,OAAAwH,yBAAA,GAAAZ,IAAA,CAAA5G,OAAA,EAAA1G,cAAA,CAAAA,cAAA,KACKX,OAAA;MACHgN,gBAAA,EAAkB3F,OAAA,CAAK2F,gBAAA;MACvBC,SAAA,EAAW5F,OAAA,CAAK4F;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA6BpB,MAAeU,aACb3N,OAAA,EACA;2CACO,MAAM2N,YAAA;MAAAhG,OAAA;IAAb,OAAAmH,0BAAA,GAAAb,IAAA,CAAAtG,OAAA,EAAAhH,cAAA,CAAAA,cAAA,KACKX,OAAA;MACHgN,gBAAA,EAAkBrF,OAAA,CAAKqF,gBAAA;MACvBC,SAAA,EAAWtF,OAAA,CAAKsF;;;;;;;;;;;;;;;;;;;;;;;;EAyBpB,MAAeW,cACb5N,OAAA,EACA;4CACO,MAAM4N,aAAA;MAAA7F,OAAA;IAAb,OAAAgH,2BAAA,GAAAd,IAAA,CAAAlG,OAAA,EAAApH,cAAA,CAAAA,cAAA,KACKX,OAAA;MACHgN,gBAAA,EAAkBjF,OAAA,CAAKiF,gBAAA;MACvBC,SAAA,EAAWlF,OAAA,CAAKkF;;;;;;;AC1lBtB,IAAa+B,aAAA,GAAb,cAAmCpG,gBAAA,CAAiB;;;;;;;;;;;;;;;EAelDrM,YACEwE,GAAA,EAIA;IAAA,IAHAL,OAAA,GAAArD,SAAA,CAAA6B,MAAA,QAAA7B,SAAA,QAAA6F,SAAA,GAAA7F,SAAA,MAAqC,EAAE;IAAA,IACvC+F,OAAA,GAAA/F,SAAA,CAAA6B,MAAA,OAAA7B,SAAA,MAAA6F,SAAA;IAAA,IACA2F,IAAA,GAAAxL,SAAA,CAAA6B,MAAA,OAAA7B,SAAA,MAAA6F,SAAA;IAEA,MAAMnC,GAAA,EAAKL,OAAA,EAAS0C,OAAA,EAAOyF,IAAA,CAAK;;;;;;;;;;;;;EAclCV,KAAK1D,EAAA,EAA4B;IAC/B,OAAO,IAAIxB,cAAA,CAAe,KAAKlC,GAAA,EAAK,KAAKL,OAAA,EAAS+D,EAAA,EAAI,KAAKnH,KAAA,CAAM;;;;;;;;;;;;;EAcnE,IAAIgQ,QAAA,EAAgC;IAClC,OAAO,IAAIQ,oBAAA,CAAqB,KAAK/M,GAAA,GAAM,WAAW;MACpDL,OAAA,EAAS,KAAKA,OAAA;MACdpD,KAAA,EAAO,KAAKA;KACb,CAAC;;;;;;;;;;;;;EAcJ,IAAI2R,UAAA,EAAoC;IACtC,OAAO,IAAI3E,sBAAA,CAAuB,KAAKvJ,GAAA,GAAM,YAAY,KAAKL,OAAA,EAAS,KAAKpD,KAAA,CAAM","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}